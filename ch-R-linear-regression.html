<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 17 R 선형 회귀 | R 프로그래밍 3판 (draft)</title>
  <meta name="description" content="이 책은 경영데이터분석기초의 주교재로 사용되기 위해 개발되었습니다." />
  <meta name="generator" content="bookdown 0.39 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 17 R 선형 회귀 | R 프로그래밍 3판 (draft)" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="이 책은 경영데이터분석기초의 주교재로 사용되기 위해 개발되었습니다." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 17 R 선형 회귀 | R 프로그래밍 3판 (draft)" />
  
  <meta name="twitter:description" content="이 책은 경영데이터분석기초의 주교재로 사용되기 위해 개발되었습니다." />
  

<meta name="author" content="Kilhwan Kim" />


<meta name="date" content="2025-11-03" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="ch-R-hypothesis-tests.html"/>
<link rel="next" href="ch-RandPython.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<link href="libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="libs/pagedtable-1.1/js/pagedtable.js"></script>
<link href="libs/htmltools-fill-0.5.8.1/fill.css" rel="stylesheet" />
<script src="libs/htmlwidgets-1.6.4/htmlwidgets.js"></script>
<script src="libs/threejs-111/three.min.js"></script>
<script src="libs/threejs-111/Detector.js"></script>
<script src="libs/threejs-111/Projector.js"></script>
<script src="libs/threejs-111/CanvasRenderer.js"></script>
<script src="libs/threejs-111/TrackballControls.js"></script>
<script src="libs/threejs-111/StateOrbitControls.js"></script>
<script src="libs/scatterplotThree-binding-0.3.3/scatterplotThree.js"></script>
<link href="libs/crosstalk-1.2.1/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.1/js/crosstalk.min.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-176754989-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-176754989-1');
</script>


<style type="text/css">
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">R 프로그래밍 3판</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path=""><a href="#%ED%8C%90-%EC%84%9C%EB%AC%B8"><i class="fa fa-check"></i>1판 서문</a></li>
<li class="chapter" data-level="" data-path=""><a href="#%ED%8C%90-%EC%84%9C%EB%AC%B8-1"><i class="fa fa-check"></i>2판 서문</a>
<ul>
<li class="chapter" data-level="" data-path=""><a href="#%ED%8C%90%EC%9D%98-%EC%A3%BC%EC%9A%94-%EA%B0%9C%EC%A0%95-2022%EB%85%84-7%EC%9B%94-%EC%9D%B4%ED%9B%84%EB%B6%80%ED%84%B0"><i class="fa fa-check"></i>2판의 주요 개정 (2022년 7월 이후부터)</a></li>
</ul></li>
<li class="chapter" data-level="" data-path=""><a href="#%ED%8C%90-%EC%84%9C%EB%AC%B8-2"><i class="fa fa-check"></i>3판 서문</a></li>
<li class="chapter" data-level="" data-path=""><a href="#%EC%9D%BC%EB%9F%AC%EB%91%90%EA%B8%B0"><i class="fa fa-check"></i>일러두기</a></li>
</ul></li>
<li class="part"><span><b>I R 프로그래밍 기초</b></span></li>
<li class="chapter" data-level="1" data-path="ch-intro.html"><a href="ch-intro.html"><i class="fa fa-check"></i><b>1</b> <strong>R</strong> 설치 및 시작</a>
<ul>
<li class="chapter" data-level="1.1" data-path="ch-intro.html"><a href="ch-intro.html#sec-Rintro"><i class="fa fa-check"></i><b>1.1</b> <strong>R</strong> 소개</a></li>
<li class="chapter" data-level="1.2" data-path="ch-intro.html"><a href="ch-intro.html#sec-installation"><i class="fa fa-check"></i><b>1.2</b> <strong>R</strong> 설치하기</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="R-linear-regression.html"><a href="#r%EC%9D%84-%EC%9C%88%EB%8F%84%EC%9A%B0%EC%A6%88%EC%97%90-%EC%84%A4%EC%B9%98%ED%95%A0-%EB%95%8C-%EC%A3%BC%EC%9D%98-%EC%82%AC%ED%95%AD"><i class="fa fa-check"></i><b>1.2.1</b> <strong>R</strong>을 윈도우즈에 설치할 때 주의 사항</a></li>
<li class="chapter" data-level="1.2.2" data-path="ch-intro.html"><a href="ch-intro.html#winget"><i class="fa fa-check"></i><b>1.2.2</b> <code>winget</code> 명령어로 설치하기</a></li>
<li class="chapter" data-level="1.2.3" data-path="R-linear-regression.html"><a href="#r-%EB%B0%B0%ED%8F%AC%ED%8C%90-%EB%82%B4%EB%A0%A4%EB%B0%9B%EA%B8%B0"><i class="fa fa-check"></i><b>1.2.3</b> <strong>R</strong> 배포판 내려받기</a></li>
<li class="chapter" data-level="1.2.4" data-path="R-linear-regression.html"><a href="#r-%EC%84%A4%EC%B9%98%ED%95%98%EA%B8%B0"><i class="fa fa-check"></i><b>1.2.4</b> R 설치하기</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="ch-intro.html"><a href="ch-intro.html#sec-RStudio"><i class="fa fa-check"></i><b>1.3</b> RStudio</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="R-linear-regression.html"><a href="#winget%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%9C-rstudio-%EC%84%A4%EC%B9%98"><i class="fa fa-check"></i><b>1.3.1</b> <code>winget</code>을 이용한 RStudio 설치</a></li>
<li class="chapter" data-level="1.3.2" data-path="R-linear-regression.html"><a href="#rstudio-%EC%84%A4%EC%B9%98"><i class="fa fa-check"></i><b>1.3.2</b> RStudio 설치</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="ch-intro.html"><a href="ch-intro.html#sec-R-start"><i class="fa fa-check"></i><b>1.4</b> RStudio로 R 시작하기</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="R-linear-regression.html"><a href="#r-%EC%BD%98%EC%86%94%EA%B3%BC-%ED%94%84%EB%A1%AC%ED%94%84%ED%8A%B8"><i class="fa fa-check"></i><b>1.4.1</b> R 콘솔과 프롬프트</a></li>
<li class="chapter" data-level="1.4.2" data-path="R-linear-regression.html"><a href="#r-%EC%BD%98%EC%86%94-%EC%82%AC%EC%9A%A9%EA%B3%BC-%EA%B4%80%EB%A0%A8%EB%90%9C-%EB%AA%87-%EA%B0%80%EC%A7%80-%ED%8C%81"><i class="fa fa-check"></i><b>1.4.2</b> R 콘솔 사용과 관련된 몇 가지 팁</a></li>
<li class="chapter" data-level="1.4.3" data-path="R-linear-regression.html"><a href="#r-%EC%8A%A4%ED%81%AC%EB%A6%BD%ED%8A%B8-%ED%8C%8C%EC%9D%BC-%EB%A7%8C%EB%93%A4%EA%B8%B0"><i class="fa fa-check"></i><b>1.4.3</b> R 스크립트 파일 만들기</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="ch-R-Data-Basic.html"><a href="ch-R-Data-Basic.html"><i class="fa fa-check"></i><b>2</b> R 데이터 기초</a>
<ul>
<li class="chapter" data-level="2.1" data-path="R-linear-regression.html"><a href="#%EB%8B%A8%EC%88%9C%ED%95%9C-%EB%8D%B0%EC%9D%B4%ED%84%B0-%ED%98%95%EC%8B%9D-data-types"><i class="fa fa-check"></i><b>2.1</b> 단순한 데이터 형식 (data types)</a></li>
<li class="chapter" data-level="2.2" data-path="R-linear-regression.html"><a href="#%EB%8B%A8%EC%88%9C-%EC%97%B0%EC%82%B0"><i class="fa fa-check"></i><b>2.2</b> 단순 연산</a></li>
<li class="chapter" data-level="2.3" data-path="R-linear-regression.html"><a href="#%EB%B3%80%EC%88%98%EC%99%80-%ED%95%A0%EB%8B%B9"><i class="fa fa-check"></i><b>2.3</b> 변수와 할당</a></li>
<li class="chapter" data-level="2.4" data-path="R-linear-regression.html"><a href="#%ED%95%A8%EC%88%98%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%9C-%EC%97%B0%EC%82%B0"><i class="fa fa-check"></i><b>2.4</b> 함수를 이용한 연산</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="ch-R-Vectors.html"><a href="ch-R-Vectors.html"><i class="fa fa-check"></i><b>3</b> <strong>R</strong> 벡터</a>
<ul>
<li class="chapter" data-level="3.1" data-path="R-linear-regression.html"><a href="#%EC%88%AB%EC%9E%90-%EB%B2%A1%ED%84%B0"><i class="fa fa-check"></i><b>3.1</b> 숫자 벡터</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="R-linear-regression.html"><a href="#c-%ED%95%A8%EC%88%98%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%9C-%EC%88%AB%EC%9E%90-%EB%B2%A1%ED%84%B0-%EB%A7%8C%EB%93%A4%EA%B8%B0"><i class="fa fa-check"></i><b>3.1.1</b> c() 함수를 이용한 숫자 벡터 만들기</a></li>
<li class="chapter" data-level="3.1.2" data-path="R-linear-regression.html"><a href="#%ED%8C%A8%ED%84%B4%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%9C-%EC%88%AB%EC%9E%90-%EB%B2%A1%ED%84%B0-%EB%A7%8C%EB%93%A4%EA%B8%B0"><i class="fa fa-check"></i><b>3.1.2</b> 패턴을 이용한 숫자 벡터 만들기</a></li>
<li class="chapter" data-level="3.1.3" data-path="R-linear-regression.html"><a href="#%EC%88%AB%EC%9E%90-%EB%B2%A1%ED%84%B0%EC%9D%98-%EC%97%B0%EC%82%B0"><i class="fa fa-check"></i><b>3.1.3</b> 숫자 벡터의 연산</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="R-linear-regression.html"><a href="#%EB%85%BC%EB%A6%AC-%EB%B2%A1%ED%84%B0"><i class="fa fa-check"></i><b>3.2</b> 논리 벡터</a></li>
<li class="chapter" data-level="3.3" data-path="R-linear-regression.html"><a href="#%EB%AC%B8%EC%9E%90-%EB%B2%A1%ED%84%B0"><i class="fa fa-check"></i><b>3.3</b> 문자 벡터</a></li>
<li class="chapter" data-level="3.4" data-path="R-linear-regression.html"><a href="#%EA%B2%B0%EC%B8%A1%EC%B9%98-missing-values"><i class="fa fa-check"></i><b>3.4</b> 결측치 (Missing Values)</a></li>
<li class="chapter" data-level="3.5" data-path="R-linear-regression.html"><a href="#%EC%9D%B8%EB%8D%B1%EC%8A%A4-%EB%B2%A1%ED%84%B0%EC%99%80-%ED%95%84%ED%84%B0%EB%A7%81"><i class="fa fa-check"></i><b>3.5</b> 인덱스 벡터와 필터링</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="R-linear-regression.html"><a href="#%EC%9E%90%EC%97%B0%EC%88%98-%EC%9D%B8%EB%8D%B1%EC%8A%A4-%EB%B2%A1%ED%84%B0"><i class="fa fa-check"></i><b>3.5.1</b> 자연수 인덱스 벡터</a></li>
<li class="chapter" data-level="3.5.2" data-path="R-linear-regression.html"><a href="#%EC%9D%8C%EC%9D%98-%EC%A0%95%EC%88%98-%EC%9D%B8%EB%8D%B1%EC%8A%A4-%EB%B2%A1%ED%84%B0"><i class="fa fa-check"></i><b>3.5.2</b> 음의 정수 인덱스 벡터</a></li>
<li class="chapter" data-level="3.5.3" data-path="R-linear-regression.html"><a href="#%EB%85%BC%EB%A6%AC-%EC%9D%B8%EB%8D%B1%EC%8A%A4-%EB%B2%A1%ED%84%B0"><i class="fa fa-check"></i><b>3.5.3</b> 논리 인덱스 벡터</a></li>
<li class="chapter" data-level="3.5.4" data-path="R-linear-regression.html"><a href="#%EC%9D%B4%EB%A6%84-%EC%9D%B8%EB%8D%B1%EC%8A%A4-%EB%B2%A1%ED%84%B0"><i class="fa fa-check"></i><b>3.5.4</b> 이름 인덱스 벡터</a></li>
<li class="chapter" data-level="3.5.5" data-path="R-linear-regression.html"><a href="#%EC%9D%B8%EB%8D%B1%EC%8A%A4-%EB%B2%A1%ED%84%B0%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%B4-%EB%B2%A1%ED%84%B0-%EC%9A%94%EC%86%8C%EC%97%90-%EA%B0%92-%ED%95%A0%EB%8B%B9%ED%95%98%EA%B8%B0"><i class="fa fa-check"></i><b>3.5.5</b> 인덱스 벡터를 이용해 벡터 요소에 값 할당하기</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="ch-R-Matrix.html"><a href="ch-R-Matrix.html"><i class="fa fa-check"></i><b>4</b> <strong>R</strong> 행렬</a>
<ul>
<li class="chapter" data-level="4.1" data-path="R-linear-regression.html"><a href="#%ED%96%89%EB%A0%AC-%EB%A7%8C%EB%93%A4%EA%B8%B0"><i class="fa fa-check"></i><b>4.1</b> 행렬 만들기</a></li>
<li class="chapter" data-level="4.2" data-path="R-linear-regression.html"><a href="#%EB%B2%A1%ED%84%B0%EB%A5%BC-%EA%B2%B0%ED%95%A9%ED%95%98%EC%97%AC-%ED%96%89%EB%A0%AC-%EB%A7%8C%EB%93%A4%EA%B8%B0"><i class="fa fa-check"></i><b>4.2</b> 벡터를 결합하여 행렬 만들기</a></li>
<li class="chapter" data-level="4.3" data-path="R-linear-regression.html"><a href="#%ED%96%89%EB%A0%AC%EC%9D%98-%ED%95%84%ED%84%B0%EB%A7%81"><i class="fa fa-check"></i><b>4.3</b> 행렬의 필터링</a></li>
<li class="chapter" data-level="4.4" data-path="R-linear-regression.html"><a href="#%ED%96%89%EB%A0%AC%EC%9D%98-%EC%97%B0%EC%82%B0"><i class="fa fa-check"></i><b>4.4</b> 행렬의 연산</a></li>
<li class="chapter" data-level="4.5" data-path="R-linear-regression.html"><a href="#%ED%96%89%EB%A0%AC%EA%B3%BC-%ED%95%A8%EC%88%98"><i class="fa fa-check"></i><b>4.5</b> 행렬과 함수</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="R-linear-regression.html"><a href="#%ED%96%89%EB%A0%AC%EC%9D%84-%EC%9D%B8%EC%88%98%EB%A1%9C-%ED%95%98%EB%8A%94-%ED%95%A8%EC%88%98%EB%93%A4"><i class="fa fa-check"></i><b>4.5.1</b> 행렬을 인수로 하는 함수들</a></li>
<li class="chapter" data-level="4.5.2" data-path="R-linear-regression.html"><a href="#%ED%96%89%EB%A0%AC%EC%9D%98-%ED%96%89%EB%B3%84-%EB%98%90%EB%8A%94-%EC%97%B4%EB%B3%84%EB%A1%9C-%ED%95%A8%EC%88%98%EB%A5%BC-%EC%A0%81%EC%9A%A9%ED%95%98%EB%8A%94-%EB%B0%A9%EB%B2%95"><i class="fa fa-check"></i><b>4.5.2</b> 행렬의 행별 또는 열별로 함수를 적용하는 방법</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="ch-R-Matrix.html"><a href="ch-R-Matrix.html#sec-RMatrix-array"><i class="fa fa-check"></i><b>4.6</b> 배열 *</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="R-linear-regression.html"><a href="#%EB%B0%B0%EC%97%B4%EC%9D%98-%EC%83%9D%EC%84%B1"><i class="fa fa-check"></i><b>4.6.1</b> 배열의 생성</a></li>
<li class="chapter" data-level="4.6.2" data-path="R-linear-regression.html"><a href="#%EB%B0%B0%EC%97%B4%EB%8F%84-%EA%B2%B0%EA%B5%AD-%EB%B2%A1%ED%84%B0"><i class="fa fa-check"></i><b>4.6.2</b> 배열도 결국 벡터</a></li>
<li class="chapter" data-level="4.6.3" data-path="R-linear-regression.html"><a href="#%EB%B0%B0%EC%97%B4%EC%9D%98-%EC%97%B0%EC%82%B0%EA%B3%BC-%ED%95%84%ED%84%B0%EB%A7%81"><i class="fa fa-check"></i><b>4.6.3</b> 배열의 연산과 필터링</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="ch-R-Matrix.html"><a href="ch-R-Matrix.html#sec-RMatrix-operation-advanced"><i class="fa fa-check"></i><b>4.7</b> 행렬과 배열의 고급 연산 *</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="R-linear-regression.html"><a href="#%ED%96%89%EB%A0%AC%EC%9D%98-%EA%B3%B1"><i class="fa fa-check"></i><b>4.7.1</b> 행렬의 곱</a></li>
<li class="chapter" data-level="4.7.2" data-path="R-linear-regression.html"><a href="#%ED%96%89%EB%A0%AC%EC%9D%98-%EC%A3%BC%EB%8C%80%EA%B0%81%EC%84%A0-%EC%9A%94%EC%86%8C%EC%99%80-%EB%8C%80%EA%B0%81%ED%96%89%EB%A0%AC"><i class="fa fa-check"></i><b>4.7.2</b> 행렬의 주대각선 요소와 대각행렬</a></li>
<li class="chapter" data-level="4.7.3" data-path="R-linear-regression.html"><a href="#%EC%97%B0%EB%A6%BD-%EC%9D%BC%EC%B0%A8-%EB%B0%A9%EC%A0%95%EC%8B%9D%EA%B3%BC-%EC%97%AD%ED%96%89%EB%A0%AC"><i class="fa fa-check"></i><b>4.7.3</b> 연립 일차 방정식과 역행렬</a></li>
<li class="chapter" data-level="4.7.4" data-path="R-linear-regression.html"><a href="#%EA%B3%A0%EC%9C%A0%EC%B9%98eigenvalues%EC%99%80-%EA%B3%A0%EC%9C%A0%EB%B2%A1%ED%84%B0eigenvectors"><i class="fa fa-check"></i><b>4.7.4</b> 고유치(eigenvalues)와 고유벡터(eigenvectors)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="ch-R-List.html"><a href="ch-R-List.html"><i class="fa fa-check"></i><b>5</b> <strong>R</strong> 리스트</a>
<ul>
<li class="chapter" data-level="5.1" data-path="R-linear-regression.html"><a href="#%EA%B0%9D%EC%B2%B4-%EA%B0%9D%EC%B2%B4%EC%9D%98-%ED%83%80%EC%9E%85-%EA%B0%9D%EC%B2%B4%EC%9D%98-%EC%86%8D%EC%84%B1"><i class="fa fa-check"></i><b>5.1</b> 객체, 객체의 타입, 객체의 속성 *</a></li>
<li class="chapter" data-level="5.2" data-path="R-linear-regression.html"><a href="#%EB%A6%AC%EC%8A%A4%ED%8A%B8%EC%9D%98-%EC%83%9D%EC%84%B1-%EB%B0%8F-%ED%95%84%ED%84%B0%EB%A7%81"><i class="fa fa-check"></i><b>5.2</b> 리스트의 생성 및 필터링</a></li>
<li class="chapter" data-level="5.3" data-path="R-linear-regression.html"><a href="#%EB%A6%AC%EC%8A%A4%ED%8A%B8%EC%9D%98-%EB%B3%80%EA%B2%BD-%EB%B0%8F-%EC%97%B0%EA%B2%B0"><i class="fa fa-check"></i><b>5.3</b> 리스트의 변경 및 연결</a></li>
<li class="chapter" data-level="5.4" data-path="R-linear-regression.html"><a href="#%EB%A6%AC%EC%8A%A4%ED%8A%B8%EC%97%90-%ED%95%A8%EC%88%98-%EC%A0%81%EC%9A%A9%ED%95%98%EA%B8%B0"><i class="fa fa-check"></i><b>5.4</b> 리스트에 함수 적용하기</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="R-linear-regression.html"><a href="#lapply-%ED%95%A8%EC%88%98"><i class="fa fa-check"></i><b>5.4.1</b> lapply() 함수</a></li>
<li class="chapter" data-level="5.4.2" data-path="R-linear-regression.html"><a href="#sapply-%ED%95%A8%EC%88%98"><i class="fa fa-check"></i><b>5.4.2</b> sapply() 함수</a></li>
<li class="chapter" data-level="5.4.3" data-path="R-linear-regression.html"><a href="#mapply-%ED%95%A8%EC%88%98"><i class="fa fa-check"></i><b>5.4.3</b> mapply() 함수</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="R-linear-regression.html"><a href="#%EB%A6%AC%EC%8A%A4%ED%8A%B8-%ED%99%9C%EC%9A%A9-%EB%B6%84%EC%95%BC"><i class="fa fa-check"></i><b>5.5</b> 리스트 활용 분야</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="ch-R-Data-Frame.html"><a href="ch-R-Data-Frame.html"><i class="fa fa-check"></i><b>6</b> <strong>R</strong> 데이터 프레임</a>
<ul>
<li class="chapter" data-level="6.1" data-path="R-linear-regression.html"><a href="#%EB%B2%94%EC%A3%BC%ED%98%95-%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%99%80-%EC%9A%94%EC%9D%B8-factors"><i class="fa fa-check"></i><b>6.1</b> 범주형 데이터와 요인 (Factors)</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="R-linear-regression.html"><a href="#%EB%AA%85%EB%AA%A9%ED%98%95-%EB%B3%80%EC%88%98%EC%99%80-%EC%9A%94%EC%9D%B8"><i class="fa fa-check"></i><b>6.1.1</b> 명목형 변수와 요인</a></li>
<li class="chapter" data-level="6.1.2" data-path="R-linear-regression.html"><a href="#%EC%88%9C%EC%84%9C%ED%98%95-%EB%B3%80%EC%88%98%EC%99%80-%EC%9A%94%EC%9D%B8"><i class="fa fa-check"></i><b>6.1.2</b> 순서형 변수와 요인</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="R-linear-regression.html"><a href="#%EB%8D%B0%EC%9D%B4%ED%84%B0-%ED%94%84%EB%A0%88%EC%9E%84-%EB%A7%8C%EB%93%A4%EA%B8%B0"><i class="fa fa-check"></i><b>6.2</b> 데이터 프레임 만들기</a></li>
<li class="chapter" data-level="6.3" data-path="R-linear-regression.html"><a href="#%EB%8D%B0%EC%9D%B4%ED%84%B0-%ED%94%84%EB%A0%88%EC%9E%84-%EA%B0%81-%EC%97%B4%EC%9D%98-%EC%A7%80%EC%A0%95"><i class="fa fa-check"></i><b>6.3</b> 데이터 프레임 각 열의 지정</a></li>
<li class="chapter" data-level="6.4" data-path="R-linear-regression.html"><a href="#%EB%8D%B0%EC%9D%B4%ED%84%B0-%ED%94%84%EB%A0%88%EC%9E%84%EC%9D%98-%ED%95%84%ED%84%B0%EB%A7%81"><i class="fa fa-check"></i><b>6.4</b> 데이터 프레임의 필터링</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="R-linear-regression.html"><a href="#%EB%A6%AC%EC%8A%A4%ED%8A%B8-%ED%98%95%EC%8B%9D%EC%9C%BC%EB%A1%9C-%ED%95%84%ED%84%B0%EB%A7%81"><i class="fa fa-check"></i><b>6.4.1</b> 리스트 형식으로 필터링</a></li>
<li class="chapter" data-level="6.4.2" data-path="R-linear-regression.html"><a href="#%ED%96%89%EB%A0%AC-%ED%98%95%EC%8B%9D%EC%9C%BC%EB%A1%9C-%ED%95%84%ED%84%B0%EB%A7%81"><i class="fa fa-check"></i><b>6.4.2</b> 행렬 형식으로 필터링</a></li>
<li class="chapter" data-level="6.4.3" data-path="R-linear-regression.html"><a href="#subset%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%9C-%ED%95%84%ED%84%B0%EB%A7%81"><i class="fa fa-check"></i><b>6.4.3</b> subset()을 이용한 필터링</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="R-linear-regression.html"><a href="#%EB%8D%B0%EC%9D%B4%ED%84%B0-%ED%94%84%EB%A0%88%EC%9E%84%EC%97%90-%ED%95%A8%EC%88%98-%EC%A0%81%EC%9A%A9%ED%95%98%EA%B8%B0"><i class="fa fa-check"></i><b>6.5</b> 데이터 프레임에 함수 적용하기</a></li>
<li class="chapter" data-level="6.6" data-path="ch-R-Data-Frame.html"><a href="ch-R-Data-Frame.html#sec-read-file"><i class="fa fa-check"></i><b>6.6</b> 파일에서 데이터 읽어오기</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="R-linear-regression.html"><a href="#%ED%85%8D%EC%8A%A4%ED%8A%B8-%ED%8C%8C%EC%9D%BC%EC%97%90%EC%84%9C-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%9D%BD%EC%96%B4%EC%98%A4%EA%B8%B0"><i class="fa fa-check"></i><b>6.6.1</b> 텍스트 파일에서 데이터 읽어오기</a></li>
<li class="chapter" data-level="6.6.2" data-path="R-linear-regression.html"><a href="#csv-%ED%8C%8C%EC%9D%BC%EC%97%90%EC%84%9C-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%9D%BD%EC%96%B4%EC%98%A4%EA%B8%B0"><i class="fa fa-check"></i><b>6.6.2</b> CSV 파일에서 데이터 읽어오기</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="ch-R-Data-Frame.html"><a href="ch-R-Data-Frame.html#sec-write-file"><i class="fa fa-check"></i><b>6.7</b> 데이터 프레임을 파일로 쓰기</a>
<ul>
<li class="chapter" data-level="6.7.1" data-path="R-linear-regression.html"><a href="#%EB%B0%94%EC%9D%B4%EB%84%88%EB%A6%AC-%ED%98%95%EC%8B%9D%EC%9C%BC%EB%A1%9C-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EA%B0%9D%EC%B2%B4-%EC%A0%80%EC%9E%A5-%EB%B0%8F-%EB%B3%B5%EC%9B%90"><i class="fa fa-check"></i><b>6.7.1</b> 바이너리 형식으로 데이터 객체 저장 및 복원</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="R-linear-regression.html"><a href="#%EB%8D%B0%EC%9D%B4%ED%84%B0-%ED%94%84%EB%A0%88%EC%9E%84%EC%9D%98-%EC%97%B4%EC%9D%84-%EB%B3%80%EC%88%98%EC%B2%98%EB%9F%BC-%EC%9D%B4%EC%9A%A9%ED%95%98%EB%8A%94-%EB%B0%A9%EB%B2%95"><i class="fa fa-check"></i><b>6.8</b> 데이터 프레임의 열을 변수처럼 이용하는 방법 *</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="ch-dataTransformation.html"><a href="ch-dataTransformation.html"><i class="fa fa-check"></i><b>7</b> dplyr을 이용한 데이터 변환</a>
<ul>
<li class="chapter" data-level="7.1" data-path="ch-dataTransformation.html"><a href="ch-dataTransformation.html#sec-tidyData"><i class="fa fa-check"></i><b>7.1</b> 정돈 데이터 (tidy data)</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="R-linear-regression.html"><a href="#%EC%A0%95%EB%8F%88-%EB%8D%B0%EC%9D%B4%ED%84%B0-%ED%98%95%EC%8B%9D%EC%9D%98-%EC%A1%B0%EA%B1%B4"><i class="fa fa-check"></i><b>7.1.1</b> 정돈 데이터 형식의 조건</a></li>
<li class="chapter" data-level="7.1.2" data-path="R-linear-regression.html"><a href="#%EB%B9%84%EC%A0%95%EB%8F%88-%EB%8D%B0%EC%9D%B4%ED%84%B0-%ED%98%95%EC%8B%9D"><i class="fa fa-check"></i><b>7.1.2</b> 비정돈 데이터 형식</a></li>
<li class="chapter" data-level="7.1.3" data-path="R-linear-regression.html"><a href="#%EC%A0%95%EB%8F%88-%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A5%BC-%EC%82%AC%EC%9A%A9%ED%95%98%EB%8A%94-%EC%9D%B4%EC%9C%A0"><i class="fa fa-check"></i><b>7.1.3</b> 정돈 데이터를 사용하는 이유</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="R-linear-regression.html"><a href="#tidyverse-%ED%8C%A8%ED%82%A4%EC%A7%80"><i class="fa fa-check"></i><b>7.2</b> <code>tidyverse</code> 패키지</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="R-linear-regression.html"><a href="#tidyverse-%ED%8C%A8%ED%82%A4%EC%A7%80-%EC%84%A4%EC%B9%98"><i class="fa fa-check"></i><b>7.2.1</b> <code>tidyverse</code> 패키지 설치</a></li>
<li class="chapter" data-level="7.2.2" data-path="R-linear-regression.html"><a href="#tidyverse-%ED%8C%A8%ED%82%A4%EC%A7%80-%EC%A0%81%EC%9E%AC"><i class="fa fa-check"></i><b>7.2.2</b> <code>tidyverse</code> 패키지 적재</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="ch-dataTransformation.html"><a href="ch-dataTransformation.html#sec-dplyr"><i class="fa fa-check"></i><b>7.3</b> <code>dplyr</code> 패키지와 정돈 데이터의 변환</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="R-linear-regression.html"><a href="#dplyr-%ED%8C%A8%ED%82%A4%EC%A7%80"><i class="fa fa-check"></i><b>7.3.1</b> <code>dplyr</code> 패키지</a></li>
<li class="chapter" data-level="7.3.2" data-path="R-linear-regression.html"><a href="#%EC%A0%95%EB%8F%88-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%B3%80%ED%99%98%EC%9D%98-%EC%A2%85%EB%A5%98"><i class="fa fa-check"></i><b>7.3.2</b> 정돈 데이터 변환의 종류</a></li>
<li class="chapter" data-level="7.3.3" data-path="R-linear-regression.html"><a href="#dplyr-%ED%8C%A8%ED%82%A4%EC%A7%80-vs.-r%EC%9D%98-%EA%B8%B0%EB%B3%B8-%EA%B8%B0%EB%8A%A5"><i class="fa fa-check"></i><b>7.3.3</b> <code>dplyr</code> 패키지 vs. R의 기본 기능</a></li>
<li class="chapter" data-level="7.3.4" data-path="R-linear-regression.html"><a href="#mpg-%EB%8D%B0%EC%9D%B4%ED%84%B0"><i class="fa fa-check"></i><b>7.3.4</b> <code>mpg</code> 데이터</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="ch-dataTransformation.html"><a href="ch-dataTransformation.html#sec-filter"><i class="fa fa-check"></i><b>7.4</b> <code>filter()</code>로 행 선택하기</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="R-linear-regression.html"><a href="#%EC%84%A0%ED%83%9D-%EC%A1%B0%EA%B1%B4%EC%9D%B4-%ED%95%98%EB%82%98%EC%9D%B8-%EA%B2%BD%EC%9A%B0"><i class="fa fa-check"></i><b>7.4.1</b> 선택 조건이 하나인 경우</a></li>
<li class="chapter" data-level="7.4.2" data-path="R-linear-regression.html"><a href="#%EC%97%AC%EB%9F%AC-%EC%A1%B0%EA%B1%B4%EC%9D%84-%EB%A7%8C%EC%A1%B1%ED%95%98%EB%8A%94-%ED%96%89-%EC%B6%94%EC%B6%9C%ED%95%98%EA%B8%B0"><i class="fa fa-check"></i><b>7.4.2</b> 여러 조건을 만족하는 행 추출하기</a></li>
<li class="chapter" data-level="7.4.3" data-path="R-linear-regression.html"><a href="#%EB%85%BC%EB%A6%AC-%EC%97%B0%EC%82%B0%EC%9E%90%EB%A1%9C-%EB%B3%B5%ED%95%A9-%EC%A1%B0%EA%B1%B4-%EB%A7%8C%EB%93%A4%EA%B8%B0"><i class="fa fa-check"></i><b>7.4.3</b> 논리 연산자로 복합 조건 만들기</a></li>
<li class="chapter" data-level="7.4.4" data-path="R-linear-regression.html"><a href="#in-%EC%97%B0%EC%82%B0%EC%9E%90"><i class="fa fa-check"></i><b>7.4.4</b> <code>%in%</code> 연산자</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="ch-dataTransformation.html"><a href="ch-dataTransformation.html#sec-slice"><i class="fa fa-check"></i><b>7.5</b> <code>slice()</code>로 행 선택하기</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="R-linear-regression.html"><a href="#slice_sample%EB%A1%9C-%ED%91%9C%EB%B3%B8-%EC%B6%94%EC%B6%9C%ED%95%98%EA%B8%B0"><i class="fa fa-check"></i><b>7.5.1</b> <code>slice_sample()</code>로 표본 추출하기</a></li>
<li class="chapter" data-level="7.5.2" data-path="R-linear-regression.html"><a href="#slice_head%EC%99%80-slice_tail"><i class="fa fa-check"></i><b>7.5.2</b> <code>slice_head()</code>와 <code>slice_tail()</code></a></li>
<li class="chapter" data-level="7.5.3" data-path="R-linear-regression.html"><a href="#slice_min%EA%B3%BC-slice_max"><i class="fa fa-check"></i><b>7.5.3</b> <code>slice_min()</code>과 <code>slice_max()</code></a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="ch-dataTransformation.html"><a href="ch-dataTransformation.html#sec-arrange"><i class="fa fa-check"></i><b>7.6</b> <code>arrange()</code>로 행 정렬하기</a>
<ul>
<li class="chapter" data-level="7.6.1" data-path="R-linear-regression.html"><a href="#desc%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%98%EC%97%AC-%EB%82%B4%EB%A6%BC%EC%B0%A8%EC%88%9C%EC%9C%BC%EB%A1%9C-%EC%A0%95%EB%A0%AC%ED%95%98%EA%B8%B0"><i class="fa fa-check"></i><b>7.6.1</b> <code>desc()</code>를 이용하여 내림차순으로 정렬하기</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="ch-dataTransformation.html"><a href="ch-dataTransformation.html#sec-select"><i class="fa fa-check"></i><b>7.7</b> <code>select()</code>를 이용하여 변수 이름으로 열 선택하기</a>
<ul>
<li class="chapter" data-level="7.7.1" data-path="R-linear-regression.html"><a href="#%EB%B3%80%EC%88%98-%EC%9D%B4%EB%A6%84%EC%9D%84-%EB%82%98%EC%97%B4%ED%95%98%EC%97%AC-%EC%84%A0%ED%83%9D%ED%95%98%EA%B8%B0"><i class="fa fa-check"></i><b>7.7.1</b> 변수 이름을 나열하여 선택하기</a></li>
<li class="chapter" data-level="7.7.2" data-path="R-linear-regression.html"><a href="#%EB%B3%80%EC%88%98-%EC%9D%B4%EB%A6%84%EC%9C%BC%EB%A1%9C-%EB%B3%80%EC%88%98-%EB%B2%94%EC%9C%84%EB%A5%BC-%EC%84%A0%ED%83%9D%ED%95%98%EA%B8%B0"><i class="fa fa-check"></i><b>7.7.2</b> 변수 이름으로 변수 범위를 선택하기</a></li>
<li class="chapter" data-level="7.7.3" data-path="R-linear-regression.html"><a href="#%EB%B3%80%EC%88%98-%EC%9C%84%EC%B9%98%EB%A1%9C-%EB%A7%A4%EC%B9%AD%ED%95%98%EC%97%AC-%EC%84%A0%ED%83%9D%ED%95%98%EA%B8%B0"><i class="fa fa-check"></i><b>7.7.3</b> 변수 위치로 매칭하여 선택하기</a></li>
<li class="chapter" data-level="7.7.4" data-path="ch-dataTransformation.html"><a href="ch-dataTransformation.html#sec-select-match"><i class="fa fa-check"></i><b>7.7.4</b> 변수 이름을 매칭하여 선택하기</a></li>
<li class="chapter" data-level="7.7.5" data-path="R-linear-regression.html"><a href="#%EB%B3%80%EC%88%98%EC%9D%98-%ED%98%95%EC%8B%9D%EC%9D%B4%EB%82%98-%EC%A1%B0%EA%B1%B4%EC%9C%BC%EB%A1%9C-%EB%A7%A4%EC%B9%AD%ED%95%98%EC%97%AC-%EC%84%A0%ED%83%9D%ED%95%98%EA%B8%B0"><i class="fa fa-check"></i><b>7.7.5</b> 변수의 형식이나 조건으로 매칭하여 선택하기*</a></li>
<li class="chapter" data-level="7.7.6" data-path="R-linear-regression.html"><a href="#%EB%B3%80%EC%88%98-%EC%9D%B4%EB%A6%84-%EB%B0%94%EA%BE%B8%EA%B8%B0"><i class="fa fa-check"></i><b>7.7.6</b> 변수 이름 바꾸기</a></li>
<li class="chapter" data-level="7.7.7" data-path="R-linear-regression.html"><a href="#%EB%B3%80%EC%88%98-%EC%88%9C%EC%84%9C-%EB%B0%94%EA%BE%B8%EA%B8%B0"><i class="fa fa-check"></i><b>7.7.7</b> 변수 순서 바꾸기</a></li>
</ul></li>
<li class="chapter" data-level="7.8" data-path="ch-dataTransformation.html"><a href="ch-dataTransformation.html#sec-mutate"><i class="fa fa-check"></i><b>7.8</b> <code>mutate()</code>로 새로운 변수 만들기</a>
<ul>
<li class="chapter" data-level="7.8.1" data-path="R-linear-regression.html"><a href="#transmute%EB%A1%9C-%EC%83%88%EB%A1%9C%EC%9A%B4-%EB%B3%80%EC%88%98%EB%A7%8C-%EB%82%A8%EA%B8%B0%EA%B8%B0"><i class="fa fa-check"></i><b>7.8.1</b> <code>transmute()</code>로 새로운 변수만 남기기</a></li>
<li class="chapter" data-level="7.8.2" data-path="R-linear-regression.html"><a href="#%EC%83%88%EB%A1%9C%EC%9A%B4-%EB%B3%80%EC%88%98%EB%A5%BC-%EB%A7%8C%EB%93%A4-%EB%95%8C-%EC%82%AC%EC%9A%A9%ED%95%A0-%EC%88%98-%EC%9E%88%EB%8A%94-%ED%95%A8%EC%88%98%EB%93%A4"><i class="fa fa-check"></i><b>7.8.2</b> 새로운 변수를 만들 때 사용할 수 있는 함수들</a></li>
</ul></li>
<li class="chapter" data-level="7.9" data-path="ch-dataTransformation.html"><a href="ch-dataTransformation.html#sec-summarize"><i class="fa fa-check"></i><b>7.9</b> <code>summarize()</code>로 변수 요약하기</a>
<ul>
<li class="chapter" data-level="7.9.1" data-path="R-linear-regression.html"><a href="#across%EB%A1%9C-%EC%97%AC%EB%A0%A4-%EB%B3%80%EC%88%98%EB%A5%BC-%EC%9A%94%EC%95%BD%ED%95%98%EA%B8%B0"><i class="fa fa-check"></i><b>7.9.1</b> <code>across()</code>로 여려 변수를 요약하기*</a></li>
</ul></li>
<li class="chapter" data-level="7.10" data-path="ch-dataTransformation.html"><a href="ch-dataTransformation.html#sec-groupBy"><i class="fa fa-check"></i><b>7.10</b> <code>group_by()</code>로 그룹별로 요약하기</a>
<ul>
<li class="chapter" data-level="7.10.1" data-path="R-linear-regression.html"><a href="#group_by%EB%A1%9C-%EA%B7%B8%EB%A3%B9%EB%B3%84%EB%A1%9C-%EC%83%88-%EB%B3%80%EC%88%98-%EC%B6%94%EA%B0%80%ED%95%98%EA%B8%B0"><i class="fa fa-check"></i><b>7.10.1</b> <code>group_by()</code>로 그룹별로 새 변수 추가하기</a></li>
<li class="chapter" data-level="7.10.2" data-path="R-linear-regression.html"><a href="#count%EB%A1%9C-%EA%B0%9C%EC%88%98-%EC%84%B8%EA%B8%B0"><i class="fa fa-check"></i><b>7.10.2</b> <code>count()</code>로 개수 세기</a></li>
</ul></li>
<li class="chapter" data-level="7.11" data-path="ch-dataTransformation.html"><a href="ch-dataTransformation.html#sec-pipeOperator"><i class="fa fa-check"></i><b>7.11</b> <code>%&gt;%</code> 파이프 연산자</a>
<ul>
<li class="chapter" data-level="7.11.1" data-path="R-linear-regression.html"><a href="#%EC%97%AC%EB%9F%AC-%EB%8B%A8%EA%B3%84%EB%A5%BC-%EA%B1%B0%EC%B3%90-%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A5%BC-%EB%B3%80%ED%99%98%ED%95%A0-%EB%95%8C"><i class="fa fa-check"></i><b>7.11.1</b> 여러 단계를 거쳐 데이터를 변환할 때</a></li>
<li class="chapter" data-level="7.11.2" data-path="R-linear-regression.html"><a href="#%ED%8C%8C%EC%9D%B4%ED%94%84-%EC%97%B0%EC%82%B0%EC%9E%90"><i class="fa fa-check"></i><b>7.11.2</b> 파이프 연산자</a></li>
<li class="chapter" data-level="7.11.3" data-path="ch-dataTransformation.html"><a href="ch-dataTransformation.html#ungroup"><i class="fa fa-check"></i><b>7.11.3</b> <code>ungroup()</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="ch-visualization.html"><a href="ch-visualization.html"><i class="fa fa-check"></i><b>8</b> ggplot2를 이용한 데이터 시각화</a>
<ul>
<li class="chapter" data-level="8.1" data-path="ch-visualization.html"><a href="ch-visualization.html#sec-getStarted-ggplot2"><i class="fa fa-check"></i><b>8.1</b> ggplot2 시작하기</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="ch-visualization.html"><a href="ch-visualization.html#subsec-tryGgplot"><i class="fa fa-check"></i><b>8.1.1</b> ggplot2 그래프 그려보기</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="ch-visualization.html"><a href="ch-visualization.html#sec-aesMapping"><i class="fa fa-check"></i><b>8.2</b> 도형의 속성에 데이터 열을 대응시키기 (aesthetic mapping)</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="R-linear-regression.html"><a href="#%EB%B2%94%EC%A3%BC%ED%98%95-%EB%B3%80%EC%88%98%EB%A5%BC-%EC%83%89%EC%83%81color-%EC%86%8D%EC%84%B1%EC%97%90-%EB%A7%A4%ED%95%91%ED%95%98%EA%B8%B0"><i class="fa fa-check"></i><b>8.2.1</b> 범주형 변수를 색상(<code>color</code>) 속성에 매핑하기</a></li>
<li class="chapter" data-level="8.2.2" data-path="R-linear-regression.html"><a href="#%EB%B2%94%EC%A3%BC%ED%98%95-%EB%B3%80%EC%88%98%EB%A5%BC-%EB%AA%A8%EC%96%91shape-%EC%86%8D%EC%84%B1%EC%97%90-%EB%A7%A4%ED%95%91%ED%95%98%EA%B8%B0"><i class="fa fa-check"></i><b>8.2.2</b> 범주형 변수를 모양(<code>shape</code>) 속성에 매핑하기</a></li>
<li class="chapter" data-level="8.2.3" data-path="R-linear-regression.html"><a href="#%EC%97%B0%EC%86%8D%ED%98%95-%EB%B3%80%EC%88%98%EB%A5%BC-%ED%81%AC%EA%B8%B0size-%ED%88%AC%EB%AA%85%EB%8F%84alpha-%EC%83%89%EC%83%81color-%EC%86%8D%EC%84%B1%EC%97%90-%EB%A7%A4%ED%95%91%ED%95%98%EA%B8%B0"><i class="fa fa-check"></i><b>8.2.3</b> 연속형 변수를 크기(<code>size</code>), 투명도(<code>alpha</code>), 색상(<code>color</code>) 속성에 매핑하기</a></li>
<li class="chapter" data-level="8.2.4" data-path="R-linear-regression.html"><a href="#%EB%8F%84%ED%98%95%EC%9D%98-%EC%97%AC%EB%9F%AC-%EC%86%8D%EC%84%B1%EC%97%90-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%97%B4%EC%9D%84-%EB%A7%A4%ED%95%91%EC%8B%9C%ED%82%A4%EA%B8%B0"><i class="fa fa-check"></i><b>8.2.4</b> 도형의 여러 속성에 데이터 열을 매핑시키기</a></li>
<li class="chapter" data-level="8.2.5" data-path="R-linear-regression.html"><a href="#%EB%8F%84%ED%98%95-%EC%86%8D%EC%84%B1%EC%97%90-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%97%B4%EC%9D%84-%EB%A7%A4%ED%95%91%ED%95%98%EA%B8%B0---%EC%98%88%EC%A0%9C"><i class="fa fa-check"></i><b>8.2.5</b> 도형 속성에 데이터 열을 매핑하기 - 예제</a></li>
<li class="chapter" data-level="8.2.6" data-path="R-linear-regression.html"><a href="#%EB%8F%84%ED%98%95%EC%9D%98-%EC%86%8D%EC%84%B1%EC%97%90-%EB%8C%80%EC%9D%91%EC%8B%9C%ED%82%A4%EA%B8%B0-vs.-%EB%8F%84%ED%98%95%EC%9D%98-%EC%86%8D%EC%84%B1-%EC%9D%B8%EC%88%98%EB%A5%BC-%EC%84%A4%EC%A0%95%ED%95%98%EA%B8%B0"><i class="fa fa-check"></i><b>8.2.6</b> 도형의 속성에 대응시키기 vs. 도형의 속성 인수를 설정하기</a></li>
<li class="chapter" data-level="8.2.7" data-path="R-linear-regression.html"><a href="#group-%EC%86%8D%EC%84%B1"><i class="fa fa-check"></i><b>8.2.7</b> <code>group</code> 속성</a></li>
<li class="chapter" data-level="8.2.8" data-path="R-linear-regression.html"><a href="#%EA%B7%B8%EB%A3%B9%EC%9C%BC%EB%A1%9C-%EB%82%98%EB%88%84%EC%96%B4-%EC%84%A0-%EA%B7%B8%EB%9E%98%ED%94%84-%EA%B7%B8%EB%A6%AC%EA%B8%B0"><i class="fa fa-check"></i><b>8.2.8</b> 그룹으로 나누어 선 그래프 그리기</a></li>
<li class="chapter" data-level="8.2.9" data-path="R-linear-regression.html"><a href="#%EC%9D%B4%EC%82%B0%ED%98%95-%EB%B3%80%EC%88%98%EB%8A%94-group-%EC%86%8D%EC%84%B1%EC%9C%BC%EB%A1%9C-%EC%9E%90%EB%8F%99-%EB%A7%A4%ED%95%91%EB%90%9C%EB%8B%A4."><i class="fa fa-check"></i><b>8.2.9</b> 이산형 변수는 <code>group</code> 속성으로 자동 매핑된다.</a></li>
<li class="chapter" data-level="8.2.10" data-path="R-linear-regression.html"><a href="#geom_smooth-%ED%95%A8%EC%88%98%EC%97%90%EC%84%9C-group-%EC%86%8D%EC%84%B1"><i class="fa fa-check"></i><b>8.2.10</b> <code>geom_smooth()</code> 함수에서 <code>group</code> 속성</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="ch-visualization.html"><a href="ch-visualization.html#sec-facets"><i class="fa fa-check"></i><b>8.3</b> 측면(facets)으로 나누어 그리기</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="R-linear-regression.html"><a href="#facet_wrap%EB%A1%9C-%EC%9D%BC%EC%B0%A8%EC%9B%90-%EC%B8%A1%EB%A9%B4-%EA%B7%B8%EB%9E%98%ED%94%84-%EA%B7%B8%EB%A6%AC%EA%B8%B0"><i class="fa fa-check"></i><b>8.3.1</b> <code>facet_wrap()</code>로 일차원 측면 그래프 그리기</a></li>
<li class="chapter" data-level="8.3.2" data-path="R-linear-regression.html"><a href="#facet_grid%EB%A1%9C-%EC%9D%B4%EC%B0%A8%EC%9B%90-%EC%B8%A1%EB%A9%B4-%EA%B7%B8%EB%9E%98%ED%94%84-%EA%B7%B8%EB%A6%AC%EA%B8%B0"><i class="fa fa-check"></i><b>8.3.2</b> <code>facet_grid()</code>로 이차원 측면 그래프 그리기</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="ch-visualization.html"><a href="ch-visualization.html#sec-layerAndGeom"><i class="fa fa-check"></i><b>8.4</b> 그래프 계층(layers)과 도형(geoms)</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="R-linear-regression.html"><a href="#geom-%ED%95%A8%EC%88%98%EC%9D%98-%EC%88%9C%EC%84%9C%EC%99%80-%EA%B7%B8%EB%9E%98%ED%94%84-%EA%B3%84%EC%B8%B5"><i class="fa fa-check"></i><b>8.4.1</b> geom 함수의 순서와 그래프 계층</a></li>
<li class="chapter" data-level="8.4.2" data-path="R-linear-regression.html"><a href="#ggplot-%ED%95%A8%EC%88%98%EB%8A%94-%EC%A2%8C%ED%91%9C%EC%B6%95%EC%9D%84-%EC%9E%90%EB%8F%99-%EC%A1%B0%EC%A0%95%ED%95%9C%EB%8B%A4."><i class="fa fa-check"></i><b>8.4.2</b> <code>ggplot()</code> 함수는 좌표축을 자동 조정한다.</a></li>
<li class="chapter" data-level="8.4.3" data-path="R-linear-regression.html"><a href="#%EC%97%AC%EB%9F%AC-%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A5%BC-%EC%82%AC%EC%9A%A9%ED%95%98%EC%97%AC-%EA%B7%B8%EB%9E%98%ED%94%84-%EA%B3%84%EC%B8%B5-%EB%A7%8C%EB%93%A4%EA%B8%B0"><i class="fa fa-check"></i><b>8.4.3</b> 여러 데이터를 사용하여 그래프 계층 만들기</a></li>
<li class="chapter" data-level="8.4.4" data-path="R-linear-regression.html"><a href="#%EB%8B%A4%EB%A5%B8-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%B2%94%EC%9C%84%EB%A1%9C-%EA%B7%B8%EB%9E%98%ED%94%84-%EA%B3%84%EC%B8%B5-%EB%A7%8C%EB%93%A4%EA%B8%B0"><i class="fa fa-check"></i><b>8.4.4</b> 다른 데이터 범위로 그래프 계층 만들기</a></li>
<li class="chapter" data-level="8.4.5" data-path="ch-visualization.html"><a href="ch-visualization.html#subsec-commonDataMapping"><i class="fa fa-check"></i><b>8.4.5</b> 공통 <code>data</code>와 <code>mapping</code>의 설정</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="ch-visualization.html"><a href="ch-visualization.html#sec-commonProblems"><i class="fa fa-check"></i><b>8.5</b> ggplot 명령문을 입력할 때 자주 발생하는 문제들</a></li>
<li class="chapter" data-level="8.6" data-path="ch-visualization.html"><a href="ch-visualization.html#sec-ggplotStat"><i class="fa fa-check"></i><b>8.6</b> 통계 변환</a>
<ul>
<li class="chapter" data-level="8.6.1" data-path="ch-visualization.html"><a href="ch-visualization.html#subsec-statCategorical"><i class="fa fa-check"></i><b>8.6.1</b> 범주형 변수의 통계 요약</a></li>
<li class="chapter" data-level="8.6.2" data-path="ch-visualization.html"><a href="ch-visualization.html#subsec-statNumerical"><i class="fa fa-check"></i><b>8.6.2</b> 수치형 변수의 통계 요약</a></li>
<li class="chapter" data-level="8.6.3" data-path="ch-visualization.html"><a href="ch-visualization.html#subsec-statNumericalPerCategory"><i class="fa fa-check"></i><b>8.6.3</b> 수치형 변수의 범주별 통계요약</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="ch-visualization.html"><a href="ch-visualization.html#sec-position"><i class="fa fa-check"></i><b>8.7</b> 위치 조정</a></li>
<li class="chapter" data-level="8.8" data-path="ch-visualization.html"><a href="ch-visualization.html#sec-typeofgraph"><i class="fa fa-check"></i><b>8.8</b> ggplot2 그래프의 종류</a>
<ul>
<li class="chapter" data-level="8.8.1" data-path="ch-visualization.html"><a href="ch-visualization.html#basic-graph"><i class="fa fa-check"></i><b>8.8.1</b> 직선을 그리는 그래픽 함수</a></li>
<li class="chapter" data-level="8.8.2" data-path="ch-visualization.html"><a href="ch-visualization.html#onecategory"><i class="fa fa-check"></i><b>8.8.2</b> 한 범주형 변수의 그래프</a></li>
<li class="chapter" data-level="8.8.3" data-path="ch-visualization.html"><a href="ch-visualization.html#onenumeric"><i class="fa fa-check"></i><b>8.8.3</b> 한 수치형 변수의 그래프</a></li>
<li class="chapter" data-level="8.8.4" data-path="ch-visualization.html"><a href="ch-visualization.html#twocategories"><i class="fa fa-check"></i><b>8.8.4</b> 두 범주형 변수의 그래프</a></li>
<li class="chapter" data-level="8.8.5" data-path="ch-visualization.html"><a href="ch-visualization.html#category-numeric"><i class="fa fa-check"></i><b>8.8.5</b> 범주형 변수와 수치형 변수의 그래프</a></li>
<li class="chapter" data-level="8.8.6" data-path="ch-visualization.html"><a href="ch-visualization.html#twonumeric"><i class="fa fa-check"></i><b>8.8.6</b> 두 수치형 변수의 그래프</a></li>
<li class="chapter" data-level="8.8.7" data-path="ch-visualization.html"><a href="ch-visualization.html#morethanthree"><i class="fa fa-check"></i><b>8.8.7</b> 세 변수 이상의 그래프</a></li>
</ul></li>
<li class="chapter" data-level="8.9" data-path="ch-visualization.html"><a href="ch-visualization.html#modification"><i class="fa fa-check"></i><b>8.9</b> 그래프의 외양 바꾸기</a>
<ul>
<li class="chapter" data-level="8.9.1" data-path="ch-visualization.html"><a href="ch-visualization.html#axes"><i class="fa fa-check"></i><b>8.9.1</b> 좌표축의 조정</a></li>
<li class="chapter" data-level="8.9.2" data-path="R-linear-regression.html"><a href="#%EC%A2%8C%ED%91%9C%EA%B3%84%EC%9D%98-%EB%B3%80%EA%B2%BD"><i class="fa fa-check"></i><b>8.9.2</b> 좌표계의 변경</a></li>
<li class="chapter" data-level="8.9.3" data-path="R-linear-regression.html"><a href="#%EC%83%89%EC%83%81-%EC%B2%99%EB%8F%84color-scales%EC%9D%98-%EB%B3%80%EA%B2%BD"><i class="fa fa-check"></i><b>8.9.3</b> 색상 척도(color scales)의 변경</a></li>
<li class="chapter" data-level="8.9.4" data-path="ch-visualization.html"><a href="ch-visualization.html#labelsmodification"><i class="fa fa-check"></i><b>8.9.4</b> 레이블 조정</a></li>
<li class="chapter" data-level="8.9.5" data-path="ch-visualization.html"><a href="ch-visualization.html#themes"><i class="fa fa-check"></i><b>8.9.5</b> 테마 변경</a></li>
</ul></li>
<li class="chapter" data-level="8.10" data-path="ch-visualization.html"><a href="ch-visualization.html#misc"><i class="fa fa-check"></i><b>8.10</b> 기타 유용한 팁들</a>
<ul>
<li class="chapter" data-level="8.10.1" data-path="ch-visualization.html"><a href="ch-visualization.html#combinegraph"><i class="fa fa-check"></i><b>8.10.1</b> 여러 그래프를 한 도표에 넣기</a></li>
<li class="chapter" data-level="8.10.2" data-path="ch-visualization.html"><a href="ch-visualization.html#savegraph"><i class="fa fa-check"></i><b>8.10.2</b> 그래프 저장하기</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="ch-R-Advanced-Data-Mgmt.html"><a href="ch-R-Advanced-Data-Mgmt.html"><i class="fa fa-check"></i><b>9</b> R 고급 데이터 변환</a>
<ul>
<li class="chapter" data-level="9.1" data-path="ch-R-Advanced-Data-Mgmt.html"><a href="ch-R-Advanced-Data-Mgmt.html#sec-bind-data"><i class="fa fa-check"></i><b>9.1</b> 데이터의 단순 결합</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="R-linear-regression.html"><a href="#%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A5%BC-%ED%96%89%EC%9C%BC%EB%A1%9C-%EA%B2%B0%ED%95%A9%ED%95%98%EA%B8%B0"><i class="fa fa-check"></i><b>9.1.1</b> 데이터를 행으로 결합하기</a></li>
<li class="chapter" data-level="9.1.2" data-path="R-linear-regression.html"><a href="#%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A5%BC-%EC%97%B4%EB%A1%9C-%EA%B2%B0%ED%95%A9%ED%95%98%EA%B8%B0"><i class="fa fa-check"></i><b>9.1.2</b> 데이터를 열로 결합하기</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="R-linear-regression.html"><a href="#%EA%B4%80%EA%B3%84%ED%98%95-%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B2%A0%EC%9D%B4%EC%8A%A4%EC%B2%98%EB%9F%BC-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EA%B2%B0%ED%95%A9%ED%95%98%EA%B8%B0"><i class="fa fa-check"></i><b>9.2</b> 관계형 데이터베이스처럼 데이터 결합하기</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="R-linear-regression.html"><a href="#inner-join%EA%B3%BC-outer-join"><i class="fa fa-check"></i><b>9.2.1</b> Inner join과 outer join</a></li>
<li class="chapter" data-level="9.2.2" data-path="ch-R-Advanced-Data-Mgmt.html"><a href="ch-R-Advanced-Data-Mgmt.html#filtering-join"><i class="fa fa-check"></i><b>9.2.2</b> Filtering join</a></li>
<li class="chapter" data-level="9.2.3" data-path="R-linear-regression.html"><a href="#join%EC%9D%84-%EC%88%98%ED%96%89%ED%95%98%EB%8A%94-%EB%8B%A4%EB%A5%B8-%EB%B0%A9%EB%B2%95%EB%93%A4"><i class="fa fa-check"></i><b>9.2.3</b> Join을 수행하는 다른 방법들</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="ch-R-Advanced-Data-Mgmt.html"><a href="ch-R-Advanced-Data-Mgmt.html#sec-tidyr"><i class="fa fa-check"></i><b>9.3</b> <code>tidyr</code> 패키지를 이용하여 정돈 데이터 형식으로 바꾸기</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="R-linear-regression.html"><a href="#pivot_longer-%EC%97%AC%EB%9F%AC-%EC%97%B4%EC%97%90-%EA%B1%B8%EC%B9%9C-%ED%95%9C-%EB%B3%80%EC%88%98%EC%9D%98-%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A5%BC-%ED%95%98%EB%82%98%EC%9D%98-%EC%97%B4%EB%A1%9C-%EA%B8%B8%EA%B2%8C-%EB%AA%A8%EC%9C%BC%EA%B8%B0"><i class="fa fa-check"></i><b>9.3.1</b> <code>pivot_longer</code>: 여러 열에 걸친 한 변수의 데이터를 하나의 열로 길게 모으기</a></li>
<li class="chapter" data-level="9.3.2" data-path="ch-R-Advanced-Data-Mgmt.html"><a href="ch-R-Advanced-Data-Mgmt.html#subsec-pivot-wider"><i class="fa fa-check"></i><b>9.3.2</b> <code>pivot_wider</code>: 한 열에 기술된 여러 변수의 데이터를 여러 열로 넓게 펼치기</a></li>
<li class="chapter" data-level="9.3.3" data-path="R-linear-regression.html"><a href="#seperate-%ED%95%9C-%EC%85%80%EC%9D%84-%EC%97%AC%EB%9F%AC-%EC%85%80%EB%A1%9C-%EB%B6%84%EB%A6%AC%ED%95%98%EA%B8%B0"><i class="fa fa-check"></i><b>9.3.3</b> <code>seperate</code>: 한 셀을 여러 셀로 분리하기</a></li>
<li class="chapter" data-level="9.3.4" data-path="R-linear-regression.html"><a href="#unite-%EC%97%AC%EB%9F%AC-%EC%85%80%EC%9D%98-%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A5%BC-%ED%95%98%EB%82%98%EC%9D%98-%EC%85%80%EB%A1%9C-%EB%B3%91%ED%95%A9%ED%95%98%EA%B8%B0"><i class="fa fa-check"></i><b>9.3.4</b> <code>unite</code>: 여러 셀의 데이터를 하나의 셀로 병합하기</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="R-linear-regression.html"><a href="#%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%97%B4%EC%9D%98-%ED%98%95%EC%8B%9D-%EB%B0%94%EA%BE%B8%EA%B8%B0"><i class="fa fa-check"></i><b>9.4</b> 데이터 열의 형식 바꾸기</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="ch-R-Programming-Structure.html"><a href="ch-R-Programming-Structure.html"><i class="fa fa-check"></i><b>10</b> R 프로그래밍 구조</a>
<ul>
<li class="chapter" data-level="10.1" data-path="R-linear-regression.html"><a href="#r-%EC%A1%B0%EA%B1%B4%EB%AC%B8"><i class="fa fa-check"></i><b>10.1</b> R 조건문</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="R-linear-regression.html"><a href="#if-%EC%A1%B0%EA%B1%B4%EB%AC%B8"><i class="fa fa-check"></i><b>10.1.1</b> if 조건문</a></li>
<li class="chapter" data-level="10.1.2" data-path="R-linear-regression.html"><a href="#switch-%ED%95%A8%EC%88%98"><i class="fa fa-check"></i><b>10.1.2</b> switch 함수</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="R-linear-regression.html"><a href="#r-%EB%B0%98%EB%B3%B5%EB%AC%B8"><i class="fa fa-check"></i><b>10.2</b> R 반복문</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="R-linear-regression.html"><a href="#for-%EB%B0%98%EB%B3%B5%EB%AC%B8"><i class="fa fa-check"></i><b>10.2.1</b> for 반복문</a></li>
<li class="chapter" data-level="10.2.2" data-path="R-linear-regression.html"><a href="#while-%EB%B0%98%EB%B3%B5%EB%AC%B8"><i class="fa fa-check"></i><b>10.2.2</b> while 반복문</a></li>
<li class="chapter" data-level="10.2.3" data-path="R-linear-regression.html"><a href="#repeat-%EB%B0%98%EB%B3%B5%EB%AC%B8"><i class="fa fa-check"></i><b>10.2.3</b> repeat 반복문</a></li>
<li class="chapter" data-level="10.2.4" data-path="R-linear-regression.html"><a href="#%EB%B0%98%EB%B3%B5%EB%AC%B8%EC%9D%98-%EC%A0%9C%EC%96%B4-%EB%AA%85%EB%A0%B9"><i class="fa fa-check"></i><b>10.2.4</b> 반복문의 제어 명령</a></li>
<li class="chapter" data-level="10.2.5" data-path="R-linear-regression.html"><a href="#r%EC%97%90%EC%84%9C-%EB%B0%98%EB%B3%B5%EB%AC%B8-%EC%82%AC%EC%9A%A9%EC%9D%98-%EC%A3%BC%EC%9D%98%EC%A0%90"><i class="fa fa-check"></i><b>10.2.5</b> R에서 반복문 사용의 주의점</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="R-linear-regression.html"><a href="#r-%ED%95%A8%EC%88%98"><i class="fa fa-check"></i><b>10.3</b> R 함수</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="R-linear-regression.html"><a href="#%ED%95%A8%EC%88%98%EC%9D%98-%EC%83%9D%EC%84%B1%EA%B3%BC-%ED%98%B8%EC%B6%9C"><i class="fa fa-check"></i><b>10.3.1</b> 함수의 생성과 호출</a></li>
<li class="chapter" data-level="10.3.2" data-path="R-linear-regression.html"><a href="#%ED%95%A8%EC%88%98-%EA%B0%9D%EC%B2%B4%EB%A5%BC-%EC%9D%B8%EC%88%98%EB%A1%9C-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0"><i class="fa fa-check"></i><b>10.3.2</b> 함수 객체를 인수로 사용하기</a></li>
<li class="chapter" data-level="10.3.3" data-path="R-linear-regression.html"><a href="#r-%EC%97%B0%EC%82%B0%EC%9E%90"><i class="fa fa-check"></i><b>10.3.3</b> R 연산자</a></li>
<li class="chapter" data-level="10.3.4" data-path="R-linear-regression.html"><a href="#%EB%B3%80%EC%88%98-%EB%B2%94%EC%9C%84"><i class="fa fa-check"></i><b>10.3.4</b> 변수 범위</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="ch-R-OOP.html"><a href="ch-R-OOP.html"><i class="fa fa-check"></i><b>11</b> R 객체 지향 프로그래밍</a>
<ul>
<li class="chapter" data-level="11.1" data-path="R-linear-regression.html"><a href="#%EA%B0%9D%EC%B2%B4-%EC%A7%80%ED%96%A5-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D"><i class="fa fa-check"></i><b>11.1</b> 객체 지향 프로그래밍</a></li>
<li class="chapter" data-level="11.2" data-path="R-linear-regression.html"><a href="#s3-%ED%81%B4%EB%9E%98%EC%8A%A4"><i class="fa fa-check"></i><b>11.2</b> S3 클래스</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="R-linear-regression.html"><a href="#s3-%ED%81%B4%EB%9E%98%EC%8A%A4-%EA%B0%9D%EC%B2%B4-%EB%A7%8C%EB%93%A4%EA%B8%B0"><i class="fa fa-check"></i><b>11.2.1</b> S3 클래스 객체 만들기</a></li>
<li class="chapter" data-level="11.2.2" data-path="R-linear-regression.html"><a href="#%ED%8F%AC%EA%B4%84-%ED%95%A8%EC%88%98generic-functions"><i class="fa fa-check"></i><b>11.2.2</b> 포괄 함수(generic functions)</a></li>
<li class="chapter" data-level="11.2.3" data-path="R-linear-regression.html"><a href="#s3%EC%97%90%EC%84%9C-%EC%83%81%EC%86%8D%EC%84%B1%EC%9D%98-%EA%B5%AC%ED%98%84"><i class="fa fa-check"></i><b>11.2.3</b> S3에서 상속성의 구현</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="R-linear-regression.html"><a href="#s4-%ED%81%B4%EB%9E%98%EC%8A%A4"><i class="fa fa-check"></i><b>11.3</b> S4 클래스</a></li>
</ul></li>
<li class="part"><span><b>II R 프로그래밍 응용</b></span></li>
<li class="chapter" data-level="12" data-path="ch-R-import.html"><a href="ch-R-import.html"><i class="fa fa-check"></i><b>12</b> <strong>R</strong> 데이터 수집</a>
<ul>
<li class="chapter" data-level="12.1" data-path="ch-R-import.html"><a href="ch-R-import.html#sec-read-csv"><i class="fa fa-check"></i><b>12.1</b> 텍스트 파일에서 데이터 읽기</a></li>
<li class="chapter" data-level="12.2" data-path="ch-R-import.html"><a href="ch-R-import.html#sec-read-spreadsheets"><i class="fa fa-check"></i><b>12.2</b> 스프레드시트 파일에서 데이터 읽기</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="ch-R-import.html"><a href="ch-R-import.html#sec-read-excel"><i class="fa fa-check"></i><b>12.2.1</b> Excel 파일에서 데이터 읽기</a></li>
<li class="chapter" data-level="12.2.2" data-path="ch-R-import.html"><a href="ch-R-import.html#sec-read-google-sheets"><i class="fa fa-check"></i><b>12.2.2</b> Google Sheets에서 데이터 읽기</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="ch-R-import.html"><a href="ch-R-import.html#sec-import-databse"><i class="fa fa-check"></i><b>12.3</b> 데이터베이스에서 데이터 가져오기</a></li>
<li class="chapter" data-level="12.4" data-path="ch-R-import.html"><a href="ch-R-import.html#sec-web-scrapping"><i class="fa fa-check"></i><b>12.4</b> 웹 스크래핑 (web scrapping): 웹 사이트에서 데이터 가져오기</a></li>
<li class="chapter" data-level="12.5" data-path="ch-R-import.html"><a href="ch-R-import.html#sec-public-api"><i class="fa fa-check"></i><b>12.5</b> 공개 API에서 데이터 가져오기</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="ch-R-documents.html"><a href="ch-R-documents.html"><i class="fa fa-check"></i><b>13</b> <strong>R</strong> 동적 문서</a>
<ul>
<li class="chapter" data-level="13.1" data-path="R-linear-regression.html"><a href="#quarto-%EC%84%A4%EC%B9%98"><i class="fa fa-check"></i><b>13.1</b> Quarto 설치</a></li>
<li class="chapter" data-level="13.2" data-path="ch-R-documents.html"><a href="ch-R-documents.html#sec-quarto-creation"><i class="fa fa-check"></i><b>13.2</b> Quarto 문서 만들기</a></li>
<li class="chapter" data-level="13.3" data-path="R-linear-regression.html"><a href="#quarto%EC%9D%98-%EC%B6%9C%EB%A0%A5-%ED%98%95%EC%8B%9D"><i class="fa fa-check"></i><b>13.3</b> Quarto의 출력 형식</a>
<ul>
<li class="chapter" data-level="" data-path=""><a href="#%EC%B6%9C%EB%A0%A5-%ED%98%95%EC%8B%9D-%EB%B0%94%EA%BE%B8%EA%B8%B0"><i class="fa fa-check"></i>출력 형식 바꾸기</a></li>
<li class="chapter" data-level="13.3.1" data-path="R-linear-regression.html"><a href="#%EC%97%AC%EB%9F%AC-%EC%B6%9C%EB%A0%A5-%ED%98%95%EC%8B%9D%EC%9C%BC%EB%A1%9C-%EB%AC%B8%EC%84%9C-%EB%B3%80%ED%99%98%ED%95%98%EA%B8%B0"><i class="fa fa-check"></i><b>13.3.1</b> 여러 출력 형식으로 문서 변환하기</a></li>
<li class="chapter" data-level="13.3.2" data-path="R-linear-regression.html"><a href="#%EC%B6%9C%EB%A0%A5-%EC%98%B5%EC%85%98-%EC%A1%B0%EC%A0%95%ED%95%98%EA%B8%B0"><i class="fa fa-check"></i><b>13.3.2</b> 출력 옵션 조정하기</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="R-linear-regression.html"><a href="#%EB%A7%88%ED%81%AC%EB%8B%A4%EC%9A%B4-%EA%B8%B0%EC%B4%88"><i class="fa fa-check"></i><b>13.4</b> 마크다운 기초</a>
<ul>
<li class="chapter" data-level="" data-path=""><a href="#%ED%85%8D%EC%8A%A4%ED%8A%B8-%EC%84%9C%EC%8B%9D"><i class="fa fa-check"></i>텍스트 서식</a></li>
<li class="chapter" data-level="" data-path=""><a href="#%EC%9E%A5%EA%B3%BC-%EC%A0%88%EC%9D%98-%EC%A0%9C%EB%AA%A9"><i class="fa fa-check"></i>장과 절의 제목</a></li>
<li class="chapter" data-level="" data-path=""><a href="#%EB%AA%A9%EB%A1%9D"><i class="fa fa-check"></i>목록</a></li>
<li class="chapter" data-level="13.4.1" data-path="R-linear-regression.html"><a href="#url-%EB%A7%81%ED%81%AC"><i class="fa fa-check"></i><b>13.4.1</b> URL 링크</a></li>
<li class="chapter" data-level="" data-path=""><a href="#%EA%B7%B8%EB%A6%BC"><i class="fa fa-check"></i>그림</a></li>
<li class="chapter" data-level="" data-path=""><a href="#%ED%91%9C"><i class="fa fa-check"></i>표</a></li>
<li class="chapter" data-level="" data-path=""><a href="#%EB%B8%94%EB%A1%9D"><i class="fa fa-check"></i>블록</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="R-linear-regression.html"><a href="#%EC%BD%94%EB%93%9C-%EB%AA%A8%EB%93%AC"><i class="fa fa-check"></i><b>13.5</b> 코드 모듬</a>
<ul>
<li class="chapter" data-level="13.5.1" data-path="R-linear-regression.html"><a href="#%EC%BD%94%EB%93%9C-%EB%AA%A8%EB%93%AC-%EC%98%B5%EC%85%98"><i class="fa fa-check"></i><b>13.5.1</b> 코드 모듬 옵션</a></li>
<li class="chapter" data-level="13.5.2" data-path="R-linear-regression.html"><a href="#%EC%8B%A4%ED%96%89-%EC%98%B5%EC%85%98-excution-options"><i class="fa fa-check"></i><b>13.5.2</b> 실행 옵션 (Excution Options)</a></li>
<li class="chapter" data-level="13.5.3" data-path="R-linear-regression.html"><a href="#%EB%8D%B0%EC%9D%B4%ED%84%B0%ED%94%84%EB%A0%88%EC%9E%84%EA%B3%BC-%ED%96%89%EB%A0%AC%EC%9D%84-%ED%91%9C%EB%A1%9C-%EC%B6%9C%EB%A0%A5%ED%95%98%EA%B8%B0"><i class="fa fa-check"></i><b>13.5.3</b> 데이터프레임과 행렬을 표로 출력하기</a></li>
<li class="chapter" data-level="13.5.4" data-path="R-linear-regression.html"><a href="#%EC%9D%B8%EB%9D%BC%EC%9D%B8-%EC%BD%94%EB%93%9C"><i class="fa fa-check"></i><b>13.5.4</b> 인라인 코드</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="ch-R-dimension-reduction.html"><a href="ch-R-dimension-reduction.html"><i class="fa fa-check"></i><b>14</b> <strong>R</strong> 차원 축소</a>
<ul>
<li class="chapter" data-level="14.1" data-path="ch-R-dimension-reduction.html"><a href="ch-R-dimension-reduction.html#sec-dimension-reduction"><i class="fa fa-check"></i><b>14.1</b> 차원 축소 (Dimension Reduction)</a>
<ul>
<li class="chapter" data-level="14.1.1" data-path="R-linear-regression.html"><a href="#%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%9D%98-%EC%B0%A8%EC%9B%90"><i class="fa fa-check"></i><b>14.1.1</b> 데이터의 차원</a></li>
<li class="chapter" data-level="14.1.2" data-path="R-linear-regression.html"><a href="#%EC%B0%A8%EC%9B%90-%EC%B6%95%EC%86%8C-%EB%B0%A9%EB%B2%95"><i class="fa fa-check"></i><b>14.1.2</b> 차원 축소 방법</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="ch-R-dimension-reduction.html"><a href="ch-R-dimension-reduction.html#sec-pca"><i class="fa fa-check"></i><b>14.2</b> 주성분 분석 (Principal Components Analysis)</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="R-linear-regression.html"><a href="#%EC%A3%BC%EC%84%B1%EB%B6%84-%EB%B6%84%EC%84%9D%EC%97%90-%EB%8C%80%ED%95%9C-%EC%A7%81%EA%B4%80%EC%A0%81-%EC%9D%B4%ED%95%B4"><i class="fa fa-check"></i><b>14.2.1</b> 주성분 분석에 대한 직관적 이해</a></li>
<li class="chapter" data-level="14.2.2" data-path="R-linear-regression.html"><a href="#%EC%B0%A8%EC%9B%90-%EC%9D%B4%EC%83%81%EC%9D%98-%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A1%9C%EC%9D%98-%EC%A3%BC%EC%84%B1%EB%B6%84-%EB%B6%84%EC%84%9D%EC%9D%98-%ED%99%95%EC%9E%A5"><i class="fa fa-check"></i><b>14.2.2</b> 3차원 이상의 데이터로의 주성분 분석의 확장</a></li>
<li class="chapter" data-level="14.2.3" data-path="R-linear-regression.html"><a href="#%EC%A3%BC%EC%84%B1%EB%B6%84-%EB%B6%84%EC%84%9D%EC%9D%98-%EA%B0%84%EB%9E%B5%ED%95%9C-%EC%9D%B4%EB%A1%A0"><i class="fa fa-check"></i><b>14.2.3</b> 주성분 분석의 간략한 이론</a></li>
<li class="chapter" data-level="14.2.4" data-path="R-linear-regression.html"><a href="#r%EB%A1%9C-%EC%A3%BC%EC%84%B1%EB%B6%84-%EB%B6%84%EC%84%9D%ED%95%98%EA%B8%B0"><i class="fa fa-check"></i><b>14.2.4</b> <strong>R</strong>로 주성분 분석하기</a></li>
<li class="chapter" data-level="14.2.5" data-path="R-linear-regression.html"><a href="#%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%95%EA%B7%9C%ED%99%94-%ED%9B%84-%EC%A3%BC%EC%84%B1%EB%B6%84-%EB%B6%84%EC%84%9D%ED%95%98%EA%B8%B0"><i class="fa fa-check"></i><b>14.2.5</b> 데이터 정규화 후 주성분 분석하기</a></li>
<li class="chapter" data-level="14.2.6" data-path="ch-R-dimension-reduction.html"><a href="ch-R-dimension-reduction.html#sec-pca-viaulaization"><i class="fa fa-check"></i><b>14.2.6</b> 주성분 분석의 시각화</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="ch-R-clustering.html"><a href="ch-R-clustering.html"><i class="fa fa-check"></i><b>15</b> <strong>R</strong> 군집 분석</a>
<ul>
<li class="chapter" data-level="15.1" data-path="ch-R-clustering.html"><a href="ch-R-clustering.html#sec-clustering"><i class="fa fa-check"></i><b>15.1</b> 군집 분석이란?</a>
<ul>
<li class="chapter" data-level="15.1.1" data-path="R-linear-regression.html"><a href="#%EA%B5%B0%EC%A7%91-%EB%B6%84%EC%84%9D%EC%9D%98-%ED%95%84%EC%9A%94%EC%84%B1"><i class="fa fa-check"></i><b>15.1.1</b> 군집 분석의 필요성</a></li>
<li class="chapter" data-level="15.1.2" data-path="R-linear-regression.html"><a href="#%EA%B5%B0%EC%A7%91-%EB%B6%84%EC%84%9D%EC%9D%98-%EC%9C%A0%ED%98%95"><i class="fa fa-check"></i><b>15.1.2</b> 군집 분석의 유형</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="ch-R-clustering.html"><a href="ch-R-clustering.html#sec-k-means"><i class="fa fa-check"></i><b>15.2</b> k-평균 군집화</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="R-linear-regression.html"><a href="#%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98"><i class="fa fa-check"></i><b>15.2.1</b> 알고리즘</a></li>
<li class="chapter" data-level="15.2.2" data-path="R-linear-regression.html"><a href="#k-%ED%8F%89%EA%B7%A0-%EA%B5%B0%EC%A7%91%ED%99%94%EC%9D%98-%EC%9E%A5%EC%A0%90-%EB%B0%8F-%EB%8B%A8%EC%A0%90"><i class="fa fa-check"></i><b>15.2.2</b> k-평균 군집화의 장점 및 단점</a></li>
<li class="chapter" data-level="15.2.3" data-path="R-linear-regression.html"><a href="#r%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%9C-k-%ED%8F%89%EA%B7%A0-%EA%B5%B0%EC%A7%91-%EB%B6%84%EC%84%9D"><i class="fa fa-check"></i><b>15.2.3</b> R을 이용한 k-평균 군집 분석</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="ch-R-clustering.html"><a href="ch-R-clustering.html#sec-agglomorative-clustering"><i class="fa fa-check"></i><b>15.3</b> 병합 군집화</a>
<ul>
<li class="chapter" data-level="15.3.1" data-path="ch-R-clustering.html"><a href="ch-R-clustering.html#sec-agglomorative-clustering-algorithm"><i class="fa fa-check"></i><b>15.3.1</b> 병합 군집화 알고리즘</a></li>
<li class="chapter" data-level="15.3.2" data-path="ch-R-clustering.html"><a href="ch-R-clustering.html#sec-distance-between-clusters"><i class="fa fa-check"></i><b>15.3.2</b> 군집 사이의 거리 계산</a></li>
<li class="chapter" data-level="15.3.3" data-path="ch-R-clustering.html"><a href="ch-R-clustering.html#sec-hclust"><i class="fa fa-check"></i><b>15.3.3</b> <code>hclust()</code> 함수를 이용한 병합 군집화</a></li>
<li class="chapter" data-level="15.3.4" data-path="R-linear-regression.html"><a href="#%EB%B3%91%ED%95%A9-%EA%B5%B0%EC%A7%91%ED%99%94%EC%97%90-%EB%8C%80%ED%95%9C-%EA%B3%84%ED%86%B5%EB%8F%84-%EA%B7%B8%EB%A6%AC%EA%B8%B0"><i class="fa fa-check"></i><b>15.3.4</b> 병합 군집화에 대한 계통도 그리기</a></li>
<li class="chapter" data-level="15.3.5" data-path="R-linear-regression.html"><a href="#%EA%B5%B0%EC%A7%91-%EB%82%98%EB%88%84%EA%B8%B0"><i class="fa fa-check"></i><b>15.3.5</b> 군집 나누기</a></li>
<li class="chapter" data-level="15.3.6" data-path="R-linear-regression.html"><a href="#%EC%B5%9C%EC%A0%81-%EA%B5%B0%EC%A7%91-%EC%88%98%EC%9D%98-%EA%B2%B0%EC%A0%95"><i class="fa fa-check"></i><b>15.3.6</b> 최적 군집 수의 결정</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="ch-R-hypothesis-tests.html"><a href="ch-R-hypothesis-tests.html"><i class="fa fa-check"></i><b>16</b> <strong>R</strong> 통계적 가설검정</a>
<ul>
<li class="chapter" data-level="16.1" data-path="ch-R-hypothesis-tests.html"><a href="ch-R-hypothesis-tests.html#sec-hypothesis"><i class="fa fa-check"></i><b>16.1</b> 가설검정이란?</a>
<ul>
<li class="chapter" data-level="16.1.1" data-path="R-linear-regression.html"><a href="#%EA%B0%80%EC%84%A4%EC%9D%98-%EC%84%A4%EC%A0%95"><i class="fa fa-check"></i><b>16.1.1</b> 가설의 설정</a></li>
<li class="chapter" data-level="16.1.2" data-path="R-linear-regression.html"><a href="#%EA%B2%80%EC%A0%95%ED%86%B5%EA%B3%84%EB%9F%89%EA%B3%BC-%ED%91%9C%EB%B3%B8-%EB%B6%84%ED%8F%AC"><i class="fa fa-check"></i><b>16.1.2</b> 검정통계량과 표본 분포</a></li>
<li class="chapter" data-level="16.1.3" data-path="R-linear-regression.html"><a href="#%EA%B8%B0%EA%B0%81%EC%97%AD%EA%B3%BC-%EC%9C%A0%EC%9D%98%EC%88%98%EC%A4%80"><i class="fa fa-check"></i><b>16.1.3</b> 기각역과 유의수준</a></li>
<li class="chapter" data-level="16.1.4" data-path="R-linear-regression.html"><a href="#%EC%9C%A0%EC%9D%98%ED%99%95%EB%A5%A0-p-%EA%B0%92p-value"><i class="fa fa-check"></i><b>16.1.4</b> 유의확률 p-값(p-value)</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="R-linear-regression.html"><a href="#r%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%9C-%EB%B2%94%EC%A3%BC%ED%98%95-%EB%B3%80%EC%88%98%EC%9D%98-%EA%B0%80%EC%84%A4%EA%B2%80%EC%A0%90"><i class="fa fa-check"></i><b>16.2</b> <strong>R</strong>을 이용한 범주형 변수의 가설검점</a>
<ul>
<li class="chapter" data-level="16.2.1" data-path="R-linear-regression.html"><a href="#%EA%B4%80%EC%A0%88%EC%97%BC-%EC%B9%98%EB%A3%8C-%EC%9E%84%EC%83%81%EC%8B%9C%ED%97%98-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%B6%84%EC%84%9D"><i class="fa fa-check"></i><b>16.2.1</b> 관절염 치료 임상시험 데이터 분석</a></li>
<li class="chapter" data-level="16.2.2" data-path="R-linear-regression.html"><a href="#%EA%B8%B0%EC%88%A0-%ED%86%B5%EA%B3%84-%EB%B6%84%EC%84%9D"><i class="fa fa-check"></i><b>16.2.2</b> 기술 통계 분석</a></li>
<li class="chapter" data-level="16.2.3" data-path="R-linear-regression.html"><a href="#%EB%8F%85%EB%A6%BD%EC%84%B1-%EA%B2%80%EC%A0%95"><i class="fa fa-check"></i><b>16.2.3</b> 독립성 검정</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="R-linear-regression.html"><a href="#%EC%88%98%EC%B9%98%ED%98%95-%EB%B3%80%EC%88%98%EC%97%90-%EB%8C%80%ED%95%9C-%EA%B0%80%EC%84%A4%EA%B2%80%EC%A0%95"><i class="fa fa-check"></i><b>16.3</b> 수치형 변수에 대한 가설검정</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="ch-R-linear-regression.html"><a href="ch-R-linear-regression.html"><i class="fa fa-check"></i><b>17</b> <strong>R</strong> 선형 회귀</a>
<ul>
<li class="chapter" data-level="17.1" data-path="ch-R-linear-regression.html"><a href="ch-R-linear-regression.html#sec-simple-linear-regression"><i class="fa fa-check"></i><b>17.1</b> 단순 선형 회귀</a>
<ul>
<li class="chapter" data-level="17.1.1" data-path="ch-R-linear-regression.html"><a href="ch-R-linear-regression.html#sec-cars"><i class="fa fa-check"></i><b>17.1.1</b> <code>cars</code> 데이터</a></li>
<li class="chapter" data-level="17.1.2" data-path="ch-R-linear-regression.html"><a href="ch-R-linear-regression.html#sec-simple-linear-regression-theory"><i class="fa fa-check"></i><b>17.1.2</b> 단순 선형 회귀 모형</a></li>
<li class="chapter" data-level="17.1.3" data-path="ch-R-linear-regression.html"><a href="ch-R-linear-regression.html#sec-lm"><i class="fa fa-check"></i><b>17.1.3</b> <code>lm()</code> 함수</a></li>
<li class="chapter" data-level="17.1.4" data-path="ch-R-linear-regression.html"><a href="ch-R-linear-regression.html#sec-linear-regression-evaluation"><i class="fa fa-check"></i><b>17.1.4</b> 선형 회귀 모형의 평가</a></li>
<li class="chapter" data-level="17.1.5" data-path="R-linear-regression.html"><a href="#%EB%AA%A8%ED%98%95%EC%9D%98-%EA%B0%9C%EC%84%A0"><i class="fa fa-check"></i><b>17.1.5</b> 모형의 개선</a></li>
</ul></li>
<li class="chapter" data-level="17.2" data-path="ch-R-linear-regression.html"><a href="ch-R-linear-regression.html#sec-multiple-linear-regression"><i class="fa fa-check"></i><b>17.2</b> 다중 선형 회귀</a>
<ul>
<li class="chapter" data-level="17.2.1" data-path="R-linear-regression.html"><a href="#galtonfamilies-%EB%8D%B0%EC%9D%B4%ED%84%B0"><i class="fa fa-check"></i><b>17.2.1</b> <code>GaltonFamilies</code> 데이터</a></li>
<li class="chapter" data-level="17.2.2" data-path="ch-R-linear-regression.html"><a href="ch-R-linear-regression.html#sec-multiple-linear-regression-theory"><i class="fa fa-check"></i><b>17.2.2</b> 다중 선형 회귀 모형</a></li>
<li class="chapter" data-level="17.2.3" data-path="R-linear-regression.html"><a href="#lm%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%9C-%EB%8B%A4%EC%A4%91-%EC%84%A0%ED%98%95-%ED%9A%8C%EA%B7%80"><i class="fa fa-check"></i><b>17.2.3</b> <code>lm()</code>을 이용한 다중 선형 회귀</a></li>
<li class="chapter" data-level="17.2.4" data-path="ch-R-linear-regression.html"><a href="ch-R-linear-regression.html#sec-interaction-terms"><i class="fa fa-check"></i><b>17.2.4</b> 교차항의 도입</a></li>
<li class="chapter" data-level="17.2.5" data-path="ch-R-linear-regression.html"><a href="ch-R-linear-regression.html#sec-variable-selections"><i class="fa fa-check"></i><b>17.2.5</b> 변수 선택</a></li>
</ul></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="ch-RandPython.html"><a href="ch-RandPython.html"><i class="fa fa-check"></i><b>A</b> <strong>R</strong>과 <strong>Python</strong> 연동하기</a>
<ul>
<li class="chapter" data-level="A.1" data-path="R-linear-regression.html"><a href="#reticulate-%EC%84%A4%EC%B9%98-%EB%B0%8F-%EC%82%AC%EC%9A%A9%ED%95%A0-%ED%8C%8C%EC%9D%B4%EC%8D%AC-%EB%B2%84%EC%A0%84-%EC%84%A4%EC%A0%95"><i class="fa fa-check"></i><b>A.1</b> <code>reticulate</code> 설치 및 사용할 파이썬 버전 설정</a></li>
<li class="chapter" data-level="A.2" data-path="R-linear-regression.html"><a href="#r%EA%B3%BC-%ED%8C%8C%EC%9D%B4%EC%8D%AC-%EC%97%B0%EB%8F%99%ED%95%98%EB%8A%94-%EB%B0%A9%EB%B2%95"><i class="fa fa-check"></i><b>A.2</b> R과 파이썬 연동하는 방법</a></li>
<li class="chapter" data-level="A.3" data-path="R-linear-regression.html"><a href="#%ED%8C%8C%EC%9D%B4%EC%8D%AC-%EB%AA%A8%EB%93%88-%EC%97%B0%EB%8F%99%ED%95%98%EA%B8%B0"><i class="fa fa-check"></i><b>A.3</b> 파이썬 모듈 연동하기</a>
<ul>
<li class="chapter" data-level="A.3.1" data-path="R-linear-regression.html"><a href="#r%EA%B3%BC-python%EC%9D%98-%ED%98%95%EC%8B%9D-%EB%B3%80%ED%99%98"><i class="fa fa-check"></i><b>A.3.1</b> <strong>R</strong>과 <strong>Python</strong>의 형식 변환</a></li>
<li class="chapter" data-level="A.3.2" data-path="R-linear-regression.html"><a href="#%ED%98%95%EB%B3%80%ED%99%98-%EC%A7%81%EC%A0%91-%ED%95%98%EA%B8%B0"><i class="fa fa-check"></i><b>A.3.2</b> 형변환 직접 하기</a></li>
<li class="chapter" data-level="A.3.3" data-path="R-linear-regression.html"><a href="#%ED%8C%8C%EC%9D%B4%EC%8D%AC-%EB%AA%A8%EB%93%88%EC%9D%98-%EB%8F%84%EC%9B%80%EB%A7%90-%ED%99%95%EC%9D%B8%ED%95%98%EA%B8%B0"><i class="fa fa-check"></i><b>A.3.3</b> 파이썬 모듈의 도움말 확인하기</a></li>
<li class="chapter" data-level="A.3.4" data-path="R-linear-regression.html"><a href="#pickle-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0"><i class="fa fa-check"></i><b>A.3.4</b> <code>pickle</code> 사용하기</a></li>
</ul></li>
<li class="chapter" data-level="A.4" data-path="R-linear-regression.html"><a href="#r-%EB%A7%88%ED%81%AC%EB%8B%A4%EC%9A%B4-%EB%AC%B8%EC%84%9C%EC%97%90%EC%84%9C-%ED%8C%8C%EC%9D%B4%EC%8D%AC-%EB%AA%85%EB%A0%B9-%EC%8B%A4%ED%96%89%ED%95%98%EA%B8%B0"><i class="fa fa-check"></i><b>A.4</b> R 마크다운 문서에서 파이썬 명령 실행하기</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="ch-RTips.html"><a href="ch-RTips.html"><i class="fa fa-check"></i><b>B</b> <strong>R</strong> 관련 여러 주제들</a>
<ul>
<li class="chapter" data-level="B.1" data-path="R-linear-regression.html"><a href="#r%EC%9D%98-%ED%8C%8C%EC%9D%BC-%EB%B0%8F-%ED%8F%B4%EB%8D%94-%EA%B4%80%EB%A0%A8-%EB%AA%85%EB%A0%B9%EC%96%B4%EB%93%B1"><i class="fa fa-check"></i><b>B.1</b> <strong>R</strong>의 파일 및 폴더 관련 명령어등</a>
<ul>
<li class="chapter" data-level="B.1.1" data-path="R-linear-regression.html"><a href="#%EC%9E%91%EC%97%85-%EB%94%94%EB%A0%89%ED%86%A0%EB%A6%AC"><i class="fa fa-check"></i><b>B.1.1</b> 작업 디렉토리</a></li>
<li class="chapter" data-level="B.1.2" data-path="R-linear-regression.html"><a href="#%ED%8F%B4%EB%8D%94-%EB%82%B4%EC%9D%98-%ED%8C%8C%EC%9D%BC-%EB%AA%A9%EB%A1%9D-%ED%99%95%EC%9D%B8%ED%95%98%EA%B8%B0"><i class="fa fa-check"></i><b>B.1.2</b> 폴더 내의 파일 목록 확인하기</a></li>
<li class="chapter" data-level="B.1.3" data-path="R-linear-regression.html"><a href="#%ED%8C%8C%EC%9D%BC%EA%B3%BC-%ED%8F%B4%EB%8D%94-%EC%A1%B4%EC%9E%AC-%ED%99%95%EC%9D%B8"><i class="fa fa-check"></i><b>B.1.3</b> 파일과 폴더 존재 확인</a></li>
<li class="chapter" data-level="B.1.4" data-path="R-linear-regression.html"><a href="#%ED%8F%B4%EB%8D%94%EC%9D%98-%EC%83%9D%EC%84%B1%EA%B3%BC-%EC%82%AD%EC%A0%9C"><i class="fa fa-check"></i><b>B.1.4</b> 폴더의 생성과 삭제</a></li>
<li class="chapter" data-level="B.1.5" data-path="R-linear-regression.html"><a href="#%ED%8C%8C%EC%9D%BC%EC%9D%98-%EC%83%9D%EC%84%B1-%EB%B3%B5%EC%82%AC-%EC%9D%B4%EB%8F%99-%EC%82%AD%EC%A0%9C"><i class="fa fa-check"></i><b>B.1.5</b> 파일의 생성, 복사, 이동, 삭제</a></li>
</ul></li>
<li class="chapter" data-level="B.2" data-path="R-linear-regression.html"><a href="#r%EC%97%90%EC%84%9C-%EA%B3%84%EC%82%B0-%EC%A0%95%ED%99%95%EB%8F%84%EB%A5%BC-%ED%96%A5%EC%83%81%EC%8B%9C%ED%82%A4%EA%B8%B0"><i class="fa fa-check"></i><b>B.2</b> <strong>R</strong>에서 계산 정확도를 향상시키기</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">R 프로그래밍 3판 (draft)</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ch-R-linear-regression" class="section level1 hasAnchor" number="17">
<h1><span class="header-section-number">Chapter 17</span> <strong>R</strong> 선형 회귀<a href="ch-R-linear-regression.html#ch-R-linear-regression" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>회귀(Regression) 분석이라는 용어는 영국 유전학자 갈톤이 생각한 문제에서 시작되었다.
갈톤은 부모의 키가 자식의 키에 미치는 영향을 통계적으로 분석하고자 205 가구의 934 명의 자식들의 키를 조사하였고 이에 대한 회귀 법칙을 1886년에 발표하였다<span class="citation">(<a href="#ref-galton1886regression">Galton 1886</a>)</span>.
데이터를 정리한 <a href="http://www.medicine.mcgill.ca/epidemiology/hanley/galton/notebook/">갈톤의 공책</a>이 남아있고 공책의 첫 장에 기술한 것처럼 가족별로 아버지, 어머나, 아들, 딸의 키가 60 인치를 기준으로 그보다 초과하는 정도가 기록되어 있다.</p>
<p><img src="img/galton-notebook.jpg" width="70%" style="display: block; margin: auto;" /></p>
<p>우리는 이 데이터를 <strong>R</strong>의 <code>HistData</code> 패키지의 <code>GaltonFamilies</code>라는 데이터로 쉽게 얻을 수 있다.
다음은 <code>GaltonFamilies</code> 데이터를 보여준다.
이 데이터는 아버지, 어머니, 자식의 키가 모두 인치로 기록되어 있다.</p>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["family"],"name":[1],"type":["fct"],"align":["left"]},{"label":["father"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["mother"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["midparentHeight"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["children"],"name":[5],"type":["int"],"align":["right"]},{"label":["childNum"],"name":[6],"type":["int"],"align":["right"]},{"label":["gender"],"name":[7],"type":["fct"],"align":["left"]},{"label":["childHeight"],"name":[8],"type":["dbl"],"align":["right"]}],"data":[{"1":"001","2":"78.5","3":"67.0","4":"75.430","5":"4","6":"1","7":"male","8":"73.2"},{"1":"001","2":"78.5","3":"67.0","4":"75.430","5":"4","6":"2","7":"female","8":"69.2"},{"1":"001","2":"78.5","3":"67.0","4":"75.430","5":"4","6":"3","7":"female","8":"69.0"},{"1":"001","2":"78.5","3":"67.0","4":"75.430","5":"4","6":"4","7":"female","8":"69.0"},{"1":"002","2":"75.5","3":"66.5","4":"73.660","5":"4","6":"1","7":"male","8":"73.5"},{"1":"002","2":"75.5","3":"66.5","4":"73.660","5":"4","6":"2","7":"male","8":"72.5"},{"1":"002","2":"75.5","3":"66.5","4":"73.660","5":"4","6":"3","7":"female","8":"65.5"},{"1":"002","2":"75.5","3":"66.5","4":"73.660","5":"4","6":"4","7":"female","8":"65.5"},{"1":"003","2":"75.0","3":"64.0","4":"72.060","5":"2","6":"1","7":"male","8":"71.0"},{"1":"003","2":"75.0","3":"64.0","4":"72.060","5":"2","6":"2","7":"female","8":"68.0"},{"1":"004","2":"75.0","3":"64.0","4":"72.060","5":"5","6":"1","7":"male","8":"70.5"},{"1":"004","2":"75.0","3":"64.0","4":"72.060","5":"5","6":"2","7":"male","8":"68.5"},{"1":"004","2":"75.0","3":"64.0","4":"72.060","5":"5","6":"3","7":"female","8":"67.0"},{"1":"004","2":"75.0","3":"64.0","4":"72.060","5":"5","6":"4","7":"female","8":"64.5"},{"1":"004","2":"75.0","3":"64.0","4":"72.060","5":"5","6":"5","7":"female","8":"63.0"},{"1":"005","2":"75.0","3":"58.5","4":"69.090","5":"6","6":"1","7":"male","8":"72.0"},{"1":"005","2":"75.0","3":"58.5","4":"69.090","5":"6","6":"2","7":"male","8":"69.0"},{"1":"005","2":"75.0","3":"58.5","4":"69.090","5":"6","6":"3","7":"male","8":"68.0"},{"1":"005","2":"75.0","3":"58.5","4":"69.090","5":"6","6":"4","7":"female","8":"66.5"},{"1":"005","2":"75.0","3":"58.5","4":"69.090","5":"6","6":"5","7":"female","8":"62.5"},{"1":"005","2":"75.0","3":"58.5","4":"69.090","5":"6","6":"6","7":"female","8":"62.5"},{"1":"006","2":"74.0","3":"68.0","4":"73.720","5":"1","6":"1","7":"female","8":"69.5"},{"1":"007","2":"74.0","3":"68.0","4":"73.720","5":"6","6":"1","7":"male","8":"76.5"},{"1":"007","2":"74.0","3":"68.0","4":"73.720","5":"6","6":"2","7":"male","8":"74.0"},{"1":"007","2":"74.0","3":"68.0","4":"73.720","5":"6","6":"3","7":"male","8":"73.0"},{"1":"007","2":"74.0","3":"68.0","4":"73.720","5":"6","6":"4","7":"male","8":"73.0"},{"1":"007","2":"74.0","3":"68.0","4":"73.720","5":"6","6":"5","7":"female","8":"70.5"},{"1":"007","2":"74.0","3":"68.0","4":"73.720","5":"6","6":"6","7":"female","8":"64.0"},{"1":"008","2":"74.0","3":"66.5","4":"72.910","5":"3","6":"1","7":"female","8":"70.5"},{"1":"008","2":"74.0","3":"66.5","4":"72.910","5":"3","6":"2","7":"female","8":"68.0"},{"1":"008","2":"74.0","3":"66.5","4":"72.910","5":"3","6":"3","7":"female","8":"66.0"},{"1":"009","2":"74.5","3":"66.0","4":"72.890","5":"1","6":"1","7":"female","8":"66.0"},{"1":"010","2":"74.0","3":"65.5","4":"72.370","5":"1","6":"1","7":"female","8":"65.5"},{"1":"011","2":"74.0","3":"62.0","4":"70.480","5":"8","6":"1","7":"male","8":"74.0"},{"1":"011","2":"74.0","3":"62.0","4":"70.480","5":"8","6":"2","7":"male","8":"70.0"},{"1":"011","2":"74.0","3":"62.0","4":"70.480","5":"8","6":"3","7":"female","8":"68.0"},{"1":"011","2":"74.0","3":"62.0","4":"70.480","5":"8","6":"4","7":"female","8":"67.0"},{"1":"011","2":"74.0","3":"62.0","4":"70.480","5":"8","6":"5","7":"female","8":"67.0"},{"1":"011","2":"74.0","3":"62.0","4":"70.480","5":"8","6":"6","7":"female","8":"66.0"},{"1":"011","2":"74.0","3":"62.0","4":"70.480","5":"8","6":"7","7":"female","8":"63.5"},{"1":"011","2":"74.0","3":"62.0","4":"70.480","5":"8","6":"8","7":"female","8":"63.0"},{"1":"012","2":"74.0","3":"61.0","4":"69.940","5":"1","6":"1","7":"female","8":"65.0"},{"1":"013","2":"73.0","3":"67.0","4":"72.680","5":"2","6":"1","7":"male","8":"71.0"},{"1":"013","2":"73.0","3":"67.0","4":"72.680","5":"2","6":"2","7":"female","8":"62.0"},{"1":"014","2":"73.0","3":"67.0","4":"72.680","5":"2","6":"1","7":"male","8":"68.0"},{"1":"014","2":"73.0","3":"67.0","4":"72.680","5":"2","6":"2","7":"male","8":"67.0"},{"1":"015","2":"73.0","3":"66.5","4":"72.410","5":"3","6":"1","7":"male","8":"71.0"},{"1":"015","2":"73.0","3":"66.5","4":"72.410","5":"3","6":"2","7":"male","8":"70.5"},{"1":"015","2":"73.0","3":"66.5","4":"72.410","5":"3","6":"3","7":"female","8":"66.7"},{"1":"016","2":"73.0","3":"65.0","4":"71.600","5":"9","6":"1","7":"male","8":"72.0"},{"1":"016","2":"73.0","3":"65.0","4":"71.600","5":"9","6":"2","7":"male","8":"70.5"},{"1":"016","2":"73.0","3":"65.0","4":"71.600","5":"9","6":"3","7":"male","8":"70.2"},{"1":"016","2":"73.0","3":"65.0","4":"71.600","5":"9","6":"4","7":"male","8":"70.2"},{"1":"016","2":"73.0","3":"65.0","4":"71.600","5":"9","6":"5","7":"male","8":"69.2"},{"1":"016","2":"73.0","3":"65.0","4":"71.600","5":"9","6":"6","7":"female","8":"68.7"},{"1":"016","2":"73.0","3":"65.0","4":"71.600","5":"9","6":"7","7":"female","8":"66.5"},{"1":"016","2":"73.0","3":"65.0","4":"71.600","5":"9","6":"8","7":"female","8":"64.5"},{"1":"016","2":"73.0","3":"65.0","4":"71.600","5":"9","6":"9","7":"female","8":"63.5"},{"1":"017","2":"73.0","3":"64.5","4":"71.330","5":"6","6":"1","7":"male","8":"74.0"},{"1":"017","2":"73.0","3":"64.5","4":"71.330","5":"6","6":"2","7":"male","8":"73.0"},{"1":"017","2":"73.0","3":"64.5","4":"71.330","5":"6","6":"3","7":"male","8":"71.5"},{"1":"017","2":"73.0","3":"64.5","4":"71.330","5":"6","6":"4","7":"male","8":"62.5"},{"1":"017","2":"73.0","3":"64.5","4":"71.330","5":"6","6":"5","7":"female","8":"66.5"},{"1":"017","2":"73.0","3":"64.5","4":"71.330","5":"6","6":"6","7":"female","8":"62.3"},{"1":"018","2":"73.0","3":"64.0","4":"71.060","5":"3","6":"1","7":"female","8":"66.0"},{"1":"018","2":"73.0","3":"64.0","4":"71.060","5":"3","6":"2","7":"female","8":"64.5"},{"1":"018","2":"73.0","3":"64.0","4":"71.060","5":"3","6":"3","7":"female","8":"64.0"},{"1":"019","2":"73.2","3":"63.0","4":"70.620","5":"1","6":"1","7":"female","8":"62.7"},{"1":"020","2":"72.7","3":"69.0","4":"73.610","5":"8","6":"1","7":"male","8":"73.2"},{"1":"020","2":"72.7","3":"69.0","4":"73.610","5":"8","6":"2","7":"male","8":"73.0"},{"1":"020","2":"72.7","3":"69.0","4":"73.610","5":"8","6":"3","7":"male","8":"72.7"},{"1":"020","2":"72.7","3":"69.0","4":"73.610","5":"8","6":"4","7":"female","8":"70.0"},{"1":"020","2":"72.7","3":"69.0","4":"73.610","5":"8","6":"5","7":"female","8":"69.0"},{"1":"020","2":"72.7","3":"69.0","4":"73.610","5":"8","6":"6","7":"female","8":"68.5"},{"1":"020","2":"72.7","3":"69.0","4":"73.610","5":"8","6":"7","7":"female","8":"68.0"},{"1":"020","2":"72.7","3":"69.0","4":"73.610","5":"8","6":"8","7":"female","8":"66.0"},{"1":"021","2":"72.0","3":"68.0","4":"72.720","5":"3","6":"1","7":"male","8":"73.0"},{"1":"021","2":"72.0","3":"68.0","4":"72.720","5":"3","6":"2","7":"female","8":"68.5"},{"1":"021","2":"72.0","3":"68.0","4":"72.720","5":"3","6":"3","7":"female","8":"68.0"},{"1":"022","2":"72.0","3":"67.0","4":"72.180","5":"3","6":"1","7":"male","8":"73.0"},{"1":"022","2":"72.0","3":"67.0","4":"72.180","5":"3","6":"2","7":"male","8":"71.0"},{"1":"022","2":"72.0","3":"67.0","4":"72.180","5":"3","6":"3","7":"female","8":"67.0"},{"1":"023","2":"72.0","3":"65.0","4":"71.100","5":"7","6":"1","7":"male","8":"74.2"},{"1":"023","2":"72.0","3":"65.0","4":"71.100","5":"7","6":"2","7":"male","8":"70.5"},{"1":"023","2":"72.0","3":"65.0","4":"71.100","5":"7","6":"3","7":"male","8":"69.5"},{"1":"023","2":"72.0","3":"65.0","4":"71.100","5":"7","6":"4","7":"female","8":"66.0"},{"1":"023","2":"72.0","3":"65.0","4":"71.100","5":"7","6":"5","7":"female","8":"65.5"},{"1":"023","2":"72.0","3":"65.0","4":"71.100","5":"7","6":"6","7":"female","8":"65.0"},{"1":"023","2":"72.0","3":"65.0","4":"71.100","5":"7","6":"7","7":"female","8":"65.0"},{"1":"024","2":"72.0","3":"65.5","4":"71.370","5":"1","6":"1","7":"female","8":"65.5"},{"1":"025","2":"72.0","3":"64.0","4":"70.560","5":"2","6":"1","7":"female","8":"66.0"},{"1":"025","2":"72.0","3":"64.0","4":"70.560","5":"2","6":"2","7":"female","8":"63.0"},{"1":"026","2":"72.0","3":"63.0","4":"70.020","5":"5","6":"1","7":"male","8":"70.5"},{"1":"026","2":"72.0","3":"63.0","4":"70.020","5":"5","6":"2","7":"male","8":"70.5"},{"1":"026","2":"72.0","3":"63.0","4":"70.020","5":"5","6":"3","7":"male","8":"69.0"},{"1":"026","2":"72.0","3":"63.0","4":"70.020","5":"5","6":"4","7":"female","8":"65.0"},{"1":"026","2":"72.0","3":"63.0","4":"70.020","5":"5","6":"5","7":"female","8":"63.0"},{"1":"027","2":"72.0","3":"63.0","4":"70.020","5":"3","6":"1","7":"male","8":"69.0"},{"1":"027","2":"72.0","3":"63.0","4":"70.020","5":"3","6":"2","7":"male","8":"67.0"},{"1":"027","2":"72.0","3":"63.0","4":"70.020","5":"3","6":"3","7":"female","8":"63.0"},{"1":"028","2":"72.0","3":"63.0","4":"70.020","5":"6","6":"1","7":"male","8":"73.0"},{"1":"028","2":"72.0","3":"63.0","4":"70.020","5":"6","6":"2","7":"male","8":"67.0"},{"1":"028","2":"72.0","3":"63.0","4":"70.020","5":"6","6":"3","7":"female","8":"70.5"},{"1":"028","2":"72.0","3":"63.0","4":"70.020","5":"6","6":"4","7":"female","8":"70.0"},{"1":"028","2":"72.0","3":"63.0","4":"70.020","5":"6","6":"5","7":"female","8":"66.5"},{"1":"028","2":"72.0","3":"63.0","4":"70.020","5":"6","6":"6","7":"female","8":"63.0"},{"1":"029","2":"72.5","3":"63.5","4":"70.540","5":"3","6":"1","7":"female","8":"67.5"},{"1":"029","2":"72.5","3":"63.5","4":"70.540","5":"3","6":"2","7":"female","8":"67.2"},{"1":"029","2":"72.5","3":"63.5","4":"70.540","5":"3","6":"3","7":"female","8":"66.7"},{"1":"030","2":"72.0","3":"62.0","4":"69.480","5":"1","6":"1","7":"female","8":"64.0"},{"1":"031","2":"72.5","3":"62.0","4":"69.730","5":"6","6":"1","7":"male","8":"71.0"},{"1":"031","2":"72.5","3":"62.0","4":"69.730","5":"6","6":"2","7":"male","8":"70.0"},{"1":"031","2":"72.5","3":"62.0","4":"69.730","5":"6","6":"3","7":"male","8":"70.0"},{"1":"031","2":"72.5","3":"62.0","4":"69.730","5":"6","6":"4","7":"female","8":"66.0"},{"1":"031","2":"72.5","3":"62.0","4":"69.730","5":"6","6":"5","7":"female","8":"65.0"},{"1":"031","2":"72.5","3":"62.0","4":"69.730","5":"6","6":"6","7":"female","8":"65.0"},{"1":"032","2":"72.0","3":"62.0","4":"69.480","5":"5","6":"1","7":"male","8":"74.0"},{"1":"032","2":"72.0","3":"62.0","4":"69.480","5":"5","6":"2","7":"male","8":"72.0"},{"1":"032","2":"72.0","3":"62.0","4":"69.480","5":"5","6":"3","7":"male","8":"69.0"},{"1":"032","2":"72.0","3":"62.0","4":"69.480","5":"5","6":"4","7":"female","8":"67.5"},{"1":"032","2":"72.0","3":"62.0","4":"69.480","5":"5","6":"5","7":"female","8":"63.5"},{"1":"033","2":"72.0","3":"62.0","4":"69.480","5":"5","6":"1","7":"male","8":"72.0"},{"1":"033","2":"72.0","3":"62.0","4":"69.480","5":"5","6":"2","7":"male","8":"71.5"},{"1":"033","2":"72.0","3":"62.0","4":"69.480","5":"5","6":"3","7":"male","8":"71.5"},{"1":"033","2":"72.0","3":"62.0","4":"69.480","5":"5","6":"4","7":"male","8":"70.0"},{"1":"033","2":"72.0","3":"62.0","4":"69.480","5":"5","6":"5","7":"female","8":"68.0"},{"1":"034","2":"72.0","3":"61.0","4":"68.940","5":"1","6":"1","7":"female","8":"65.7"},{"1":"035","2":"71.0","3":"69.0","4":"72.760","5":"5","6":"1","7":"male","8":"78.0"},{"1":"035","2":"71.0","3":"69.0","4":"72.760","5":"5","6":"2","7":"male","8":"74.0"},{"1":"035","2":"71.0","3":"69.0","4":"72.760","5":"5","6":"3","7":"male","8":"73.0"},{"1":"035","2":"71.0","3":"69.0","4":"72.760","5":"5","6":"4","7":"male","8":"72.0"},{"1":"035","2":"71.0","3":"69.0","4":"72.760","5":"5","6":"5","7":"female","8":"67.0"},{"1":"036","2":"71.0","3":"67.0","4":"71.680","5":"4","6":"1","7":"male","8":"73.2"},{"1":"036","2":"71.0","3":"67.0","4":"71.680","5":"4","6":"2","7":"male","8":"73.0"},{"1":"036","2":"71.0","3":"67.0","4":"71.680","5":"4","6":"3","7":"male","8":"69.0"},{"1":"036","2":"71.0","3":"67.0","4":"71.680","5":"4","6":"4","7":"female","8":"67.0"},{"1":"037","2":"71.0","3":"66.0","4":"71.140","5":"4","6":"1","7":"male","8":"70.0"},{"1":"037","2":"71.0","3":"66.0","4":"71.140","5":"4","6":"2","7":"female","8":"67.0"},{"1":"037","2":"71.0","3":"66.0","4":"71.140","5":"4","6":"3","7":"female","8":"67.0"},{"1":"037","2":"71.0","3":"66.0","4":"71.140","5":"4","6":"4","7":"female","8":"66.5"},{"1":"038","2":"71.0","3":"66.0","4":"71.140","5":"6","6":"1","7":"male","8":"70.0"},{"1":"038","2":"71.0","3":"66.0","4":"71.140","5":"6","6":"2","7":"male","8":"69.0"},{"1":"038","2":"71.0","3":"66.0","4":"71.140","5":"6","6":"3","7":"male","8":"68.5"},{"1":"038","2":"71.0","3":"66.0","4":"71.140","5":"6","6":"4","7":"female","8":"66.0"},{"1":"038","2":"71.0","3":"66.0","4":"71.140","5":"6","6":"5","7":"female","8":"64.5"},{"1":"038","2":"71.0","3":"66.0","4":"71.140","5":"6","6":"6","7":"female","8":"63.0"},{"1":"039","2":"71.0","3":"66.0","4":"71.140","5":"2","6":"1","7":"male","8":"71.0"},{"1":"039","2":"71.0","3":"66.0","4":"71.140","5":"2","6":"2","7":"female","8":"67.0"},{"1":"040","2":"71.0","3":"66.0","4":"71.140","5":"5","6":"1","7":"male","8":"76.0"},{"1":"040","2":"71.0","3":"66.0","4":"71.140","5":"5","6":"2","7":"male","8":"72.0"},{"1":"040","2":"71.0","3":"66.0","4":"71.140","5":"5","6":"3","7":"male","8":"71.0"},{"1":"040","2":"71.0","3":"66.0","4":"71.140","5":"5","6":"4","7":"male","8":"66.0"},{"1":"040","2":"71.0","3":"66.0","4":"71.140","5":"5","6":"5","7":"female","8":"66.0"},{"1":"041","2":"71.7","3":"65.5","4":"71.220","5":"1","6":"1","7":"male","8":"70.5"},{"1":"042","2":"71.0","3":"65.5","4":"70.870","5":"6","6":"1","7":"male","8":"72.0"},{"1":"042","2":"71.0","3":"65.5","4":"70.870","5":"6","6":"2","7":"male","8":"72.0"},{"1":"042","2":"71.0","3":"65.5","4":"70.870","5":"6","6":"3","7":"male","8":"71.0"},{"1":"042","2":"71.0","3":"65.5","4":"70.870","5":"6","6":"4","7":"male","8":"69.0"},{"1":"042","2":"71.0","3":"65.5","4":"70.870","5":"6","6":"5","7":"female","8":"66.0"},{"1":"042","2":"71.0","3":"65.5","4":"70.870","5":"6","6":"6","7":"female","8":"65.0"},{"1":"043","2":"71.5","3":"65.5","4":"71.120","5":"2","6":"1","7":"male","8":"73.0"},{"1":"043","2":"71.5","3":"65.5","4":"71.120","5":"2","6":"2","7":"female","8":"65.2"},{"1":"044","2":"71.5","3":"65.0","4":"70.850","5":"2","6":"1","7":"male","8":"68.5"},{"1":"044","2":"71.5","3":"65.0","4":"70.850","5":"2","6":"2","7":"male","8":"67.7"},{"1":"045","2":"71.0","3":"65.0","4":"70.600","5":"3","6":"1","7":"male","8":"68.0"},{"1":"045","2":"71.0","3":"65.0","4":"70.600","5":"3","6":"2","7":"male","8":"68.0"},{"1":"045","2":"71.0","3":"65.0","4":"70.600","5":"3","6":"3","7":"female","8":"62.0"},{"1":"046","2":"71.0","3":"64.0","4":"70.060","5":"8","6":"1","7":"female","8":"68.0"},{"1":"046","2":"71.0","3":"64.0","4":"70.060","5":"8","6":"2","7":"female","8":"68.0"},{"1":"046","2":"71.0","3":"64.0","4":"70.060","5":"8","6":"3","7":"female","8":"67.5"},{"1":"046","2":"71.0","3":"64.0","4":"70.060","5":"8","6":"4","7":"female","8":"66.5"},{"1":"046","2":"71.0","3":"64.0","4":"70.060","5":"8","6":"5","7":"female","8":"66.5"},{"1":"046","2":"71.0","3":"64.0","4":"70.060","5":"8","6":"6","7":"female","8":"66.0"},{"1":"046","2":"71.0","3":"64.0","4":"70.060","5":"8","6":"7","7":"female","8":"65.5"},{"1":"046","2":"71.0","3":"64.0","4":"70.060","5":"8","6":"8","7":"female","8":"65.0"},{"1":"047","2":"71.7","3":"64.5","4":"70.680","5":"4","6":"1","7":"male","8":"72.0"},{"1":"047","2":"71.7","3":"64.5","4":"70.680","5":"4","6":"2","7":"male","8":"71.0"},{"1":"047","2":"71.7","3":"64.5","4":"70.680","5":"4","6":"3","7":"male","8":"70.5"},{"1":"047","2":"71.7","3":"64.5","4":"70.680","5":"4","6":"4","7":"female","8":"67.0"},{"1":"048","2":"71.0","3":"64.0","4":"70.060","5":"3","6":"1","7":"male","8":"68.0"},{"1":"048","2":"71.0","3":"64.0","4":"70.060","5":"3","6":"2","7":"male","8":"68.0"},{"1":"048","2":"71.0","3":"64.0","4":"70.060","5":"3","6":"3","7":"male","8":"68.0"},{"1":"049","2":"71.5","3":"64.5","4":"70.580","5":"7","6":"1","7":"male","8":"72.0"},{"1":"049","2":"71.5","3":"64.5","4":"70.580","5":"7","6":"2","7":"male","8":"71.0"},{"1":"049","2":"71.5","3":"64.5","4":"70.580","5":"7","6":"3","7":"male","8":"70.0"},{"1":"049","2":"71.5","3":"64.5","4":"70.580","5":"7","6":"4","7":"female","8":"66.0"},{"1":"049","2":"71.5","3":"64.5","4":"70.580","5":"7","6":"5","7":"female","8":"64.5"},{"1":"049","2":"71.5","3":"64.5","4":"70.580","5":"7","6":"6","7":"female","8":"64.5"},{"1":"049","2":"71.5","3":"64.5","4":"70.580","5":"7","6":"7","7":"female","8":"62.0"},{"1":"050","2":"71.0","3":"64.5","4":"70.330","5":"2","6":"1","7":"male","8":"73.0"},{"1":"050","2":"71.0","3":"64.5","4":"70.330","5":"2","6":"2","7":"female","8":"62.0"},{"1":"051","2":"71.2","3":"63.0","4":"69.620","5":"2","6":"1","7":"female","8":"67.5"},{"1":"051","2":"71.2","3":"63.0","4":"69.620","5":"2","6":"2","7":"female","8":"64.5"},{"1":"052","2":"71.0","3":"63.5","4":"69.790","5":"5","6":"1","7":"male","8":"71.0"},{"1":"052","2":"71.0","3":"63.5","4":"69.790","5":"5","6":"2","7":"male","8":"67.0"},{"1":"052","2":"71.0","3":"63.5","4":"69.790","5":"5","6":"3","7":"female","8":"66.0"},{"1":"052","2":"71.0","3":"63.5","4":"69.790","5":"5","6":"4","7":"female","8":"65.0"},{"1":"052","2":"71.0","3":"63.5","4":"69.790","5":"5","6":"5","7":"female","8":"63.5"},{"1":"053","2":"71.0","3":"63.0","4":"69.520","5":"9","6":"1","7":"male","8":"71.0"},{"1":"053","2":"71.0","3":"63.0","4":"69.520","5":"9","6":"2","7":"male","8":"70.0"},{"1":"053","2":"71.0","3":"63.0","4":"69.520","5":"9","6":"3","7":"male","8":"70.0"},{"1":"053","2":"71.0","3":"63.0","4":"69.520","5":"9","6":"4","7":"male","8":"64.0"},{"1":"053","2":"71.0","3":"63.0","4":"69.520","5":"9","6":"5","7":"female","8":"65.0"},{"1":"053","2":"71.0","3":"63.0","4":"69.520","5":"9","6":"6","7":"female","8":"65.0"},{"1":"053","2":"71.0","3":"63.0","4":"69.520","5":"9","6":"7","7":"female","8":"64.0"},{"1":"053","2":"71.0","3":"63.0","4":"69.520","5":"9","6":"8","7":"female","8":"63.0"},{"1":"053","2":"71.0","3":"63.0","4":"69.520","5":"9","6":"9","7":"female","8":"63.0"},{"1":"054","2":"71.0","3":"63.0","4":"69.520","5":"4","6":"1","7":"male","8":"71.0"},{"1":"054","2":"71.0","3":"63.0","4":"69.520","5":"4","6":"2","7":"male","8":"71.0"},{"1":"054","2":"71.0","3":"63.0","4":"69.520","5":"4","6":"3","7":"male","8":"70.0"},{"1":"054","2":"71.0","3":"63.0","4":"69.520","5":"4","6":"4","7":"female","8":"63.5"},{"1":"055","2":"71.0","3":"62.0","4":"68.980","5":"5","6":"1","7":"male","8":"71.0"},{"1":"055","2":"71.0","3":"62.0","4":"68.980","5":"5","6":"2","7":"male","8":"70.0"},{"1":"055","2":"71.0","3":"62.0","4":"68.980","5":"5","6":"3","7":"female","8":"64.5"},{"1":"055","2":"71.0","3":"62.0","4":"68.980","5":"5","6":"4","7":"female","8":"62.5"},{"1":"055","2":"71.0","3":"62.0","4":"68.980","5":"5","6":"5","7":"female","8":"61.5"},{"1":"056","2":"71.0","3":"62.0","4":"68.980","5":"5","6":"1","7":"male","8":"72.0"},{"1":"056","2":"71.0","3":"62.0","4":"68.980","5":"5","6":"2","7":"male","8":"70.5"},{"1":"056","2":"71.0","3":"62.0","4":"68.980","5":"5","6":"3","7":"male","8":"70.5"},{"1":"056","2":"71.0","3":"62.0","4":"68.980","5":"5","6":"4","7":"female","8":"64.5"},{"1":"056","2":"71.0","3":"62.0","4":"68.980","5":"5","6":"5","7":"female","8":"60.0"},{"1":"057","2":"71.0","3":"62.5","4":"69.250","5":"5","6":"1","7":"male","8":"70.0"},{"1":"057","2":"71.0","3":"62.5","4":"69.250","5":"5","6":"2","7":"female","8":"64.0"},{"1":"057","2":"71.0","3":"62.5","4":"69.250","5":"5","6":"3","7":"female","8":"64.0"},{"1":"057","2":"71.0","3":"62.5","4":"69.250","5":"5","6":"4","7":"female","8":"64.0"},{"1":"057","2":"71.0","3":"62.5","4":"69.250","5":"5","6":"5","7":"female","8":"62.5"},{"1":"058","2":"71.0","3":"62.0","4":"68.980","5":"7","6":"1","7":"male","8":"70.5"},{"1":"058","2":"71.0","3":"62.0","4":"68.980","5":"7","6":"2","7":"male","8":"70.0"},{"1":"058","2":"71.0","3":"62.0","4":"68.980","5":"7","6":"3","7":"male","8":"69.0"},{"1":"058","2":"71.0","3":"62.0","4":"68.980","5":"7","6":"4","7":"male","8":"69.0"},{"1":"058","2":"71.0","3":"62.0","4":"68.980","5":"7","6":"5","7":"male","8":"66.0"},{"1":"058","2":"71.0","3":"62.0","4":"68.980","5":"7","6":"6","7":"female","8":"64.5"},{"1":"058","2":"71.0","3":"62.0","4":"68.980","5":"7","6":"7","7":"female","8":"64.0"},{"1":"059","2":"71.0","3":"61.0","4":"68.440","5":"1","6":"1","7":"female","8":"62.0"},{"1":"060","2":"71.0","3":"58.0","4":"66.820","5":"2","6":"1","7":"male","8":"71.5"},{"1":"060","2":"71.0","3":"58.0","4":"66.820","5":"2","6":"2","7":"male","8":"69.0"},{"1":"061","2":"70.0","3":"69.0","4":"72.260","5":"4","6":"1","7":"male","8":"71.0"},{"1":"061","2":"70.0","3":"69.0","4":"72.260","5":"4","6":"2","7":"male","8":"70.0"},{"1":"061","2":"70.0","3":"69.0","4":"72.260","5":"4","6":"3","7":"male","8":"69.0"},{"1":"061","2":"70.0","3":"69.0","4":"72.260","5":"4","6":"4","7":"female","8":"69.0"},{"1":"062","2":"70.0","3":"69.0","4":"72.260","5":"6","6":"1","7":"male","8":"70.0"},{"1":"062","2":"70.0","3":"69.0","4":"72.260","5":"6","6":"2","7":"male","8":"68.7"},{"1":"062","2":"70.0","3":"69.0","4":"72.260","5":"6","6":"3","7":"female","8":"68.0"},{"1":"062","2":"70.0","3":"69.0","4":"72.260","5":"6","6":"4","7":"female","8":"66.0"},{"1":"062","2":"70.0","3":"69.0","4":"72.260","5":"6","6":"5","7":"female","8":"64.0"},{"1":"062","2":"70.0","3":"69.0","4":"72.260","5":"6","6":"6","7":"female","8":"62.0"},{"1":"063","2":"70.0","3":"68.0","4":"71.720","5":"1","6":"1","7":"male","8":"75.0"},{"1":"064","2":"70.0","3":"67.0","4":"71.180","5":"5","6":"1","7":"male","8":"70.0"},{"1":"064","2":"70.0","3":"67.0","4":"71.180","5":"5","6":"2","7":"male","8":"69.0"},{"1":"064","2":"70.0","3":"67.0","4":"71.180","5":"5","6":"3","7":"female","8":"66.0"},{"1":"064","2":"70.0","3":"67.0","4":"71.180","5":"5","6":"4","7":"female","8":"64.0"},{"1":"064","2":"70.0","3":"67.0","4":"71.180","5":"5","6":"5","7":"female","8":"60.0"},{"1":"065","2":"70.0","3":"67.0","4":"71.180","5":"1","6":"1","7":"female","8":"67.5"},{"1":"066","2":"70.0","3":"66.5","4":"70.910","5":"11","6":"1","7":"male","8":"73.0"},{"1":"066","2":"70.0","3":"66.5","4":"70.910","5":"11","6":"2","7":"male","8":"72.0"},{"1":"066","2":"70.0","3":"66.5","4":"70.910","5":"11","6":"3","7":"male","8":"72.0"},{"1":"066","2":"70.0","3":"66.5","4":"70.910","5":"11","6":"4","7":"male","8":"66.5"},{"1":"066","2":"70.0","3":"66.5","4":"70.910","5":"11","6":"5","7":"female","8":"69.2"},{"1":"066","2":"70.0","3":"66.5","4":"70.910","5":"11","6":"6","7":"female","8":"67.2"},{"1":"066","2":"70.0","3":"66.5","4":"70.910","5":"11","6":"7","7":"female","8":"66.5"},{"1":"066","2":"70.0","3":"66.5","4":"70.910","5":"11","6":"8","7":"female","8":"66.0"},{"1":"066","2":"70.0","3":"66.5","4":"70.910","5":"11","6":"9","7":"female","8":"66.0"},{"1":"066","2":"70.0","3":"66.5","4":"70.910","5":"11","6":"10","7":"female","8":"64.2"},{"1":"066","2":"70.0","3":"66.5","4":"70.910","5":"11","6":"11","7":"female","8":"63.7"},{"1":"067","2":"70.5","3":"65.0","4":"70.350","5":"4","6":"1","7":"male","8":"72.0"},{"1":"067","2":"70.5","3":"65.0","4":"70.350","5":"4","6":"2","7":"male","8":"70.2"},{"1":"067","2":"70.5","3":"65.0","4":"70.350","5":"4","6":"3","7":"male","8":"69.0"},{"1":"067","2":"70.5","3":"65.0","4":"70.350","5":"4","6":"4","7":"male","8":"68.5"},{"1":"068","2":"70.5","3":"65.0","4":"70.350","5":"5","6":"1","7":"female","8":"68.0"},{"1":"068","2":"70.5","3":"65.0","4":"70.350","5":"5","6":"2","7":"female","8":"65.0"},{"1":"068","2":"70.5","3":"65.0","4":"70.350","5":"5","6":"3","7":"female","8":"61.5"},{"1":"068","2":"70.5","3":"65.0","4":"70.350","5":"5","6":"4","7":"female","8":"61.0"},{"1":"068","2":"70.5","3":"65.0","4":"70.350","5":"5","6":"5","7":"female","8":"61.0"},{"1":"069","2":"70.0","3":"65.0","4":"70.100","5":"8","6":"1","7":"male","8":"73.0"},{"1":"069","2":"70.0","3":"65.0","4":"70.100","5":"8","6":"2","7":"male","8":"72.0"},{"1":"069","2":"70.0","3":"65.0","4":"70.100","5":"8","6":"3","7":"male","8":"70.5"},{"1":"069","2":"70.0","3":"65.0","4":"70.100","5":"8","6":"4","7":"male","8":"65.0"},{"1":"069","2":"70.0","3":"65.0","4":"70.100","5":"8","6":"5","7":"male","8":"65.0"},{"1":"069","2":"70.0","3":"65.0","4":"70.100","5":"8","6":"6","7":"female","8":"64.5"},{"1":"069","2":"70.0","3":"65.0","4":"70.100","5":"8","6":"7","7":"female","8":"63.0"},{"1":"069","2":"70.0","3":"65.0","4":"70.100","5":"8","6":"8","7":"female","8":"62.0"},{"1":"070","2":"70.0","3":"65.0","4":"70.100","5":"5","6":"1","7":"male","8":"67.0"},{"1":"070","2":"70.0","3":"65.0","4":"70.100","5":"5","6":"2","7":"male","8":"65.0"},{"1":"070","2":"70.0","3":"65.0","4":"70.100","5":"5","6":"3","7":"female","8":"64.5"},{"1":"070","2":"70.0","3":"65.0","4":"70.100","5":"5","6":"4","7":"female","8":"62.5"},{"1":"070","2":"70.0","3":"65.0","4":"70.100","5":"5","6":"5","7":"female","8":"62.5"},{"1":"071","2":"70.0","3":"65.0","4":"70.100","5":"6","6":"1","7":"male","8":"70.0"},{"1":"071","2":"70.0","3":"65.0","4":"70.100","5":"6","6":"2","7":"male","8":"70.0"},{"1":"071","2":"70.0","3":"65.0","4":"70.100","5":"6","6":"3","7":"female","8":"67.0"},{"1":"071","2":"70.0","3":"65.0","4":"70.100","5":"6","6":"4","7":"female","8":"65.0"},{"1":"071","2":"70.0","3":"65.0","4":"70.100","5":"6","6":"5","7":"female","8":"65.0"},{"1":"071","2":"70.0","3":"65.0","4":"70.100","5":"6","6":"6","7":"female","8":"63.0"},{"1":"072","2":"70.0","3":"65.0","4":"70.100","5":"7","6":"1","7":"male","8":"79.0"},{"1":"072","2":"70.0","3":"65.0","4":"70.100","5":"7","6":"2","7":"male","8":"75.0"},{"1":"072","2":"70.0","3":"65.0","4":"70.100","5":"7","6":"3","7":"male","8":"71.0"},{"1":"072","2":"70.0","3":"65.0","4":"70.100","5":"7","6":"4","7":"female","8":"69.0"},{"1":"072","2":"70.0","3":"65.0","4":"70.100","5":"7","6":"5","7":"female","8":"67.0"},{"1":"072","2":"70.0","3":"65.0","4":"70.100","5":"7","6":"6","7":"female","8":"65.7"},{"1":"072","2":"70.0","3":"65.0","4":"70.100","5":"7","6":"7","7":"female","8":"62.0"},{"1":"073","2":"70.0","3":"65.0","4":"70.100","5":"3","6":"1","7":"male","8":"73.0"},{"1":"073","2":"70.0","3":"65.0","4":"70.100","5":"3","6":"2","7":"male","8":"72.5"},{"1":"073","2":"70.0","3":"65.0","4":"70.100","5":"3","6":"3","7":"female","8":"65.0"},{"1":"074","2":"70.0","3":"65.0","4":"70.100","5":"2","6":"1","7":"male","8":"69.0"},{"1":"074","2":"70.0","3":"65.0","4":"70.100","5":"2","6":"2","7":"male","8":"69.0"},{"1":"075","2":"70.0","3":"64.7","4":"69.938","5":"7","6":"1","7":"male","8":"72.0"},{"1":"075","2":"70.0","3":"64.7","4":"69.938","5":"7","6":"2","7":"male","8":"70.0"},{"1":"075","2":"70.0","3":"64.7","4":"69.938","5":"7","6":"3","7":"male","8":"68.7"},{"1":"075","2":"70.0","3":"64.7","4":"69.938","5":"7","6":"4","7":"female","8":"66.5"},{"1":"075","2":"70.0","3":"64.7","4":"69.938","5":"7","6":"5","7":"female","8":"65.5"},{"1":"075","2":"70.0","3":"64.7","4":"69.938","5":"7","6":"6","7":"female","8":"64.7"},{"1":"075","2":"70.0","3":"64.7","4":"69.938","5":"7","6":"7","7":"female","8":"64.5"},{"1":"076","2":"70.0","3":"64.0","4":"69.560","5":"7","6":"1","7":"male","8":"70.7"},{"1":"076","2":"70.0","3":"64.0","4":"69.560","5":"7","6":"2","7":"male","8":"70.0"},{"1":"076","2":"70.0","3":"64.0","4":"69.560","5":"7","6":"3","7":"male","8":"68.0"},{"1":"076","2":"70.0","3":"64.0","4":"69.560","5":"7","6":"4","7":"male","8":"67.0"},{"1":"076","2":"70.0","3":"64.0","4":"69.560","5":"7","6":"5","7":"male","8":"66.0"},{"1":"076","2":"70.0","3":"64.0","4":"69.560","5":"7","6":"6","7":"male","8":"65.0"},{"1":"076","2":"70.0","3":"64.0","4":"69.560","5":"7","6":"7","7":"female","8":"67.0"},{"1":"077","2":"70.0","3":"64.0","4":"69.560","5":"4","6":"1","7":"male","8":"70.0"},{"1":"077","2":"70.0","3":"64.0","4":"69.560","5":"4","6":"2","7":"male","8":"68.0"},{"1":"077","2":"70.0","3":"64.0","4":"69.560","5":"4","6":"3","7":"male","8":"66.7"},{"1":"077","2":"70.0","3":"64.0","4":"69.560","5":"4","6":"4","7":"female","8":"65.5"},{"1":"078","2":"70.0","3":"64.2","4":"69.668","5":"5","6":"1","7":"male","8":"72.0"},{"1":"078","2":"70.0","3":"64.2","4":"69.668","5":"5","6":"2","7":"male","8":"70.0"},{"1":"078","2":"70.0","3":"64.2","4":"69.668","5":"5","6":"3","7":"female","8":"62.5"},{"1":"078","2":"70.0","3":"64.2","4":"69.668","5":"5","6":"4","7":"female","8":"61.2"},{"1":"078","2":"70.0","3":"64.2","4":"69.668","5":"5","6":"5","7":"female","8":"60.1"},{"1":"079","2":"70.5","3":"64.0","4":"69.810","5":"8","6":"1","7":"male","8":"74.0"},{"1":"079","2":"70.5","3":"64.0","4":"69.810","5":"8","6":"2","7":"male","8":"69.5"},{"1":"079","2":"70.5","3":"64.0","4":"69.810","5":"8","6":"3","7":"male","8":"69.0"},{"1":"079","2":"70.5","3":"64.0","4":"69.810","5":"8","6":"4","7":"male","8":"68.0"},{"1":"079","2":"70.5","3":"64.0","4":"69.810","5":"8","6":"5","7":"male","8":"68.0"},{"1":"079","2":"70.5","3":"64.0","4":"69.810","5":"8","6":"6","7":"male","8":"68.0"},{"1":"079","2":"70.5","3":"64.0","4":"69.810","5":"8","6":"7","7":"female","8":"65.5"},{"1":"079","2":"70.5","3":"64.0","4":"69.810","5":"8","6":"8","7":"female","8":"65.0"},{"1":"080","2":"70.5","3":"64.5","4":"70.080","5":"1","6":"1","7":"female","8":"60.0"},{"1":"081","2":"70.0","3":"64.0","4":"69.560","5":"4","6":"1","7":"male","8":"68.0"},{"1":"081","2":"70.0","3":"64.0","4":"69.560","5":"4","6":"2","7":"female","8":"65.0"},{"1":"081","2":"70.0","3":"64.0","4":"69.560","5":"4","6":"3","7":"female","8":"64.0"},{"1":"081","2":"70.0","3":"64.0","4":"69.560","5":"4","6":"4","7":"female","8":"62.0"},{"1":"082","2":"70.0","3":"64.0","4":"69.560","5":"9","6":"1","7":"male","8":"71.0"},{"1":"082","2":"70.0","3":"64.0","4":"69.560","5":"9","6":"2","7":"male","8":"70.0"},{"1":"082","2":"70.0","3":"64.0","4":"69.560","5":"9","6":"3","7":"male","8":"70.0"},{"1":"082","2":"70.0","3":"64.0","4":"69.560","5":"9","6":"4","7":"male","8":"70.0"},{"1":"082","2":"70.0","3":"64.0","4":"69.560","5":"9","6":"5","7":"male","8":"69.5"},{"1":"082","2":"70.0","3":"64.0","4":"69.560","5":"9","6":"6","7":"male","8":"68.5"},{"1":"082","2":"70.0","3":"64.0","4":"69.560","5":"9","6":"7","7":"female","8":"69.0"},{"1":"082","2":"70.0","3":"64.0","4":"69.560","5":"9","6":"8","7":"female","8":"65.0"},{"1":"082","2":"70.0","3":"64.0","4":"69.560","5":"9","6":"9","7":"female","8":"64.0"},{"1":"083","2":"70.0","3":"63.7","4":"69.398","5":"8","6":"1","7":"male","8":"70.0"},{"1":"083","2":"70.0","3":"63.7","4":"69.398","5":"8","6":"2","7":"male","8":"67.0"},{"1":"083","2":"70.0","3":"63.7","4":"69.398","5":"8","6":"3","7":"male","8":"65.5"},{"1":"083","2":"70.0","3":"63.7","4":"69.398","5":"8","6":"4","7":"female","8":"63.7"},{"1":"083","2":"70.0","3":"63.7","4":"69.398","5":"8","6":"5","7":"female","8":"63.2"},{"1":"083","2":"70.0","3":"63.7","4":"69.398","5":"8","6":"6","7":"female","8":"62.5"},{"1":"083","2":"70.0","3":"63.7","4":"69.398","5":"8","6":"7","7":"female","8":"62.2"},{"1":"083","2":"70.0","3":"63.7","4":"69.398","5":"8","6":"8","7":"female","8":"61.0"},{"1":"084","2":"70.5","3":"63.0","4":"69.270","5":"4","6":"1","7":"male","8":"70.0"},{"1":"084","2":"70.5","3":"63.0","4":"69.270","5":"4","6":"2","7":"male","8":"68.5"},{"1":"084","2":"70.5","3":"63.0","4":"69.270","5":"4","6":"3","7":"female","8":"65.5"},{"1":"084","2":"70.5","3":"63.0","4":"69.270","5":"4","6":"4","7":"female","8":"63.5"},{"1":"085","2":"70.5","3":"63.0","4":"69.270","5":"5","6":"1","7":"male","8":"72.5"},{"1":"085","2":"70.5","3":"63.0","4":"69.270","5":"5","6":"2","7":"male","8":"69.0"},{"1":"085","2":"70.5","3":"63.0","4":"69.270","5":"5","6":"3","7":"male","8":"67.0"},{"1":"085","2":"70.5","3":"63.0","4":"69.270","5":"5","6":"4","7":"female","8":"64.5"},{"1":"085","2":"70.5","3":"63.0","4":"69.270","5":"5","6":"5","7":"female","8":"64.0"},{"1":"086","2":"70.0","3":"63.5","4":"69.290","5":"4","6":"1","7":"male","8":"71.0"},{"1":"086","2":"70.0","3":"63.5","4":"69.290","5":"4","6":"2","7":"male","8":"67.5"},{"1":"086","2":"70.0","3":"63.5","4":"69.290","5":"4","6":"3","7":"female","8":"67.5"},{"1":"086","2":"70.0","3":"63.5","4":"69.290","5":"4","6":"4","7":"female","8":"63.5"},{"1":"087","2":"70.0","3":"63.0","4":"69.020","5":"4","6":"1","7":"male","8":"68.0"},{"1":"087","2":"70.0","3":"63.0","4":"69.020","5":"4","6":"2","7":"male","8":"67.0"},{"1":"087","2":"70.0","3":"63.0","4":"69.020","5":"4","6":"3","7":"female","8":"63.7"},{"1":"087","2":"70.0","3":"63.0","4":"69.020","5":"4","6":"4","7":"female","8":"62.0"},{"1":"088","2":"70.0","3":"63.0","4":"69.020","5":"4","6":"1","7":"male","8":"70.0"},{"1":"088","2":"70.0","3":"63.0","4":"69.020","5":"4","6":"2","7":"male","8":"66.5"},{"1":"088","2":"70.0","3":"63.0","4":"69.020","5":"4","6":"3","7":"female","8":"62.0"},{"1":"088","2":"70.0","3":"63.0","4":"69.020","5":"4","6":"4","7":"female","8":"61.0"},{"1":"089","2":"70.5","3":"62.0","4":"68.730","5":"8","6":"1","7":"male","8":"72.0"},{"1":"089","2":"70.5","3":"62.0","4":"68.730","5":"8","6":"2","7":"male","8":"70.0"},{"1":"089","2":"70.5","3":"62.0","4":"68.730","5":"8","6":"3","7":"male","8":"69.5"},{"1":"089","2":"70.5","3":"62.0","4":"68.730","5":"8","6":"4","7":"male","8":"69.5"},{"1":"089","2":"70.5","3":"62.0","4":"68.730","5":"8","6":"5","7":"male","8":"68.0"},{"1":"089","2":"70.5","3":"62.0","4":"68.730","5":"8","6":"6","7":"female","8":"65.0"},{"1":"089","2":"70.5","3":"62.0","4":"68.730","5":"8","6":"7","7":"female","8":"64.0"},{"1":"089","2":"70.5","3":"62.0","4":"68.730","5":"8","6":"8","7":"female","8":"63.0"},{"1":"090","2":"70.3","3":"62.7","4":"69.008","5":"7","6":"1","7":"male","8":"70.7"},{"1":"090","2":"70.3","3":"62.7","4":"69.008","5":"7","6":"2","7":"male","8":"69.7"},{"1":"090","2":"70.3","3":"62.7","4":"69.008","5":"7","6":"3","7":"male","8":"69.2"},{"1":"090","2":"70.3","3":"62.7","4":"69.008","5":"7","6":"4","7":"male","8":"65.2"},{"1":"090","2":"70.3","3":"62.7","4":"69.008","5":"7","6":"5","7":"female","8":"64.0"},{"1":"090","2":"70.3","3":"62.7","4":"69.008","5":"7","6":"6","7":"female","8":"63.5"},{"1":"090","2":"70.3","3":"62.7","4":"69.008","5":"7","6":"7","7":"female","8":"63.2"},{"1":"091","2":"70.5","3":"62.0","4":"68.730","5":"3","6":"1","7":"male","8":"72.0"},{"1":"091","2":"70.5","3":"62.0","4":"68.730","5":"3","6":"2","7":"male","8":"72.0"},{"1":"091","2":"70.5","3":"62.0","4":"68.730","5":"3","6":"3","7":"female","8":"60.0"},{"1":"092","2":"70.0","3":"61.0","4":"67.940","5":"2","6":"1","7":"male","8":"71.2"},{"1":"092","2":"70.0","3":"61.0","4":"67.940","5":"2","6":"2","7":"male","8":"67.0"},{"1":"093","2":"70.0","3":"60.0","4":"67.400","5":"4","6":"1","7":"male","8":"67.0"},{"1":"093","2":"70.0","3":"60.0","4":"67.400","5":"4","6":"2","7":"male","8":"64.5"},{"1":"093","2":"70.0","3":"60.0","4":"67.400","5":"4","6":"3","7":"female","8":"65.0"},{"1":"093","2":"70.0","3":"60.0","4":"67.400","5":"4","6":"4","7":"female","8":"63.0"},{"1":"094","2":"70.0","3":"60.0","4":"67.400","5":"2","6":"1","7":"female","8":"65.0"},{"1":"094","2":"70.0","3":"60.0","4":"67.400","5":"2","6":"2","7":"female","8":"65.0"},{"1":"095","2":"70.0","3":"58.5","4":"66.590","5":"3","6":"1","7":"male","8":"71.5"},{"1":"095","2":"70.0","3":"58.5","4":"66.590","5":"3","6":"2","7":"male","8":"64.5"},{"1":"095","2":"70.0","3":"58.5","4":"66.590","5":"3","6":"3","7":"female","8":"63.0"},{"1":"096","2":"70.0","3":"58.0","4":"66.320","5":"5","6":"1","7":"male","8":"72.0"},{"1":"096","2":"70.0","3":"58.0","4":"66.320","5":"5","6":"2","7":"male","8":"66.0"},{"1":"096","2":"70.0","3":"58.0","4":"66.320","5":"5","6":"3","7":"female","8":"66.0"},{"1":"096","2":"70.0","3":"58.0","4":"66.320","5":"5","6":"4","7":"female","8":"65.0"},{"1":"096","2":"70.0","3":"58.0","4":"66.320","5":"5","6":"5","7":"female","8":"63.0"},{"1":"097","2":"69.0","3":"68.5","4":"71.490","5":"10","6":"1","7":"male","8":"75.0"},{"1":"097","2":"69.0","3":"68.5","4":"71.490","5":"10","6":"2","7":"male","8":"71.0"},{"1":"097","2":"69.0","3":"68.5","4":"71.490","5":"10","6":"3","7":"male","8":"70.0"},{"1":"097","2":"69.0","3":"68.5","4":"71.490","5":"10","6":"4","7":"female","8":"66.0"},{"1":"097","2":"69.0","3":"68.5","4":"71.490","5":"10","6":"5","7":"female","8":"66.0"},{"1":"097","2":"69.0","3":"68.5","4":"71.490","5":"10","6":"6","7":"female","8":"65.5"},{"1":"097","2":"69.0","3":"68.5","4":"71.490","5":"10","6":"7","7":"female","8":"65.0"},{"1":"097","2":"69.0","3":"68.5","4":"71.490","5":"10","6":"8","7":"female","8":"65.0"},{"1":"097","2":"69.0","3":"68.5","4":"71.490","5":"10","6":"9","7":"female","8":"64.0"},{"1":"097","2":"69.0","3":"68.5","4":"71.490","5":"10","6":"10","7":"female","8":"64.0"},{"1":"098","2":"69.0","3":"67.0","4":"70.680","5":"1","6":"1","7":"female","8":"64.0"},{"1":"099","2":"69.0","3":"66.0","4":"70.140","5":"8","6":"1","7":"male","8":"73.0"},{"1":"099","2":"69.0","3":"66.0","4":"70.140","5":"8","6":"2","7":"male","8":"72.0"},{"1":"099","2":"69.0","3":"66.0","4":"70.140","5":"8","6":"3","7":"male","8":"71.7"},{"1":"099","2":"69.0","3":"66.0","4":"70.140","5":"8","6":"4","7":"male","8":"71.5"},{"1":"099","2":"69.0","3":"66.0","4":"70.140","5":"8","6":"5","7":"female","8":"65.5"},{"1":"099","2":"69.0","3":"66.0","4":"70.140","5":"8","6":"6","7":"female","8":"65.0"},{"1":"099","2":"69.0","3":"66.0","4":"70.140","5":"8","6":"7","7":"female","8":"62.7"},{"1":"099","2":"69.0","3":"66.0","4":"70.140","5":"8","6":"8","7":"female","8":"62.5"},{"1":"100","2":"69.0","3":"66.0","4":"70.140","5":"3","6":"1","7":"male","8":"71.2"},{"1":"100","2":"69.0","3":"66.0","4":"70.140","5":"3","6":"2","7":"male","8":"71.0"},{"1":"100","2":"69.0","3":"66.0","4":"70.140","5":"3","6":"3","7":"male","8":"70.0"},{"1":"101","2":"69.0","3":"66.7","4":"70.518","5":"4","6":"1","7":"male","8":"75.0"},{"1":"101","2":"69.0","3":"66.7","4":"70.518","5":"4","6":"2","7":"male","8":"74.0"},{"1":"101","2":"69.0","3":"66.7","4":"70.518","5":"4","6":"3","7":"male","8":"72.0"},{"1":"101","2":"69.0","3":"66.7","4":"70.518","5":"4","6":"4","7":"male","8":"68.5"},{"1":"102","2":"69.0","3":"66.0","4":"70.140","5":"6","6":"1","7":"male","8":"70.0"},{"1":"102","2":"69.0","3":"66.0","4":"70.140","5":"6","6":"2","7":"male","8":"68.5"},{"1":"102","2":"69.0","3":"66.0","4":"70.140","5":"6","6":"3","7":"male","8":"68.0"},{"1":"102","2":"69.0","3":"66.0","4":"70.140","5":"6","6":"4","7":"female","8":"65.0"},{"1":"102","2":"69.0","3":"66.0","4":"70.140","5":"6","6":"5","7":"female","8":"63.0"},{"1":"102","2":"69.0","3":"66.0","4":"70.140","5":"6","6":"6","7":"female","8":"62.5"},{"1":"103","2":"69.0","3":"66.5","4":"70.410","5":"7","6":"1","7":"male","8":"73.0"},{"1":"103","2":"69.0","3":"66.5","4":"70.410","5":"7","6":"2","7":"male","8":"71.0"},{"1":"103","2":"69.0","3":"66.5","4":"70.410","5":"7","6":"3","7":"male","8":"70.5"},{"1":"103","2":"69.0","3":"66.5","4":"70.410","5":"7","6":"4","7":"male","8":"70.5"},{"1":"103","2":"69.0","3":"66.5","4":"70.410","5":"7","6":"5","7":"male","8":"67.0"},{"1":"103","2":"69.0","3":"66.5","4":"70.410","5":"7","6":"6","7":"male","8":"66.0"},{"1":"103","2":"69.0","3":"66.5","4":"70.410","5":"7","6":"7","7":"female","8":"61.0"},{"1":"104","2":"69.5","3":"66.5","4":"70.660","5":"4","6":"1","7":"male","8":"70.5"},{"1":"104","2":"69.5","3":"66.5","4":"70.660","5":"4","6":"2","7":"male","8":"67.5"},{"1":"104","2":"69.5","3":"66.5","4":"70.660","5":"4","6":"3","7":"female","8":"64.5"},{"1":"104","2":"69.5","3":"66.5","4":"70.660","5":"4","6":"4","7":"female","8":"64.0"},{"1":"105","2":"69.0","3":"66.5","4":"70.410","5":"6","6":"1","7":"male","8":"71.0"},{"1":"105","2":"69.0","3":"66.5","4":"70.410","5":"6","6":"2","7":"female","8":"68.5"},{"1":"105","2":"69.0","3":"66.5","4":"70.410","5":"6","6":"3","7":"female","8":"67.5"},{"1":"105","2":"69.0","3":"66.5","4":"70.410","5":"6","6":"4","7":"female","8":"66.0"},{"1":"105","2":"69.0","3":"66.5","4":"70.410","5":"6","6":"5","7":"female","8":"63.0"},{"1":"105","2":"69.0","3":"66.5","4":"70.410","5":"6","6":"6","7":"female","8":"63.0"},{"1":"106","2":"69.5","3":"66.0","4":"70.390","5":"7","6":"1","7":"male","8":"71.0"},{"1":"106","2":"69.5","3":"66.0","4":"70.390","5":"7","6":"2","7":"male","8":"71.0"},{"1":"106","2":"69.5","3":"66.0","4":"70.390","5":"7","6":"3","7":"male","8":"70.5"},{"1":"106","2":"69.5","3":"66.0","4":"70.390","5":"7","6":"4","7":"male","8":"70.5"},{"1":"106","2":"69.5","3":"66.0","4":"70.390","5":"7","6":"5","7":"female","8":"66.5"},{"1":"106","2":"69.5","3":"66.0","4":"70.390","5":"7","6":"6","7":"female","8":"65.5"},{"1":"106","2":"69.5","3":"66.0","4":"70.390","5":"7","6":"7","7":"female","8":"64.5"},{"1":"107","2":"69.0","3":"66.0","4":"70.140","5":"9","6":"1","7":"male","8":"73.0"},{"1":"107","2":"69.0","3":"66.0","4":"70.140","5":"9","6":"2","7":"male","8":"72.0"},{"1":"107","2":"69.0","3":"66.0","4":"70.140","5":"9","6":"3","7":"male","8":"69.0"},{"1":"107","2":"69.0","3":"66.0","4":"70.140","5":"9","6":"4","7":"male","8":"69.0"},{"1":"107","2":"69.0","3":"66.0","4":"70.140","5":"9","6":"5","7":"female","8":"66.5"},{"1":"107","2":"69.0","3":"66.0","4":"70.140","5":"9","6":"6","7":"female","8":"65.5"},{"1":"107","2":"69.0","3":"66.0","4":"70.140","5":"9","6":"7","7":"female","8":"65.5"},{"1":"107","2":"69.0","3":"66.0","4":"70.140","5":"9","6":"8","7":"female","8":"65.0"},{"1":"107","2":"69.0","3":"66.0","4":"70.140","5":"9","6":"9","7":"female","8":"64.0"},{"1":"108","2":"69.0","3":"65.0","4":"69.600","5":"7","6":"1","7":"male","8":"70.0"},{"1":"108","2":"69.0","3":"65.0","4":"69.600","5":"7","6":"2","7":"male","8":"68.5"},{"1":"108","2":"69.0","3":"65.0","4":"69.600","5":"7","6":"3","7":"male","8":"67.0"},{"1":"108","2":"69.0","3":"65.0","4":"69.600","5":"7","6":"4","7":"female","8":"65.0"},{"1":"108","2":"69.0","3":"65.0","4":"69.600","5":"7","6":"5","7":"female","8":"64.0"},{"1":"108","2":"69.0","3":"65.0","4":"69.600","5":"7","6":"6","7":"female","8":"63.5"},{"1":"108","2":"69.0","3":"65.0","4":"69.600","5":"7","6":"7","7":"female","8":"61.0"},{"1":"109","2":"69.5","3":"64.5","4":"69.580","5":"7","6":"1","7":"male","8":"69.7"},{"1":"109","2":"69.5","3":"64.5","4":"69.580","5":"7","6":"2","7":"male","8":"68.0"},{"1":"109","2":"69.5","3":"64.5","4":"69.580","5":"7","6":"3","7":"male","8":"60.0"},{"1":"109","2":"69.5","3":"64.5","4":"69.580","5":"7","6":"4","7":"female","8":"65.2"},{"1":"109","2":"69.5","3":"64.5","4":"69.580","5":"7","6":"5","7":"female","8":"64.5"},{"1":"109","2":"69.5","3":"64.5","4":"69.580","5":"7","6":"6","7":"female","8":"63.7"},{"1":"109","2":"69.5","3":"64.5","4":"69.580","5":"7","6":"7","7":"female","8":"60.0"},{"1":"110","2":"69.2","3":"64.0","4":"69.160","5":"4","6":"1","7":"male","8":"71.7"},{"1":"110","2":"69.2","3":"64.0","4":"69.160","5":"4","6":"2","7":"male","8":"66.5"},{"1":"110","2":"69.2","3":"64.0","4":"69.160","5":"4","6":"3","7":"female","8":"65.0"},{"1":"110","2":"69.2","3":"64.0","4":"69.160","5":"4","6":"4","7":"female","8":"63.5"},{"1":"111","2":"69.0","3":"63.5","4":"68.790","5":"1","6":"1","7":"female","8":"65.5"},{"1":"112","2":"69.0","3":"63.0","4":"68.520","5":"3","6":"1","7":"male","8":"69.0"},{"1":"112","2":"69.0","3":"63.0","4":"68.520","5":"3","6":"2","7":"female","8":"67.5"},{"1":"112","2":"69.0","3":"63.0","4":"68.520","5":"3","6":"3","7":"female","8":"63.5"},{"1":"113","2":"69.0","3":"63.0","4":"68.520","5":"1","6":"1","7":"male","8":"72.0"},{"1":"114","2":"69.0","3":"63.0","4":"68.520","5":"6","6":"1","7":"male","8":"73.0"},{"1":"114","2":"69.0","3":"63.0","4":"68.520","5":"6","6":"2","7":"male","8":"70.0"},{"1":"114","2":"69.0","3":"63.0","4":"68.520","5":"6","6":"3","7":"male","8":"70.0"},{"1":"114","2":"69.0","3":"63.0","4":"68.520","5":"6","6":"4","7":"male","8":"64.0"},{"1":"114","2":"69.0","3":"63.0","4":"68.520","5":"6","6":"5","7":"female","8":"66.0"},{"1":"114","2":"69.0","3":"63.0","4":"68.520","5":"6","6":"6","7":"female","8":"62.0"},{"1":"115","2":"69.0","3":"63.5","4":"68.790","5":"7","6":"1","7":"male","8":"70.5"},{"1":"115","2":"69.0","3":"63.5","4":"68.790","5":"7","6":"2","7":"male","8":"67.0"},{"1":"115","2":"69.0","3":"63.5","4":"68.790","5":"7","6":"3","7":"male","8":"66.0"},{"1":"115","2":"69.0","3":"63.5","4":"68.790","5":"7","6":"4","7":"female","8":"65.0"},{"1":"115","2":"69.0","3":"63.5","4":"68.790","5":"7","6":"5","7":"female","8":"63.0"},{"1":"115","2":"69.0","3":"63.5","4":"68.790","5":"7","6":"6","7":"female","8":"62.0"},{"1":"115","2":"69.0","3":"63.5","4":"68.790","5":"7","6":"7","7":"female","8":"61.0"},{"1":"116","2":"69.0","3":"63.5","4":"68.790","5":"3","6":"1","7":"male","8":"70.5"},{"1":"116","2":"69.0","3":"63.5","4":"68.790","5":"3","6":"2","7":"female","8":"63.7"},{"1":"116","2":"69.0","3":"63.5","4":"68.790","5":"3","6":"3","7":"female","8":"63.0"},{"1":"117","2":"69.7","3":"62.0","4":"68.330","5":"1","6":"1","7":"female","8":"62.5"},{"1":"118","2":"69.5","3":"62.0","4":"68.230","5":"3","6":"1","7":"male","8":"73.0"},{"1":"118","2":"69.5","3":"62.0","4":"68.230","5":"3","6":"2","7":"male","8":"72.0"},{"1":"118","2":"69.5","3":"62.0","4":"68.230","5":"3","6":"3","7":"male","8":"69.0"},{"1":"119","2":"69.0","3":"62.0","4":"67.980","5":"5","6":"1","7":"male","8":"73.0"},{"1":"119","2":"69.0","3":"62.0","4":"67.980","5":"5","6":"2","7":"male","8":"71.0"},{"1":"119","2":"69.0","3":"62.0","4":"67.980","5":"5","6":"3","7":"male","8":"71.0"},{"1":"119","2":"69.0","3":"62.0","4":"67.980","5":"5","6":"4","7":"male","8":"69.0"},{"1":"119","2":"69.0","3":"62.0","4":"67.980","5":"5","6":"5","7":"female","8":"63.0"},{"1":"120","2":"69.5","3":"62.0","4":"68.230","5":"11","6":"1","7":"male","8":"72.0"},{"1":"120","2":"69.5","3":"62.0","4":"68.230","5":"11","6":"2","7":"male","8":"70.0"},{"1":"120","2":"69.5","3":"62.0","4":"68.230","5":"11","6":"3","7":"male","8":"67.8"},{"1":"120","2":"69.5","3":"62.0","4":"68.230","5":"11","6":"4","7":"female","8":"65.2"},{"1":"120","2":"69.5","3":"62.0","4":"68.230","5":"11","6":"5","7":"female","8":"64.7"},{"1":"120","2":"69.5","3":"62.0","4":"68.230","5":"11","6":"6","7":"female","8":"64.5"},{"1":"120","2":"69.5","3":"62.0","4":"68.230","5":"11","6":"7","7":"female","8":"63.5"},{"1":"120","2":"69.5","3":"62.0","4":"68.230","5":"11","6":"8","7":"female","8":"63.5"},{"1":"120","2":"69.5","3":"62.0","4":"68.230","5":"11","6":"9","7":"female","8":"62.5"},{"1":"120","2":"69.5","3":"62.0","4":"68.230","5":"11","6":"10","7":"female","8":"62.0"},{"1":"120","2":"69.5","3":"62.0","4":"68.230","5":"11","6":"11","7":"female","8":"61.5"},{"1":"121","2":"69.0","3":"62.5","4":"68.250","5":"8","6":"1","7":"male","8":"71.0"},{"1":"121","2":"69.0","3":"62.5","4":"68.250","5":"8","6":"2","7":"male","8":"70.0"},{"1":"121","2":"69.0","3":"62.5","4":"68.250","5":"8","6":"3","7":"male","8":"70.0"},{"1":"121","2":"69.0","3":"62.5","4":"68.250","5":"8","6":"4","7":"male","8":"69.0"},{"1":"121","2":"69.0","3":"62.5","4":"68.250","5":"8","6":"5","7":"female","8":"63.5"},{"1":"121","2":"69.0","3":"62.5","4":"68.250","5":"8","6":"6","7":"female","8":"62.5"},{"1":"121","2":"69.0","3":"62.5","4":"68.250","5":"8","6":"7","7":"female","8":"62.5"},{"1":"121","2":"69.0","3":"62.5","4":"68.250","5":"8","6":"8","7":"female","8":"62.0"},{"1":"122","2":"69.0","3":"62.0","4":"67.980","5":"4","6":"1","7":"male","8":"72.0"},{"1":"122","2":"69.0","3":"62.0","4":"67.980","5":"4","6":"2","7":"male","8":"68.0"},{"1":"122","2":"69.0","3":"62.0","4":"67.980","5":"4","6":"3","7":"female","8":"66.0"},{"1":"122","2":"69.0","3":"62.0","4":"67.980","5":"4","6":"4","7":"female","8":"66.0"},{"1":"123","2":"69.5","3":"61.0","4":"67.690","5":"5","6":"1","7":"male","8":"70.0"},{"1":"123","2":"69.5","3":"61.0","4":"67.690","5":"5","6":"2","7":"male","8":"69.5"},{"1":"123","2":"69.5","3":"61.0","4":"67.690","5":"5","6":"3","7":"male","8":"69.0"},{"1":"123","2":"69.5","3":"61.0","4":"67.690","5":"5","6":"4","7":"female","8":"63.0"},{"1":"123","2":"69.5","3":"61.0","4":"67.690","5":"5","6":"5","7":"female","8":"62.0"},{"1":"124","2":"69.0","3":"61.0","4":"67.440","5":"9","6":"1","7":"male","8":"68.0"},{"1":"124","2":"69.0","3":"61.0","4":"67.440","5":"9","6":"2","7":"male","8":"68.0"},{"1":"124","2":"69.0","3":"61.0","4":"67.440","5":"9","6":"3","7":"male","8":"67.5"},{"1":"124","2":"69.0","3":"61.0","4":"67.440","5":"9","6":"4","7":"male","8":"64.0"},{"1":"124","2":"69.0","3":"61.0","4":"67.440","5":"9","6":"5","7":"male","8":"63.0"},{"1":"124","2":"69.0","3":"61.0","4":"67.440","5":"9","6":"6","7":"male","8":"63.0"},{"1":"124","2":"69.0","3":"61.0","4":"67.440","5":"9","6":"7","7":"female","8":"63.5"},{"1":"124","2":"69.0","3":"61.0","4":"67.440","5":"9","6":"8","7":"female","8":"62.0"},{"1":"124","2":"69.0","3":"61.0","4":"67.440","5":"9","6":"9","7":"female","8":"62.0"},{"1":"125","2":"69.0","3":"60.0","4":"66.900","5":"3","6":"1","7":"male","8":"70.5"},{"1":"125","2":"69.0","3":"60.0","4":"66.900","5":"3","6":"2","7":"female","8":"68.0"},{"1":"125","2":"69.0","3":"60.0","4":"66.900","5":"3","6":"3","7":"female","8":"62.5"},{"1":"126","2":"69.0","3":"60.0","4":"66.900","5":"4","6":"1","7":"male","8":"69.0"},{"1":"126","2":"69.0","3":"60.0","4":"66.900","5":"4","6":"2","7":"male","8":"66.0"},{"1":"126","2":"69.0","3":"60.0","4":"66.900","5":"4","6":"3","7":"female","8":"61.7"},{"1":"126","2":"69.0","3":"60.0","4":"66.900","5":"4","6":"4","7":"female","8":"60.5"},{"1":"127","2":"69.0","3":"60.5","4":"67.170","5":"1","6":"1","7":"male","8":"69.5"},{"1":"128","2":"68.7","3":"70.5","4":"72.420","5":"2","6":"1","7":"male","8":"71.0"},{"1":"128","2":"68.7","3":"70.5","4":"72.420","5":"2","6":"2","7":"female","8":"61.7"},{"1":"129","2":"68.5","3":"67.0","4":"70.430","5":"3","6":"1","7":"male","8":"73.0"},{"1":"129","2":"68.5","3":"67.0","4":"70.430","5":"3","6":"2","7":"male","8":"71.0"},{"1":"129","2":"68.5","3":"67.0","4":"70.430","5":"3","6":"3","7":"female","8":"67.0"},{"1":"130","2":"68.5","3":"66.5","4":"70.160","5":"11","6":"1","7":"male","8":"70.0"},{"1":"130","2":"68.5","3":"66.5","4":"70.160","5":"11","6":"2","7":"male","8":"69.0"},{"1":"130","2":"68.5","3":"66.5","4":"70.160","5":"11","6":"3","7":"male","8":"69.0"},{"1":"130","2":"68.5","3":"66.5","4":"70.160","5":"11","6":"4","7":"male","8":"68.7"},{"1":"130","2":"68.5","3":"66.5","4":"70.160","5":"11","6":"5","7":"male","8":"68.5"},{"1":"130","2":"68.5","3":"66.5","4":"70.160","5":"11","6":"6","7":"male","8":"68.5"},{"1":"130","2":"68.5","3":"66.5","4":"70.160","5":"11","6":"7","7":"male","8":"68.0"},{"1":"130","2":"68.5","3":"66.5","4":"70.160","5":"11","6":"8","7":"male","8":"68.0"},{"1":"130","2":"68.5","3":"66.5","4":"70.160","5":"11","6":"9","7":"male","8":"68.0"},{"1":"130","2":"68.5","3":"66.5","4":"70.160","5":"11","6":"10","7":"male","8":"66.2"},{"1":"130","2":"68.5","3":"66.5","4":"70.160","5":"11","6":"11","7":"female","8":"63.2"},{"1":"131","2":"68.0","3":"65.0","4":"69.100","5":"2","6":"1","7":"male","8":"67.5"},{"1":"131","2":"68.0","3":"65.0","4":"69.100","5":"2","6":"2","7":"male","8":"66.0"},{"1":"132","2":"68.0","3":"65.5","4":"69.370","5":"2","6":"1","7":"male","8":"66.0"},{"1":"132","2":"68.0","3":"65.5","4":"69.370","5":"2","6":"2","7":"female","8":"64.0"},{"1":"133","2":"68.0","3":"65.5","4":"69.370","5":"7","6":"1","7":"male","8":"71.7"},{"1":"133","2":"68.0","3":"65.5","4":"69.370","5":"7","6":"2","7":"male","8":"71.5"},{"1":"133","2":"68.0","3":"65.5","4":"69.370","5":"7","6":"3","7":"male","8":"70.7"},{"1":"133","2":"68.0","3":"65.5","4":"69.370","5":"7","6":"4","7":"male","8":"65.5"},{"1":"133","2":"68.0","3":"65.5","4":"69.370","5":"7","6":"5","7":"female","8":"66.5"},{"1":"133","2":"68.0","3":"65.5","4":"69.370","5":"7","6":"6","7":"female","8":"65.2"},{"1":"133","2":"68.0","3":"65.5","4":"69.370","5":"7","6":"7","7":"female","8":"61.5"},{"1":"134","2":"68.0","3":"65.0","4":"69.100","5":"4","6":"1","7":"male","8":"72.0"},{"1":"134","2":"68.0","3":"65.0","4":"69.100","5":"4","6":"2","7":"male","8":"72.0"},{"1":"134","2":"68.0","3":"65.0","4":"69.100","5":"4","6":"3","7":"female","8":"68.0"},{"1":"134","2":"68.0","3":"65.0","4":"69.100","5":"4","6":"4","7":"female","8":"66.0"},{"1":"135","2":"68.5","3":"65.0","4":"69.350","5":"8","6":"1","7":"male","8":"69.2"},{"1":"135","2":"68.5","3":"65.0","4":"69.350","5":"8","6":"2","7":"male","8":"68.0"},{"1":"135","2":"68.5","3":"65.0","4":"69.350","5":"8","6":"3","7":"male","8":"66.0"},{"1":"135","2":"68.5","3":"65.0","4":"69.350","5":"8","6":"4","7":"male","8":"66.0"},{"1":"135","2":"68.5","3":"65.0","4":"69.350","5":"8","6":"5","7":"female","8":"62.0"},{"1":"135","2":"68.5","3":"65.0","4":"69.350","5":"8","6":"6","7":"female","8":"61.5"},{"1":"135","2":"68.5","3":"65.0","4":"69.350","5":"8","6":"7","7":"female","8":"61.0"},{"1":"135","2":"68.5","3":"65.0","4":"69.350","5":"8","6":"8","7":"female","8":"60.0"},{"1":"136A","2":"68.5","3":"65.0","4":"69.350","5":"8","6":"1","7":"male","8":"72.0"},{"1":"136A","2":"68.5","3":"65.0","4":"69.350","5":"8","6":"2","7":"male","8":"70.5"},{"1":"136A","2":"68.5","3":"65.0","4":"69.350","5":"8","6":"3","7":"male","8":"68.7"},{"1":"136A","2":"68.5","3":"65.0","4":"69.350","5":"8","6":"4","7":"male","8":"68.5"},{"1":"136A","2":"68.5","3":"65.0","4":"69.350","5":"8","6":"5","7":"male","8":"67.7"},{"1":"136A","2":"68.5","3":"65.0","4":"69.350","5":"8","6":"6","7":"female","8":"64.0"},{"1":"136A","2":"68.5","3":"65.0","4":"69.350","5":"8","6":"7","7":"female","8":"63.5"},{"1":"136A","2":"68.5","3":"65.0","4":"69.350","5":"8","6":"8","7":"female","8":"63.0"},{"1":"136","2":"68.0","3":"64.0","4":"68.560","5":"10","6":"1","7":"male","8":"71.0"},{"1":"136","2":"68.0","3":"64.0","4":"68.560","5":"10","6":"2","7":"male","8":"68.0"},{"1":"136","2":"68.0","3":"64.0","4":"68.560","5":"10","6":"3","7":"male","8":"68.0"},{"1":"136","2":"68.0","3":"64.0","4":"68.560","5":"10","6":"4","7":"male","8":"67.0"},{"1":"136","2":"68.0","3":"64.0","4":"68.560","5":"10","6":"5","7":"female","8":"65.0"},{"1":"136","2":"68.0","3":"64.0","4":"68.560","5":"10","6":"6","7":"female","8":"64.0"},{"1":"136","2":"68.0","3":"64.0","4":"68.560","5":"10","6":"7","7":"female","8":"63.0"},{"1":"136","2":"68.0","3":"64.0","4":"68.560","5":"10","6":"8","7":"female","8":"63.0"},{"1":"136","2":"68.0","3":"64.0","4":"68.560","5":"10","6":"9","7":"female","8":"62.0"},{"1":"136","2":"68.0","3":"64.0","4":"68.560","5":"10","6":"10","7":"female","8":"61.0"},{"1":"137","2":"68.0","3":"64.0","4":"68.560","5":"4","6":"1","7":"male","8":"66.0"},{"1":"137","2":"68.0","3":"64.0","4":"68.560","5":"4","6":"2","7":"male","8":"63.0"},{"1":"137","2":"68.0","3":"64.0","4":"68.560","5":"4","6":"3","7":"female","8":"65.5"},{"1":"137","2":"68.0","3":"64.0","4":"68.560","5":"4","6":"4","7":"female","8":"62.0"},{"1":"138","2":"68.0","3":"64.0","4":"68.560","5":"5","6":"1","7":"male","8":"71.2"},{"1":"138","2":"68.0","3":"64.0","4":"68.560","5":"5","6":"2","7":"male","8":"71.2"},{"1":"138","2":"68.0","3":"64.0","4":"68.560","5":"5","6":"3","7":"male","8":"69.0"},{"1":"138","2":"68.0","3":"64.0","4":"68.560","5":"5","6":"4","7":"male","8":"68.5"},{"1":"138","2":"68.0","3":"64.0","4":"68.560","5":"5","6":"5","7":"female","8":"62.5"},{"1":"139","2":"68.0","3":"64.5","4":"68.830","5":"1","6":"1","7":"female","8":"62.0"},{"1":"140","2":"68.0","3":"64.0","4":"68.560","5":"10","6":"1","7":"male","8":"69.0"},{"1":"140","2":"68.0","3":"64.0","4":"68.560","5":"10","6":"2","7":"male","8":"67.0"},{"1":"140","2":"68.0","3":"64.0","4":"68.560","5":"10","6":"3","7":"male","8":"66.0"},{"1":"140","2":"68.0","3":"64.0","4":"68.560","5":"10","6":"4","7":"female","8":"66.0"},{"1":"140","2":"68.0","3":"64.0","4":"68.560","5":"10","6":"5","7":"female","8":"66.0"},{"1":"140","2":"68.0","3":"64.0","4":"68.560","5":"10","6":"6","7":"female","8":"65.0"},{"1":"140","2":"68.0","3":"64.0","4":"68.560","5":"10","6":"7","7":"female","8":"65.0"},{"1":"140","2":"68.0","3":"64.0","4":"68.560","5":"10","6":"8","7":"female","8":"65.0"},{"1":"140","2":"68.0","3":"64.0","4":"68.560","5":"10","6":"9","7":"female","8":"64.0"},{"1":"140","2":"68.0","3":"64.0","4":"68.560","5":"10","6":"10","7":"female","8":"63.0"},{"1":"141","2":"68.0","3":"63.0","4":"68.020","5":"8","6":"1","7":"male","8":"70.5"},{"1":"141","2":"68.0","3":"63.0","4":"68.020","5":"8","6":"2","7":"male","8":"70.0"},{"1":"141","2":"68.0","3":"63.0","4":"68.020","5":"8","6":"3","7":"male","8":"68.0"},{"1":"141","2":"68.0","3":"63.0","4":"68.020","5":"8","6":"4","7":"male","8":"66.0"},{"1":"141","2":"68.0","3":"63.0","4":"68.020","5":"8","6":"5","7":"male","8":"66.0"},{"1":"141","2":"68.0","3":"63.0","4":"68.020","5":"8","6":"6","7":"female","8":"66.0"},{"1":"141","2":"68.0","3":"63.0","4":"68.020","5":"8","6":"7","7":"female","8":"62.0"},{"1":"141","2":"68.0","3":"63.0","4":"68.020","5":"8","6":"8","7":"female","8":"61.5"},{"1":"142","2":"68.5","3":"63.5","4":"68.540","5":"4","6":"1","7":"male","8":"73.5"},{"1":"142","2":"68.5","3":"63.5","4":"68.540","5":"4","6":"2","7":"male","8":"70.0"},{"1":"142","2":"68.5","3":"63.5","4":"68.540","5":"4","6":"3","7":"male","8":"69.5"},{"1":"142","2":"68.5","3":"63.5","4":"68.540","5":"4","6":"4","7":"female","8":"65.5"},{"1":"143","2":"68.0","3":"63.0","4":"68.020","5":"1","6":"1","7":"male","8":"67.0"},{"1":"144","2":"68.0","3":"63.0","4":"68.020","5":"4","6":"1","7":"male","8":"70.0"},{"1":"144","2":"68.0","3":"63.0","4":"68.020","5":"4","6":"2","7":"male","8":"68.0"},{"1":"144","2":"68.0","3":"63.0","4":"68.020","5":"4","6":"3","7":"female","8":"64.5"},{"1":"144","2":"68.0","3":"63.0","4":"68.020","5":"4","6":"4","7":"female","8":"64.0"},{"1":"145","2":"68.0","3":"63.0","4":"68.020","5":"8","6":"1","7":"male","8":"71.0"},{"1":"145","2":"68.0","3":"63.0","4":"68.020","5":"8","6":"2","7":"male","8":"68.0"},{"1":"145","2":"68.0","3":"63.0","4":"68.020","5":"8","6":"3","7":"male","8":"66.0"},{"1":"145","2":"68.0","3":"63.0","4":"68.020","5":"8","6":"4","7":"male","8":"65.5"},{"1":"145","2":"68.0","3":"63.0","4":"68.020","5":"8","6":"5","7":"male","8":"65.0"},{"1":"145","2":"68.0","3":"63.0","4":"68.020","5":"8","6":"6","7":"female","8":"63.0"},{"1":"145","2":"68.0","3":"63.0","4":"68.020","5":"8","6":"7","7":"female","8":"62.0"},{"1":"145","2":"68.0","3":"63.0","4":"68.020","5":"8","6":"8","7":"female","8":"62.0"},{"1":"146","2":"68.0","3":"63.0","4":"68.020","5":"6","6":"1","7":"male","8":"67.0"},{"1":"146","2":"68.0","3":"63.0","4":"68.020","5":"6","6":"2","7":"male","8":"67.0"},{"1":"146","2":"68.0","3":"63.0","4":"68.020","5":"6","6":"3","7":"male","8":"66.0"},{"1":"146","2":"68.0","3":"63.0","4":"68.020","5":"6","6":"4","7":"female","8":"64.0"},{"1":"146","2":"68.0","3":"63.0","4":"68.020","5":"6","6":"5","7":"female","8":"63.5"},{"1":"146","2":"68.0","3":"63.0","4":"68.020","5":"6","6":"6","7":"female","8":"61.0"},{"1":"147","2":"68.5","3":"63.5","4":"68.540","5":"1","6":"1","7":"male","8":"68.2"},{"1":"148","2":"68.0","3":"63.0","4":"68.020","5":"1","6":"1","7":"male","8":"70.0"},{"1":"149","2":"68.2","3":"63.5","4":"68.390","5":"5","6":"1","7":"male","8":"70.0"},{"1":"149","2":"68.2","3":"63.5","4":"68.390","5":"5","6":"2","7":"male","8":"69.0"},{"1":"149","2":"68.2","3":"63.5","4":"68.390","5":"5","6":"3","7":"male","8":"67.0"},{"1":"149","2":"68.2","3":"63.5","4":"68.390","5":"5","6":"4","7":"male","8":"65.5"},{"1":"149","2":"68.2","3":"63.5","4":"68.390","5":"5","6":"5","7":"female","8":"64.5"},{"1":"150","2":"68.0","3":"62.5","4":"67.750","5":"1","6":"1","7":"male","8":"68.5"},{"1":"151","2":"68.7","3":"62.0","4":"67.830","5":"2","6":"1","7":"male","8":"67.7"},{"1":"151","2":"68.7","3":"62.0","4":"67.830","5":"2","6":"2","7":"female","8":"61.7"},{"1":"152","2":"68.0","3":"62.5","4":"67.750","5":"1","6":"1","7":"male","8":"66.5"},{"1":"153","2":"68.0","3":"61.0","4":"66.940","5":"5","6":"1","7":"male","8":"68.5"},{"1":"153","2":"68.0","3":"61.0","4":"66.940","5":"5","6":"2","7":"male","8":"68.0"},{"1":"153","2":"68.0","3":"61.0","4":"66.940","5":"5","6":"3","7":"male","8":"64.0"},{"1":"153","2":"68.0","3":"61.0","4":"66.940","5":"5","6":"4","7":"female","8":"63.5"},{"1":"153","2":"68.0","3":"61.0","4":"66.940","5":"5","6":"5","7":"female","8":"63.0"},{"1":"154","2":"68.0","3":"60.2","4":"66.508","5":"1","6":"1","7":"male","8":"66.7"},{"1":"155","2":"68.0","3":"60.0","4":"66.400","5":"7","6":"1","7":"male","8":"64.0"},{"1":"155","2":"68.0","3":"60.0","4":"66.400","5":"7","6":"2","7":"female","8":"61.0"},{"1":"155","2":"68.0","3":"60.0","4":"66.400","5":"7","6":"3","7":"female","8":"61.0"},{"1":"155","2":"68.0","3":"60.0","4":"66.400","5":"7","6":"4","7":"female","8":"60.0"},{"1":"155","2":"68.0","3":"60.0","4":"66.400","5":"7","6":"5","7":"female","8":"60.0"},{"1":"155","2":"68.0","3":"60.0","4":"66.400","5":"7","6":"6","7":"female","8":"60.0"},{"1":"155","2":"68.0","3":"60.0","4":"66.400","5":"7","6":"7","7":"female","8":"56.0"},{"1":"156","2":"68.0","3":"60.0","4":"66.400","5":"4","6":"1","7":"male","8":"67.5"},{"1":"156","2":"68.0","3":"60.0","4":"66.400","5":"4","6":"2","7":"male","8":"67.0"},{"1":"156","2":"68.0","3":"60.0","4":"66.400","5":"4","6":"3","7":"male","8":"66.5"},{"1":"156","2":"68.0","3":"60.0","4":"66.400","5":"4","6":"4","7":"female","8":"60.0"},{"1":"157","2":"68.5","3":"59.0","4":"66.110","5":"1","6":"1","7":"male","8":"69.0"},{"1":"158","2":"68.0","3":"59.0","4":"65.860","5":"10","6":"1","7":"male","8":"68.0"},{"1":"158","2":"68.0","3":"59.0","4":"65.860","5":"10","6":"2","7":"male","8":"65.0"},{"1":"158","2":"68.0","3":"59.0","4":"65.860","5":"10","6":"3","7":"male","8":"64.7"},{"1":"158","2":"68.0","3":"59.0","4":"65.860","5":"10","6":"4","7":"male","8":"64.0"},{"1":"158","2":"68.0","3":"59.0","4":"65.860","5":"10","6":"5","7":"male","8":"64.0"},{"1":"158","2":"68.0","3":"59.0","4":"65.860","5":"10","6":"6","7":"male","8":"63.0"},{"1":"158","2":"68.0","3":"59.0","4":"65.860","5":"10","6":"7","7":"female","8":"65.0"},{"1":"158","2":"68.0","3":"59.0","4":"65.860","5":"10","6":"8","7":"female","8":"65.0"},{"1":"158","2":"68.0","3":"59.0","4":"65.860","5":"10","6":"9","7":"female","8":"62.0"},{"1":"158","2":"68.0","3":"59.0","4":"65.860","5":"10","6":"10","7":"female","8":"61.0"},{"1":"159","2":"67.0","3":"66.2","4":"69.248","5":"5","6":"1","7":"male","8":"72.7"},{"1":"159","2":"67.0","3":"66.2","4":"69.248","5":"5","6":"2","7":"male","8":"72.7"},{"1":"159","2":"67.0","3":"66.2","4":"69.248","5":"5","6":"3","7":"male","8":"71.5"},{"1":"159","2":"67.0","3":"66.2","4":"69.248","5":"5","6":"4","7":"female","8":"65.5"},{"1":"159","2":"67.0","3":"66.2","4":"69.248","5":"5","6":"5","7":"female","8":"63.5"},{"1":"160","2":"67.0","3":"66.5","4":"69.410","5":"1","6":"1","7":"male","8":"71.0"},{"1":"161","2":"67.0","3":"66.0","4":"69.140","5":"8","6":"1","7":"male","8":"73.0"},{"1":"161","2":"67.0","3":"66.0","4":"69.140","5":"8","6":"2","7":"male","8":"71.0"},{"1":"161","2":"67.0","3":"66.0","4":"69.140","5":"8","6":"3","7":"male","8":"70.7"},{"1":"161","2":"67.0","3":"66.0","4":"69.140","5":"8","6":"4","7":"male","8":"70.0"},{"1":"161","2":"67.0","3":"66.0","4":"69.140","5":"8","6":"5","7":"male","8":"69.0"},{"1":"161","2":"67.0","3":"66.0","4":"69.140","5":"8","6":"6","7":"female","8":"68.0"},{"1":"161","2":"67.0","3":"66.0","4":"69.140","5":"8","6":"7","7":"female","8":"65.5"},{"1":"161","2":"67.0","3":"66.0","4":"69.140","5":"8","6":"8","7":"female","8":"62.0"},{"1":"162","2":"67.0","3":"65.0","4":"68.600","5":"6","6":"1","7":"male","8":"69.7"},{"1":"162","2":"67.0","3":"65.0","4":"68.600","5":"6","6":"2","7":"male","8":"67.5"},{"1":"162","2":"67.0","3":"65.0","4":"68.600","5":"6","6":"3","7":"female","8":"65.5"},{"1":"162","2":"67.0","3":"65.0","4":"68.600","5":"6","6":"4","7":"female","8":"65.0"},{"1":"162","2":"67.0","3":"65.0","4":"68.600","5":"6","6":"5","7":"female","8":"64.5"},{"1":"162","2":"67.0","3":"65.0","4":"68.600","5":"6","6":"6","7":"female","8":"63.5"},{"1":"163","2":"67.0","3":"65.5","4":"68.870","5":"5","6":"1","7":"male","8":"70.0"},{"1":"163","2":"67.0","3":"65.5","4":"68.870","5":"5","6":"2","7":"male","8":"69.0"},{"1":"163","2":"67.0","3":"65.5","4":"68.870","5":"5","6":"3","7":"female","8":"65.5"},{"1":"163","2":"67.0","3":"65.5","4":"68.870","5":"5","6":"4","7":"female","8":"65.5"},{"1":"163","2":"67.0","3":"65.5","4":"68.870","5":"5","6":"5","7":"female","8":"63.0"},{"1":"164","2":"67.0","3":"65.5","4":"68.870","5":"4","6":"1","7":"male","8":"70.0"},{"1":"164","2":"67.0","3":"65.5","4":"68.870","5":"4","6":"2","7":"male","8":"67.7"},{"1":"164","2":"67.0","3":"65.5","4":"68.870","5":"4","6":"3","7":"female","8":"63.0"},{"1":"164","2":"67.0","3":"65.5","4":"68.870","5":"4","6":"4","7":"female","8":"60.0"},{"1":"165","2":"67.0","3":"65.0","4":"68.600","5":"3","6":"1","7":"male","8":"65.0"},{"1":"165","2":"67.0","3":"65.0","4":"68.600","5":"3","6":"2","7":"female","8":"62.0"},{"1":"165","2":"67.0","3":"65.0","4":"68.600","5":"3","6":"3","7":"female","8":"62.0"},{"1":"166","2":"67.5","3":"65.0","4":"68.850","5":"11","6":"1","7":"male","8":"71.0"},{"1":"166","2":"67.5","3":"65.0","4":"68.850","5":"11","6":"2","7":"male","8":"69.0"},{"1":"166","2":"67.5","3":"65.0","4":"68.850","5":"11","6":"3","7":"female","8":"64.0"},{"1":"166","2":"67.5","3":"65.0","4":"68.850","5":"11","6":"4","7":"female","8":"64.0"},{"1":"166","2":"67.5","3":"65.0","4":"68.850","5":"11","6":"5","7":"female","8":"63.0"},{"1":"166","2":"67.5","3":"65.0","4":"68.850","5":"11","6":"6","7":"female","8":"63.0"},{"1":"166","2":"67.5","3":"65.0","4":"68.850","5":"11","6":"7","7":"female","8":"63.0"},{"1":"166","2":"67.5","3":"65.0","4":"68.850","5":"11","6":"8","7":"female","8":"63.0"},{"1":"166","2":"67.5","3":"65.0","4":"68.850","5":"11","6":"9","7":"female","8":"63.0"},{"1":"166","2":"67.5","3":"65.0","4":"68.850","5":"11","6":"10","7":"female","8":"62.5"},{"1":"166","2":"67.5","3":"65.0","4":"68.850","5":"11","6":"11","7":"female","8":"62.0"},{"1":"167","2":"67.0","3":"64.0","4":"68.060","5":"4","6":"1","7":"male","8":"71.5"},{"1":"167","2":"67.0","3":"64.0","4":"68.060","5":"4","6":"2","7":"male","8":"70.0"},{"1":"167","2":"67.0","3":"64.0","4":"68.060","5":"4","6":"3","7":"male","8":"67.0"},{"1":"167","2":"67.0","3":"64.0","4":"68.060","5":"4","6":"4","7":"male","8":"67.0"},{"1":"168","2":"67.0","3":"63.5","4":"67.790","5":"8","6":"1","7":"male","8":"71.0"},{"1":"168","2":"67.0","3":"63.5","4":"67.790","5":"8","6":"2","7":"male","8":"70.2"},{"1":"168","2":"67.0","3":"63.5","4":"67.790","5":"8","6":"3","7":"male","8":"69.2"},{"1":"168","2":"67.0","3":"63.5","4":"67.790","5":"8","6":"4","7":"male","8":"68.5"},{"1":"168","2":"67.0","3":"63.5","4":"67.790","5":"8","6":"5","7":"male","8":"68.0"},{"1":"168","2":"67.0","3":"63.5","4":"67.790","5":"8","6":"6","7":"male","8":"67.0"},{"1":"168","2":"67.0","3":"63.5","4":"67.790","5":"8","6":"7","7":"male","8":"65.5"},{"1":"168","2":"67.0","3":"63.5","4":"67.790","5":"8","6":"8","7":"female","8":"63.5"},{"1":"169","2":"67.0","3":"63.0","4":"67.520","5":"3","6":"1","7":"male","8":"69.0"},{"1":"169","2":"67.0","3":"63.0","4":"67.520","5":"3","6":"2","7":"male","8":"68.0"},{"1":"169","2":"67.0","3":"63.0","4":"67.520","5":"3","6":"3","7":"female","8":"63.0"},{"1":"170","2":"67.5","3":"62.0","4":"67.230","5":"5","6":"1","7":"male","8":"70.0"},{"1":"170","2":"67.5","3":"62.0","4":"67.230","5":"5","6":"2","7":"male","8":"69.5"},{"1":"170","2":"67.5","3":"62.0","4":"67.230","5":"5","6":"3","7":"male","8":"69.0"},{"1":"170","2":"67.5","3":"62.0","4":"67.230","5":"5","6":"4","7":"male","8":"68.5"},{"1":"170","2":"67.5","3":"62.0","4":"67.230","5":"5","6":"5","7":"female","8":"66.0"},{"1":"171","2":"67.0","3":"61.0","4":"66.440","5":"1","6":"1","7":"male","8":"67.0"},{"1":"172","2":"66.0","3":"67.0","4":"69.180","5":"8","6":"1","7":"male","8":"70.5"},{"1":"172","2":"66.0","3":"67.0","4":"69.180","5":"8","6":"2","7":"male","8":"70.5"},{"1":"172","2":"66.0","3":"67.0","4":"69.180","5":"8","6":"3","7":"male","8":"67.0"},{"1":"172","2":"66.0","3":"67.0","4":"69.180","5":"8","6":"4","7":"male","8":"66.0"},{"1":"172","2":"66.0","3":"67.0","4":"69.180","5":"8","6":"5","7":"male","8":"66.0"},{"1":"172","2":"66.0","3":"67.0","4":"69.180","5":"8","6":"6","7":"female","8":"62.0"},{"1":"172","2":"66.0","3":"67.0","4":"69.180","5":"8","6":"7","7":"female","8":"62.0"},{"1":"172","2":"66.0","3":"67.0","4":"69.180","5":"8","6":"8","7":"female","8":"61.5"},{"1":"173","2":"66.0","3":"67.0","4":"69.180","5":"9","6":"1","7":"male","8":"72.0"},{"1":"173","2":"66.0","3":"67.0","4":"69.180","5":"9","6":"2","7":"male","8":"65.0"},{"1":"173","2":"66.0","3":"67.0","4":"69.180","5":"9","6":"3","7":"male","8":"65.0"},{"1":"173","2":"66.0","3":"67.0","4":"69.180","5":"9","6":"4","7":"female","8":"67.0"},{"1":"173","2":"66.0","3":"67.0","4":"69.180","5":"9","6":"5","7":"female","8":"64.0"},{"1":"173","2":"66.0","3":"67.0","4":"69.180","5":"9","6":"6","7":"female","8":"64.0"},{"1":"173","2":"66.0","3":"67.0","4":"69.180","5":"9","6":"7","7":"female","8":"62.0"},{"1":"173","2":"66.0","3":"67.0","4":"69.180","5":"9","6":"8","7":"female","8":"60.0"},{"1":"173","2":"66.0","3":"67.0","4":"69.180","5":"9","6":"9","7":"female","8":"60.0"},{"1":"174","2":"66.0","3":"66.0","4":"68.640","5":"5","6":"1","7":"male","8":"66.0"},{"1":"174","2":"66.0","3":"66.0","4":"68.640","5":"5","6":"2","7":"male","8":"65.0"},{"1":"174","2":"66.0","3":"66.0","4":"68.640","5":"5","6":"3","7":"female","8":"67.0"},{"1":"174","2":"66.0","3":"66.0","4":"68.640","5":"5","6":"4","7":"female","8":"66.5"},{"1":"174","2":"66.0","3":"66.0","4":"68.640","5":"5","6":"5","7":"female","8":"65.5"},{"1":"175","2":"66.0","3":"66.0","4":"68.640","5":"6","6":"1","7":"male","8":"72.0"},{"1":"175","2":"66.0","3":"66.0","4":"68.640","5":"6","6":"2","7":"male","8":"68.0"},{"1":"175","2":"66.0","3":"66.0","4":"68.640","5":"6","6":"3","7":"female","8":"66.0"},{"1":"175","2":"66.0","3":"66.0","4":"68.640","5":"6","6":"4","7":"female","8":"65.0"},{"1":"175","2":"66.0","3":"66.0","4":"68.640","5":"6","6":"5","7":"female","8":"62.0"},{"1":"175","2":"66.0","3":"66.0","4":"68.640","5":"6","6":"6","7":"female","8":"61.0"},{"1":"176","2":"66.5","3":"65.0","4":"68.350","5":"8","6":"1","7":"male","8":"68.7"},{"1":"176","2":"66.5","3":"65.0","4":"68.350","5":"8","6":"2","7":"male","8":"68.5"},{"1":"176","2":"66.5","3":"65.0","4":"68.350","5":"8","6":"3","7":"male","8":"66.5"},{"1":"176","2":"66.5","3":"65.0","4":"68.350","5":"8","6":"4","7":"male","8":"64.5"},{"1":"176","2":"66.5","3":"65.0","4":"68.350","5":"8","6":"5","7":"female","8":"62.5"},{"1":"176","2":"66.5","3":"65.0","4":"68.350","5":"8","6":"6","7":"female","8":"60.5"},{"1":"176","2":"66.5","3":"65.0","4":"68.350","5":"8","6":"7","7":"female","8":"60.5"},{"1":"176","2":"66.5","3":"65.0","4":"68.350","5":"8","6":"8","7":"female","8":"57.5"},{"1":"177","2":"66.0","3":"65.5","4":"68.370","5":"5","6":"1","7":"male","8":"72.0"},{"1":"177","2":"66.0","3":"65.5","4":"68.370","5":"5","6":"2","7":"male","8":"71.0"},{"1":"177","2":"66.0","3":"65.5","4":"68.370","5":"5","6":"3","7":"male","8":"67.0"},{"1":"177","2":"66.0","3":"65.5","4":"68.370","5":"5","6":"4","7":"female","8":"66.0"},{"1":"177","2":"66.0","3":"65.5","4":"68.370","5":"5","6":"5","7":"female","8":"65.0"},{"1":"178","2":"66.0","3":"63.0","4":"67.020","5":"1","6":"1","7":"male","8":"70.0"},{"1":"179","2":"66.0","3":"63.5","4":"67.290","5":"2","6":"1","7":"female","8":"64.5"},{"1":"179","2":"66.0","3":"63.5","4":"67.290","5":"2","6":"2","7":"female","8":"62.0"},{"1":"180","2":"66.5","3":"63.0","4":"67.270","5":"6","6":"1","7":"male","8":"67.2"},{"1":"180","2":"66.5","3":"63.0","4":"67.270","5":"6","6":"2","7":"male","8":"67.0"},{"1":"180","2":"66.5","3":"63.0","4":"67.270","5":"6","6":"3","7":"male","8":"65.0"},{"1":"180","2":"66.5","3":"63.0","4":"67.270","5":"6","6":"4","7":"female","8":"65.0"},{"1":"180","2":"66.5","3":"63.0","4":"67.270","5":"6","6":"5","7":"female","8":"65.0"},{"1":"180","2":"66.5","3":"63.0","4":"67.270","5":"6","6":"6","7":"female","8":"63.0"},{"1":"181","2":"66.5","3":"62.5","4":"67.000","5":"7","6":"1","7":"male","8":"70.0"},{"1":"181","2":"66.5","3":"62.5","4":"67.000","5":"7","6":"2","7":"male","8":"68.0"},{"1":"181","2":"66.5","3":"62.5","4":"67.000","5":"7","6":"3","7":"female","8":"63.5"},{"1":"181","2":"66.5","3":"62.5","4":"67.000","5":"7","6":"4","7":"female","8":"62.5"},{"1":"181","2":"66.5","3":"62.5","4":"67.000","5":"7","6":"5","7":"female","8":"62.5"},{"1":"181","2":"66.5","3":"62.5","4":"67.000","5":"7","6":"6","7":"female","8":"62.5"},{"1":"181","2":"66.5","3":"62.5","4":"67.000","5":"7","6":"7","7":"female","8":"62.5"},{"1":"182","2":"66.0","3":"61.5","4":"66.210","5":"1","6":"1","7":"male","8":"70.0"},{"1":"183","2":"66.0","3":"60.0","4":"65.400","5":"4","6":"1","7":"male","8":"68.0"},{"1":"183","2":"66.0","3":"60.0","4":"65.400","5":"4","6":"2","7":"male","8":"67.0"},{"1":"183","2":"66.0","3":"60.0","4":"65.400","5":"4","6":"3","7":"male","8":"65.0"},{"1":"183","2":"66.0","3":"60.0","4":"65.400","5":"4","6":"4","7":"female","8":"60.0"},{"1":"184","2":"66.0","3":"60.0","4":"65.400","5":"1","6":"1","7":"male","8":"65.0"},{"1":"185","2":"66.0","3":"59.0","4":"64.860","5":"15","6":"1","7":"male","8":"68.0"},{"1":"185","2":"66.0","3":"59.0","4":"64.860","5":"15","6":"2","7":"male","8":"67.0"},{"1":"185","2":"66.0","3":"59.0","4":"64.860","5":"15","6":"3","7":"male","8":"66.5"},{"1":"185","2":"66.0","3":"59.0","4":"64.860","5":"15","6":"4","7":"male","8":"66.0"},{"1":"185","2":"66.0","3":"59.0","4":"64.860","5":"15","6":"5","7":"male","8":"65.7"},{"1":"185","2":"66.0","3":"59.0","4":"64.860","5":"15","6":"6","7":"male","8":"65.5"},{"1":"185","2":"66.0","3":"59.0","4":"64.860","5":"15","6":"7","7":"male","8":"65.0"},{"1":"185","2":"66.0","3":"59.0","4":"64.860","5":"15","6":"8","7":"female","8":"65.0"},{"1":"185","2":"66.0","3":"59.0","4":"64.860","5":"15","6":"9","7":"female","8":"64.0"},{"1":"185","2":"66.0","3":"59.0","4":"64.860","5":"15","6":"10","7":"female","8":"63.0"},{"1":"185","2":"66.0","3":"59.0","4":"64.860","5":"15","6":"11","7":"female","8":"62.0"},{"1":"185","2":"66.0","3":"59.0","4":"64.860","5":"15","6":"12","7":"female","8":"61.0"},{"1":"185","2":"66.0","3":"59.0","4":"64.860","5":"15","6":"13","7":"female","8":"60.0"},{"1":"185","2":"66.0","3":"59.0","4":"64.860","5":"15","6":"14","7":"female","8":"58.0"},{"1":"185","2":"66.0","3":"59.0","4":"64.860","5":"15","6":"15","7":"female","8":"57.0"},{"1":"186","2":"65.0","3":"67.0","4":"68.680","5":"4","6":"1","7":"male","8":"66.5"},{"1":"186","2":"65.0","3":"67.0","4":"68.680","5":"4","6":"2","7":"male","8":"66.0"},{"1":"186","2":"65.0","3":"67.0","4":"68.680","5":"4","6":"3","7":"male","8":"66.0"},{"1":"186","2":"65.0","3":"67.0","4":"68.680","5":"4","6":"4","7":"female","8":"65.0"},{"1":"187","2":"65.0","3":"67.0","4":"68.680","5":"1","6":"1","7":"female","8":"63.0"},{"1":"188","2":"65.0","3":"66.0","4":"68.140","5":"4","6":"1","7":"male","8":"63.0"},{"1":"188","2":"65.0","3":"66.0","4":"68.140","5":"4","6":"2","7":"female","8":"63.0"},{"1":"188","2":"65.0","3":"66.0","4":"68.140","5":"4","6":"3","7":"female","8":"63.0"},{"1":"188","2":"65.0","3":"66.0","4":"68.140","5":"4","6":"4","7":"female","8":"60.0"},{"1":"189","2":"65.0","3":"66.0","4":"68.140","5":"5","6":"1","7":"male","8":"67.0"},{"1":"189","2":"65.0","3":"66.0","4":"68.140","5":"5","6":"2","7":"male","8":"66.0"},{"1":"189","2":"65.0","3":"66.0","4":"68.140","5":"5","6":"3","7":"male","8":"65.0"},{"1":"189","2":"65.0","3":"66.0","4":"68.140","5":"5","6":"4","7":"female","8":"65.0"},{"1":"189","2":"65.0","3":"66.0","4":"68.140","5":"5","6":"5","7":"female","8":"61.0"},{"1":"190","2":"65.0","3":"65.0","4":"67.600","5":"9","6":"1","7":"male","8":"69.0"},{"1":"190","2":"65.0","3":"65.0","4":"67.600","5":"9","6":"2","7":"male","8":"68.0"},{"1":"190","2":"65.0","3":"65.0","4":"67.600","5":"9","6":"3","7":"male","8":"68.0"},{"1":"190","2":"65.0","3":"65.0","4":"67.600","5":"9","6":"4","7":"female","8":"65.0"},{"1":"190","2":"65.0","3":"65.0","4":"67.600","5":"9","6":"5","7":"female","8":"65.0"},{"1":"190","2":"65.0","3":"65.0","4":"67.600","5":"9","6":"6","7":"female","8":"62.0"},{"1":"190","2":"65.0","3":"65.0","4":"67.600","5":"9","6":"7","7":"female","8":"62.0"},{"1":"190","2":"65.0","3":"65.0","4":"67.600","5":"9","6":"8","7":"female","8":"61.0"},{"1":"190","2":"65.0","3":"65.0","4":"67.600","5":"9","6":"9","7":"female","8":"59.0"},{"1":"191","2":"65.0","3":"65.5","4":"67.870","5":"2","6":"1","7":"male","8":"70.7"},{"1":"191","2":"65.0","3":"65.5","4":"67.870","5":"2","6":"2","7":"female","8":"65.5"},{"1":"192","2":"65.0","3":"65.0","4":"67.600","5":"6","6":"1","7":"male","8":"69.2"},{"1":"192","2":"65.0","3":"65.0","4":"67.600","5":"6","6":"2","7":"male","8":"69.0"},{"1":"192","2":"65.0","3":"65.0","4":"67.600","5":"6","6":"3","7":"male","8":"68.0"},{"1":"192","2":"65.0","3":"65.0","4":"67.600","5":"6","6":"4","7":"male","8":"67.7"},{"1":"192","2":"65.0","3":"65.0","4":"67.600","5":"6","6":"5","7":"female","8":"64.5"},{"1":"192","2":"65.0","3":"65.0","4":"67.600","5":"6","6":"6","7":"female","8":"60.5"},{"1":"193","2":"65.0","3":"64.0","4":"67.060","5":"6","6":"1","7":"male","8":"67.0"},{"1":"193","2":"65.0","3":"64.0","4":"67.060","5":"6","6":"2","7":"male","8":"67.0"},{"1":"193","2":"65.0","3":"64.0","4":"67.060","5":"6","6":"3","7":"female","8":"64.0"},{"1":"193","2":"65.0","3":"64.0","4":"67.060","5":"6","6":"4","7":"female","8":"64.0"},{"1":"193","2":"65.0","3":"64.0","4":"67.060","5":"6","6":"5","7":"female","8":"62.5"},{"1":"193","2":"65.0","3":"64.0","4":"67.060","5":"6","6":"6","7":"female","8":"60.5"},{"1":"194","2":"65.0","3":"63.0","4":"66.520","5":"2","6":"1","7":"male","8":"70.0"},{"1":"194","2":"65.0","3":"63.0","4":"66.520","5":"2","6":"2","7":"female","8":"63.0"},{"1":"195","2":"65.0","3":"63.0","4":"66.520","5":"3","6":"1","7":"male","8":"66.0"},{"1":"195","2":"65.0","3":"63.0","4":"66.520","5":"3","6":"2","7":"male","8":"66.0"},{"1":"195","2":"65.0","3":"63.0","4":"66.520","5":"3","6":"3","7":"female","8":"63.0"},{"1":"196","2":"65.5","3":"63.0","4":"66.770","5":"4","6":"1","7":"male","8":"71.0"},{"1":"196","2":"65.5","3":"63.0","4":"66.770","5":"4","6":"2","7":"male","8":"71.0"},{"1":"196","2":"65.5","3":"63.0","4":"66.770","5":"4","6":"3","7":"male","8":"69.0"},{"1":"196","2":"65.5","3":"63.0","4":"66.770","5":"4","6":"4","7":"female","8":"63.5"},{"1":"197","2":"65.5","3":"60.0","4":"65.150","5":"5","6":"1","7":"male","8":"68.0"},{"1":"197","2":"65.5","3":"60.0","4":"65.150","5":"5","6":"2","7":"male","8":"68.0"},{"1":"197","2":"65.5","3":"60.0","4":"65.150","5":"5","6":"3","7":"male","8":"67.0"},{"1":"197","2":"65.5","3":"60.0","4":"65.150","5":"5","6":"4","7":"male","8":"67.0"},{"1":"197","2":"65.5","3":"60.0","4":"65.150","5":"5","6":"5","7":"female","8":"62.0"},{"1":"198","2":"64.0","3":"64.0","4":"66.560","5":"7","6":"1","7":"male","8":"71.5"},{"1":"198","2":"64.0","3":"64.0","4":"66.560","5":"7","6":"2","7":"male","8":"68.0"},{"1":"198","2":"64.0","3":"64.0","4":"66.560","5":"7","6":"3","7":"female","8":"65.5"},{"1":"198","2":"64.0","3":"64.0","4":"66.560","5":"7","6":"4","7":"female","8":"64.0"},{"1":"198","2":"64.0","3":"64.0","4":"66.560","5":"7","6":"5","7":"female","8":"62.0"},{"1":"198","2":"64.0","3":"64.0","4":"66.560","5":"7","6":"6","7":"female","8":"62.0"},{"1":"198","2":"64.0","3":"64.0","4":"66.560","5":"7","6":"7","7":"female","8":"61.0"},{"1":"199","2":"64.0","3":"64.0","4":"66.560","5":"7","6":"1","7":"male","8":"70.5"},{"1":"199","2":"64.0","3":"64.0","4":"66.560","5":"7","6":"2","7":"male","8":"68.0"},{"1":"199","2":"64.0","3":"64.0","4":"66.560","5":"7","6":"3","7":"female","8":"67.0"},{"1":"199","2":"64.0","3":"64.0","4":"66.560","5":"7","6":"4","7":"female","8":"65.0"},{"1":"199","2":"64.0","3":"64.0","4":"66.560","5":"7","6":"5","7":"female","8":"64.0"},{"1":"199","2":"64.0","3":"64.0","4":"66.560","5":"7","6":"6","7":"female","8":"64.0"},{"1":"199","2":"64.0","3":"64.0","4":"66.560","5":"7","6":"7","7":"female","8":"60.0"},{"1":"200","2":"64.0","3":"63.0","4":"66.020","5":"1","6":"1","7":"male","8":"64.5"},{"1":"201","2":"64.0","3":"60.0","4":"64.400","5":"2","6":"1","7":"male","8":"66.0"},{"1":"201","2":"64.0","3":"60.0","4":"64.400","5":"2","6":"2","7":"female","8":"60.0"},{"1":"202","2":"63.0","3":"63.5","4":"65.790","5":"2","6":"1","7":"female","8":"68.5"},{"1":"202","2":"63.0","3":"63.5","4":"65.790","5":"2","6":"2","7":"female","8":"63.5"},{"1":"203","2":"62.0","3":"66.0","4":"66.640","5":"3","6":"1","7":"male","8":"64.0"},{"1":"203","2":"62.0","3":"66.0","4":"66.640","5":"3","6":"2","7":"female","8":"62.0"},{"1":"203","2":"62.0","3":"66.0","4":"66.640","5":"3","6":"3","7":"female","8":"61.0"},{"1":"204","2":"62.5","3":"63.0","4":"65.270","5":"2","6":"1","7":"male","8":"66.5"},{"1":"204","2":"62.5","3":"63.0","4":"65.270","5":"2","6":"2","7":"female","8":"57.0"}],"options":{"columns":{"min":{},"max":[9]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>갈톤은 어머니와 딸의 키는 모두 1.08을 곱하여 남자의 키로 환산하 후, 부모의 키와 자식의 키의 관계를 다음과 같은 교차표로 정리하였다.</p>
<p><img src="img/galton-regression-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>갈톤의 시대에는 컴퓨터가 없었으므로 200 여개의 데이터를 일일이 표시하고 계산하는 것은 어려운 일이었다.
그러므로 수치 데이터를 구간으로 나누어 빈도를 표현하는 것이 데이터를 분석하기에 편리하였다.
위의 교차표에서 보듯이 부모의 키와 자식의 키는 양의 상관성을 가지고 있어서 우상향하는 관계를 보인다.</p>
<p>컴퓨터가 보편화된 현대에는 더 이상 구간으로 나눈 빈도표에 의존하지 않고, 원 데이터를 직접적으로 이용하여 관계를 탐색할 수 있다.
그리고 남자와 여자의 키를 모두 남자의 키로 환원시키지 않고도 분석할 수 있다.
다음은 부모의 키와 자신의 키를 산점도로 시각화한 것이다.
<code>childHeight</code>는 자식의 키(인치)이고, <code>midparentHeight</code>는 부모의 키(인치)의 평균이다. 어머니의 키가 아버지의 키보다 평균적으로 작기 때문에 어머니의 키에 1.08을 곱하여 남자의 키로 환산한 후 부모의 중간키(<code>midparentHeight</code>)을 계산하였다.
전반적으로 부모의 중간키가 크면 자식의 키도 큰 경향이 보인다.
산점도에서 아들과 딸의 키는 구별될 수 있도록 다른 색과 모양의 점으로 표현하였다.</p>
<p><img src="R-linear-regression_files/figure-html/unnamed-chunk-5-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>갈톤은 부모와 자식의 키 사이의 관계를 설명하기 위하여 다음처럼 교차표에서 동일한 빈도를 가지는 영역에 대한 등고선을 그렸다.
그리고 빈도의 크기가 달라져도 모두 동일한 방향으로 축을 가지는 타원으로 등고선이 그려지는 것을 관찰하였다.</p>
<p><img src="img/galton-regression-3.png" width="90%" style="display: block; margin: auto;" /></p>
<p>이러한 관찰을 통하여 자식의 키에 대한 부모의 키의 설명력이 <span class="math inline">\(2/3\)</span> 정도이고, 부모의 키가 크거나 작더라도 자식의 키는 어느 정도 평균으로 회귀(regression) 하는 성질이 있다는 것을 주장하였다.
갈톤의 논문이 발표된 후부터 수치형 변수의 선형적 관계를 추정하는 분석을 회귀 분석이라고 불리게 되었다.</p>
<p><img src="img/galton-regression-2.png" width="90%" style="display: block; margin: auto;" /></p>
<p>우리는 현대적 컴퓨터와 <strong>R</strong>을 이용하여 갈톤의 원 데이터를 이용하여 부모의 중간키와 자식의 키의 관계에 대하여 다음과 같은 관계식을 도출할 수 잇다.</p>
<p><span class="math display">\[
childHeight = 16.514
  + 0.687 \times midparentHeight
  + 5.215 \times \mathbf{1}(gender = male)
\]</span></p>
<ul>
<li>부모의 키가 1인치 커지면 자신의 키는 평균적으로 0.687 커진다.</li>
<li>아들의 키는 딸의 키보다 평균적으로 5.215 인치 더 크다.</li>
</ul>
<p>부모의 키와 자식의 키의 관계를 나타내는 위의 직선의 방정식은 다음과 같이 시각화 할 수 있다.</p>
<p><img src="R-linear-regression_files/figure-html/unnamed-chunk-9-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>선형 회귀(Linear Regression)는 설명하고자 하는 종속변수(자식의 키)를 독립변수(부모의 중간키)로 설명하는 모형으로 독립변수와 종속변수 사이의 선형적 관계를 가정한다.<a href="#fn19" class="footnote-ref" id="fnref19"><sup>19</sup></a>
그러므로 선형 회귀는 종속변수와 독립변수 사이의 복잡한 비선형 관계를 가정하는 모형에 비하여 단순한 모형처럼 보인다.
그러나 아직도 많이 사용되는 기법의 하나이며, 현대적 통계 분석 기법들은 선형 회귀를 일반화하거나 확장시킨 모형들이 많다.
그러므로 선형 회귀에 대해 명확한 이해하는 것이 복잡한 통계 분석 기법을 이해하는 데 큰 길라잡이가 될 수 있다.</p>
<div id="sec-simple-linear-regression" class="section level2 hasAnchor" number="17.1">
<h2><span class="header-section-number">17.1</span> 단순 선형 회귀<a href="ch-R-linear-regression.html#sec-simple-linear-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="sec-cars" class="section level3 hasAnchor" number="17.1.1">
<h3><span class="header-section-number">17.1.1</span> <code>cars</code> 데이터<a href="ch-R-linear-regression.html#sec-cars" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><code>cars</code> 데이터는 1920년대에 자동차의 속도와 제동거리를 측정한 데이터이다.</p>
<ul>
<li><code>speed</code>는 자동차의 속도를 mph로 측정한 열</li>
<li><code>dist</code>는 제동거리를 ft로 측정한 열</li>
</ul>
<p>데이터에 대한 기본 통계치를 구해보자.</p>
<div class="sourceCode" id="cb2790"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2790-1"><a href="ch-R-linear-regression.html#cb2790-1" tabindex="-1"></a><span class="fu">summary</span>(cars)</span></code></pre></div>
<pre><code>     speed           dist       
 Min.   : 4.0   Min.   :  2.00  
 1st Qu.:12.0   1st Qu.: 26.00  
 Median :15.0   Median : 36.00  
 Mean   :15.4   Mean   : 42.98  
 3rd Qu.:19.0   3rd Qu.: 56.00  
 Max.   :25.0   Max.   :120.00  </code></pre>
<p>자동차의 속도와 제동거리의 관계를 탐색하기 위하여 두 열을 사용하여 산점도를 그려보자.
산점도에서 보듯이 자동차의 속도가 증가하면 제동거리도 증가하는 관계가 있다는 것을 확인할 수 있다.</p>
<div class="sourceCode" id="cb2792"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2792-1"><a href="ch-R-linear-regression.html#cb2792-1" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb2792-2"><a href="ch-R-linear-regression.html#cb2792-2" tabindex="-1"></a><span class="fu">ggplot</span>(cars) <span class="sc">+</span> <span class="fu">geom_point</span>(<span class="fu">aes</span>(speed, dist))</span></code></pre></div>
<p><img src="R-linear-regression_files/figure-html/unnamed-chunk-11-1.png" width="70%" style="display: block; margin: auto;" /></p>
</div>
<div id="sec-simple-linear-regression-theory" class="section level3 hasAnchor" number="17.1.2">
<h3><span class="header-section-number">17.1.2</span> 단순 선형 회귀 모형<a href="ch-R-linear-regression.html#sec-simple-linear-regression-theory" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>단순 선형 회귀는 종속변수 <span class="math inline">\(Y\)</span>를 하나의 독립변수 <span class="math inline">\(X\)</span>로 설명하는 모형이다.
<code>cars</code> 데이터는 자동차의 제동거리를 속도로 설명하고 있으므로, 종속변수는 <code>dist</code>이고 독립변수는 <code>speed</code>이다.</p>
<p>단순 선형 회귀에서는 예측변수 <span class="math inline">\(X\)</span>와 반응변수 <span class="math inline">\(Y\)</span> 간에 근사적으로 선형 관계가 있다고 가정한다.</p>
<p><span class="math display" id="eq:simpleLR">\[\begin{equation}
Y = \beta_0 + \beta_1 X + \varepsilon. \tag{17.1}
\end{equation}\]</span>
단, <span class="math inline">\(\varepsilon\)</span>은 선형 관계로 설명되지 않는 오차항으로 관측 사례마다 독립이고 동일한 정규분포 <span class="math inline">\(\mathcal{N}(0, \sigma^2)\)</span>을 따른다.</p>
<p><a href="ch-R-linear-regression.html#eq:simpleLR">(17.1)</a> 모형을 일컬어 ‘<span class="math inline">\(Y\)</span>를 <span class="math inline">\(X\)</span>에 대해 회귀분석한다.’ 라고 한다.</p>
<p><code>cars</code> 데이터에서 제동거리 <code>dist</code>를 속도 <code>speed</code>에 대하여 회귀분석하는 모형은 다음과 같이 표현된다.</p>
<p><span class="math display">\[
dist \approx \beta_0 + \beta_1 \times speed.
\]</span></p>
<p>단순 선형 회귀는 데이터를 가장 잘 설명하는 모형의 모수 <span class="math inline">\(\beta_0\)</span>(절편)과 <span class="math inline">\(\beta_1\)</span>(기울기)를 추정하는 과정이다.</p>
<p><span class="math inline">\(X\)</span>와 <span class="math inline">\(Y\)</span>에 대한 <span class="math inline">\(n\)</span> 개의 관측치가 있다고 하자.
<span class="math display">\[
  (x_1, y_1), (x_2, y_2), \ldots, (x_n, y_n)
\]</span></p>
<p>단순 선형 회귀의 목적은 주어진 관측치에 대해 <a href="ch-R-linear-regression.html#eq:simpleLR">(17.1)</a>의 모형을 가장 잘 적합시키는 직선의 방정식, 즉, 절편과 기울기의 추정치 <span class="math inline">\(\hat{\beta}_0\)</span>와 <span class="math inline">\(\hat{\beta}_1\)</span>를 찾는 것이다.</p>
<p>다음은 <code>cars</code> 데이터를 설명하는 두 개의 직선을 보여준다.
이 두 직선 중 데이터를 더 잘 설명하는 직선은 무엇일가?
이 질문에 답하기 위해서는 모형이 데이터를 설명하는 정도를 측정할 수 있는 방법이 필요하다.</p>
<p><img src="R-linear-regression_files/figure-html/unnamed-chunk-12-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>회귀 모형이 데이터를 설명하는 정도를 측정하는 방법은 여러 가지가 있지만 가장 대표적인 방법이 최소제곱법(least squares)이다. (최소제곱법은 최소자승법이고도 한다.)
선형 회귀 모형은 <span class="math inline">\(X\)</span>의 <span class="math inline">\(i\)</span> 번째 값에 대한 <span class="math inline">\(Y\)</span>의 값을 다음과 같은 직선의 방정식을 사용하여 설명(예측)한다.</p>
<p><span class="math display">\[
\hat{y}_i = \hat{\beta}_0 + \hat{\beta}_1 x_i
\]</span></p>
<p>그런데 데이터에서 실제 관측치 <span class="math inline">\(y_i\)</span>와 모형의 예측치 <span class="math inline">\(\hat{y}_i\)</span>는 단순한 데이터가 아니라면 차이가 있기 마련이고, 관측치와 예측치의 차이를 잔차(residuals)라고 한다.
<span class="math inline">\(e_i\)</span>를 <span class="math inline">\(i\)</span> 번째 잔차라고 하면 다음과 같이 표현된다.</p>
<p><span class="math display">\[
e_i = y_i - \hat{y}_i
\]</span></p>
<p>다음은 <code>cars</code> 데이터에서 선형 회귀 모형의 잔차를 점선으로 보여준다.</p>
<p><img src="R-linear-regression_files/figure-html/unnamed-chunk-13-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>모형의 모든 잔차의 제곱의 합을 RSS(the residual sum of squares) 또는 SSE(the error sum of squares)라고 한다.</p>
<p><span class="math display">\[
\begin{split}
RSS &amp;= e_1^2 + e_2^2 + \cdots + e_n^2  \\
    &amp;= (y_1 - \hat{\beta}_0 - \hat{\beta}_1 x_1)^2 + (y_2 - \hat{\beta}_0 - \hat{\beta}_1 x_2)^2
        + \cdots + (y_n - \hat{\beta}_0 - \hat{\beta}_1 x_n)^2.
\end{split}
\]</span></p>
<p>최소제곱법에서는 RSS를 최소화하는 <span class="math inline">\(\hat{\beta}_0\)</span>과 <span class="math inline">\(\hat{\beta}_1\)</span>를 선택하고, 그 값은 다음과 같다.</p>
<p><span class="math display">\[\begin{align}
    \hat{\beta}_1 &amp;= \frac{\sum_{i=1}^{n} (x_i - \bar{x})(y_i - \bar{y})}{\sum_{i=1}^{n} (x_i - \bar{x})^2} \\
    \hat{\beta}_0 &amp;= \bar{y} - \hat{\beta}_1 \bar{x},   
\end{align}\]</span>
단, <span class="math inline">\(\bar{y} = \frac{\sum_{i=1}^{n} y_i}{n}\)</span>이고 <span class="math inline">\(\bar{x} = \frac{\sum_{i=1}^{n} x_i}{n}\)</span>이다.</p>
</div>
<div id="sec-lm" class="section level3 hasAnchor" number="17.1.3">
<h3><span class="header-section-number">17.1.3</span> <code>lm()</code> 함수<a href="ch-R-linear-regression.html#sec-lm" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>R</strong>의 기본 패키지인 <code>stats</code>의 <code>lm()</code> 함수는 선형 회귀 모형을 데이터에 적합한다.</p>
<ul>
<li><code>formula</code> 인수: 첫 번째 인수로 데이터에서 종속변수로 사용할 열과 독립변수로 사용할 열을 수식이라는 형태로 설정한다. 단순 선형 회귀에서 수식은 <code>종속변수_열 ~ 독립변수_열</code> 형식으로 지정된다.</li>
<li><code>data</code> 인수: 선형 회귀 모형을 적합할 때 사용할 데이터를 설정한다.</li>
</ul>
<p>다음은 <code>cars</code> 데디터에서 <code>dist</code> 열을 종속변수로 <code>speed</code> 열을 독립변수로 하는 선형 회귀 모형을 적합한 결과이다.</p>
<div class="sourceCode" id="cb2793"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2793-1"><a href="ch-R-linear-regression.html#cb2793-1" tabindex="-1"></a>lm_cars <span class="ot">&lt;-</span> <span class="fu">lm</span>(dist <span class="sc">~</span> speed, <span class="at">data=</span>cars)</span>
<span id="cb2793-2"><a href="ch-R-linear-regression.html#cb2793-2" tabindex="-1"></a>lm_cars</span></code></pre></div>
<pre><code>
Call:
lm(formula = dist ~ speed, data = cars)

Coefficients:
(Intercept)        speed  
    -17.579        3.932  </code></pre>
<p>출력된 결과에서 <code>Call:</code> 영역은 <code>lm()</code> 함수가 어떻게 호출되었는지에 대한 정보이다.
<code>Coefficients:</code>는 추정된 절편(<code>Intercept</code>)과 독립변수(<code>speed</code>)의 기울기이다.
즉, 잔차제곱합을 최소화하는 모형은 다음과 같은 직선이다.</p>
<p><span class="math display">\[
dist = -17.579
        + 3.932 \, speed
\]</span></p>
<p>선형 회귀 모형에 따르면 자동차의 속도가 1 mph 증가할 때마다 평균적으로 제동거리는 3.932 ft 늘어난다.</p>
<p><code>lm()</code> 함수의 결과는 출력된 정보 이외에도 다양한 요소를 가지고 있다.</p>
<ul>
<li><code>$coefficients</code>: 회귀 모형의 계수</li>
<li><code>$residuals</code>: 관측 사례별 모형의 잔차</li>
<li><code>$fitted.values</code>: 관측 사례별 모형의 예측값</li>
</ul>
<div class="sourceCode" id="cb2795"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2795-1"><a href="ch-R-linear-regression.html#cb2795-1" tabindex="-1"></a>lm_cars<span class="sc">$</span>coefficients </span></code></pre></div>
<pre><code>(Intercept)       speed 
 -17.579095    3.932409 </code></pre>
<div class="sourceCode" id="cb2797"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2797-1"><a href="ch-R-linear-regression.html#cb2797-1" tabindex="-1"></a>lm_cars<span class="sc">$</span>residuals</span></code></pre></div>
<pre><code>         1          2          3          4          5          6          7 
  3.849460  11.849460  -5.947766  12.052234   2.119825  -7.812584  -3.744993 
         8          9         10         11         12         13         14 
  4.255007  12.255007  -8.677401   2.322599 -15.609810  -9.609810  -5.609810 
        15         16         17         18         19         20         21 
 -1.609810  -7.542219   0.457781   0.457781  12.457781 -11.474628  -1.474628 
        22         23         24         25         26         27         28 
 22.525372  42.525372 -21.407036 -15.407036  12.592964 -13.339445  -5.339445 
        29         30         31         32         33         34         35 
-17.271854  -9.271854   0.728146 -11.204263   2.795737  22.795737  30.795737 
        36         37         38         39         40         41         42 
-21.136672 -11.136672  10.863328 -29.069080 -13.069080  -9.069080  -5.069080 
        43         44         45         46         47         48         49 
  2.930920  -2.933898 -18.866307  -6.798715  15.201285  16.201285  43.201285 
        50 
  4.268876 </code></pre>
<div class="sourceCode" id="cb2799"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2799-1"><a href="ch-R-linear-regression.html#cb2799-1" tabindex="-1"></a>lm_cars<span class="sc">$</span>fitted.values</span></code></pre></div>
<pre><code>        1         2         3         4         5         6         7         8 
-1.849460 -1.849460  9.947766  9.947766 13.880175 17.812584 21.744993 21.744993 
        9        10        11        12        13        14        15        16 
21.744993 25.677401 25.677401 29.609810 29.609810 29.609810 29.609810 33.542219 
       17        18        19        20        21        22        23        24 
33.542219 33.542219 33.542219 37.474628 37.474628 37.474628 37.474628 41.407036 
       25        26        27        28        29        30        31        32 
41.407036 41.407036 45.339445 45.339445 49.271854 49.271854 49.271854 53.204263 
       33        34        35        36        37        38        39        40 
53.204263 53.204263 53.204263 57.136672 57.136672 57.136672 61.069080 61.069080 
       41        42        43        44        45        46        47        48 
61.069080 61.069080 61.069080 68.933898 72.866307 76.798715 76.798715 76.798715 
       49        50 
76.798715 80.731124 </code></pre>
<p>단순 선형 회귀 모형은 독립변수가 하나이므로, 독립변수를 가로축으로 종속변수를 세로축으로 하는 산점도를 그린 후 모형을 나타내는 직선을 그려 모형이 데이터를 적절히 설명하는지를 시각적으로 탐색해 볼 수 있다.
단순 선형 회귀 모형의 직선을 <code>ggplot2</code> 그래프에 표현하는 방법은 다음 세 가지가 있다.</p>
<ul>
<li><code>geom_smooth(method="lm")</code>으로 선형 회귀 모형 결과로 추세선을 그린다.</li>
<li><code>geom_abline()</code>으로 선형 회귀 모형의 계수를 이용하여 직선을 그린다.</li>
<li><code>geom_line()</code>으로 모형의 예측값을 직선으로 나타낸다.</li>
</ul>
<p>다음은 <code>geom_smooth()</code>로 회귀적합선을 그린 예이다.
<code>geom_smooth()</code>는 회귀적합선뿐 아니라 95% 신뢰구간도 함께 표시해 준다.
신뢰구간을 표시하지 않으려면 <code>se=FALSE</code> 인수를 설정한다.</p>
<div class="sourceCode" id="cb2801"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2801-1"><a href="ch-R-linear-regression.html#cb2801-1" tabindex="-1"></a><span class="fu">ggplot</span>(cars, <span class="fu">aes</span>(speed, dist)) <span class="sc">+</span></span>
<span id="cb2801-2"><a href="ch-R-linear-regression.html#cb2801-2" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb2801-3"><a href="ch-R-linear-regression.html#cb2801-3" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method=</span><span class="st">&quot;lm&quot;</span>)</span></code></pre></div>
<pre><code>`geom_smooth()` using formula = &#39;y ~ x&#39;</code></pre>
<p><img src="R-linear-regression_files/figure-html/unnamed-chunk-18-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p><code>geom_abline()</code>은 절편(intercept)과 기울기(slope)를 지정하여 직선을 그린다.
<code>lm()</code>의 결과의 <code>$coefficients</code> 요소는 모형의 절편과 기울기를 벡터로 가지고 있으므로 이를 사용하여 <code>geom_abline()</code>으로 직선을 그린다.</p>
<div class="sourceCode" id="cb2803"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2803-1"><a href="ch-R-linear-regression.html#cb2803-1" tabindex="-1"></a><span class="fu">ggplot</span>(cars, <span class="fu">aes</span>(speed, dist)) <span class="sc">+</span></span>
<span id="cb2803-2"><a href="ch-R-linear-regression.html#cb2803-2" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb2803-3"><a href="ch-R-linear-regression.html#cb2803-3" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">intercept=</span>lm_cars<span class="sc">$</span>coefficients[<span class="dv">1</span>], <span class="at">slope=</span>lm_cars<span class="sc">$</span>coefficients[<span class="dv">2</span>],</span>
<span id="cb2803-4"><a href="ch-R-linear-regression.html#cb2803-4" tabindex="-1"></a>              <span class="at">color=</span><span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="R-linear-regression_files/figure-html/unnamed-chunk-19-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p><code>geom_line()</code> 함수는 관측점 사이를 직선으로 연결해 준다.
다음에서 <code>geom_point()</code>는 원래의 독립변수와 종속변수 값을 <code>x</code>와 <code>y</code>로 매핑하여 관측점을 표시하였고, <code>geom_line()</code>은 독립변수는 원래의 값을 <code>x</code>에, 모형의 예측값을 <code>y</code>에 매핑하여 선을 그렸다. 모형이 직선이므로 예측값을 이은 선분도 하나의 직선 위에 표시된다.
<code>geom_abline()</code>은 직선의 절편과 기울기로 직선을 그린 것이므로 좌표평면을 모두 가로질러 그려졌지만, <code>geom_line()</code>은 관측사례의 에측값을 선분으로 이어 그린 것이기 때문에 데이터의 범위 안에서만 직선이 그려진다.
<code>geom_smooth()</code>로 그린 직선도 데이터의 범위 안에서만 그려졌는데, <code>geom_line()</code>과 마찬가지로 모형의 예측값을 선분으로 이어 그리기 때문이다.</p>
<div class="sourceCode" id="cb2804"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2804-1"><a href="ch-R-linear-regression.html#cb2804-1" tabindex="-1"></a><span class="fu">ggplot</span>(cars, <span class="fu">aes</span>(speed, dist)) <span class="sc">+</span></span>
<span id="cb2804-2"><a href="ch-R-linear-regression.html#cb2804-2" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb2804-3"><a href="ch-R-linear-regression.html#cb2804-3" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y=</span>lm_cars<span class="sc">$</span>fitted.values), <span class="at">color=</span><span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="R-linear-regression_files/figure-html/unnamed-chunk-20-1.png" width="70%" style="display: block; margin: auto;" /></p>
</div>
<div id="sec-linear-regression-evaluation" class="section level3 hasAnchor" number="17.1.4">
<h3><span class="header-section-number">17.1.4</span> 선형 회귀 모형의 평가<a href="ch-R-linear-regression.html#sec-linear-regression-evaluation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>선형 회귀는 모형의 계수가 추정된 것으로 끝나는 것이 아니라, 모형의 유용성에 대한 평가를 해 봐야 한다.
모형의 유용성에 대한 주요한 평가 항목은 다음과 같다.</p>
<ul>
<li>모형의 통계적 유의성</li>
<li>모형의 설명력</li>
<li>모형의 예측력</li>
<li>모형의 기본 가정의 위배성</li>
</ul>
<div id="모형의-통계적-유의성에-대한-가설검정" class="section level4 unnumbered hasAnchor">
<h4>모형의 통계적 유의성에 대한 가설검정<a href="#%EB%AA%A8%ED%98%95%EC%9D%98-%ED%86%B5%EA%B3%84%EC%A0%81-%EC%9C%A0%EC%9D%98%EC%84%B1%EC%97%90-%EB%8C%80%ED%95%9C-%EA%B0%80%EC%84%A4%EA%B2%80%EC%A0%95" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>선형 회귀 모형은 독립변수가 종속변수에 영향을 미친다는 가정 하에 종속변수의 변화를 설명한다.
그러므로 데이터에 의해 이러한 가정이 지지되는지 검정해 보아야 한다.
모형의 통계적 유의성은 다음과 같은 가설검정을 수행하는 것이다.</p>
<p><span class="math inline">\(H_0\)</span>: 모형의 독립변수는 종속변수에 영향을 미치지 않는다.</p>
<p><span class="math inline">\(H_1\)</span>: 모형의 독립변수는 종속변수에 영향을 미친다.</p>
<p>위의 가설검정은 검정통계량 <span class="math inline">\(F\)</span>를 계산하여 수행한다.</p>
<p><span class="math display">\[\begin{equation}
F = \frac{(TSS - RSS) / p }{RSS/ (n-p-1)}
\end{equation}\]</span>
단, <span class="math inline">\(n\)</span>은 관측 사례의 수, <span class="math inline">\(p\)</span>는 독립변수의 수인데 단순 회귀 모형에서는 <span class="math inline">\(p=1\)</span>이며, <span class="math inline">\(TSS\)</span>, <span class="math inline">\(RSS\)</span> 등은 다음과 같이 정의된다.
<span class="math display">\[\begin{align*}
  TSS &amp;= \sum_{i=1}^{n} (y_i - \bar{y})^2 \\
  RSS &amp;= \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 \\
  TSS - RSS &amp;= \sum_{i=1}^{n} (\hat{y}_i - \bar{y})^2.
\end{align*}\]</span></p>
<p><span class="math inline">\(TSS\)</span>는 총제곱합(the total sum of squares)을 나타내는데 종속변수의 총 변동성을 측정한다. 종속변수의 총 변동성은 자신의 평균과의 관측값 사이의 편차의 제곱의 합으로 구한다.
<span class="math inline">\(RSS\)</span>는 <a href="ch-R-linear-regression.html#sec-simple-linear-regression-theory">17.1.2</a>에서 설명한 바와 같이 종속변수의 관측값과 모형의 예측값 사이의 차이인 잔차를 제곱하여 합한 값으로, 모형이 설명하지 못한 종속변수의 변동성을 측정한다.
<span class="math inline">\(TSS - RSS\)</span>는 모형이 설명한 종속변수의 변동성을 의미한다.
그러므로 <span class="math inline">\(F\)</span>의 분모는 모형이 설명한 종속변수의 변동성과 관련된 항이고, 분자는 모형이 설명 못한 종속변수의 변동성과 관련된 항이다. <span class="math inline">\(F\)</span>의 분모와 분자에 있는 <span class="math inline">\(p\)</span>와 <span class="math inline">\(n-p-1\)</span>은 귀무가설이 맞을 때 분모와 분자의 크기의 평균이 동일해지도록 하는 정규화 인수이다.
따라서 귀무가설이 맞으면 <span class="math inline">\(F \approx 1\)</span>이 되고 대립가설이 맞으면 모형이 설명하는 변동성이 점차 커져서 <span class="math inline">\(F &gt;&gt; 1\)</span>이 된다.</p>
<p>선형 회귀 모형의 기본 가정이 만족되면 검정통계량 <span class="math inline">\(F\)</span>는 자유도가 <span class="math inline">\((p, n-p-1)\)</span>인 F 분포를 따른다. <span class="math inline">\(F_\alpha\)</span> 값을 다음처럼 정의하자.
<span class="math display">\[
\Pr (F &gt; F_\alpha) = \alpha
\]</span>
그러면 유의수준 <span class="math inline">\(\alpha\)</span>에서 모형의 유의성에 대하여 가설검정한다면 <span class="math inline">\(F \le F_\alpha\)</span>이면 귀무가설을 <span class="math inline">\(F &gt; F_\alpha\)</span>이면 대립가설을 채택한다.</p>
<p>모형의 유의성에 대한 가설검정 결과는 <code>lm()</code>의 결과를 <code>summary()</code> 함수로 출력하면 알 수 있다.
이에 대해서는 후술하기로 한다.
단순 선형 회귀 모형에서는 <code>lm()</code>의 결과를 <code>anova()</code> 함수에 전달하여 F-검정의 결과를 쉽게 확인할 수 있다.</p>
<div class="sourceCode" id="cb2805"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2805-1"><a href="ch-R-linear-regression.html#cb2805-1" tabindex="-1"></a><span class="fu">anova</span>(lm_cars)</span></code></pre></div>
<pre><code>Analysis of Variance Table

Response: dist
          Df Sum Sq Mean Sq F value   Pr(&gt;F)    
speed      1  21186 21185.5  89.567 1.49e-12 ***
Residuals 48  11354   236.5                     
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>출력된 분산분석표(Analysis of Variance Table)의 의미는 다음과 같다.</p>
<ul>
<li><code>Response:</code>는 분산분석표가 어떤 종속변수에 대한 변동성(분산)을 분석했는지를 출력한다. 이 예에서는 제동거리(<code>dist</code>)의 분산을 분석한 것이다.</li>
<li>분산분석표는 두 개의 행으로 되어 있는데, 위의 행은 종속변수의 변동성(분산)이 독립변수(<code>speed</code>)에 의해 설명된 부분으로 <span class="math inline">\(F\)</span> 통계량의 분자에 해당하고, 아래 행은 모형에서 설명하지 못하고 잔차(<code>Residuals</code>)로 남아있는 부분으로 <span class="math inline">\(F\)</span> 통계량의 분모에 해당한다.</li>
<li>분산붆석표의 <code>Df</code>는 <span class="math inline">\(F\)</span>의 분자와 분모의 자유도를 나타내며 이 값은 <span class="math inline">\(p\)</span>와 <span class="math inline">\(n-p-1\)</span>이다. 이 예에서는 <span class="math inline">\(p=1\)</span>이고 <span class="math inline">\(n=50\)</span>이므로 1과 48로 계산되었다.</li>
<li>분산분석표의 <code>Sum Sq</code>는 제곱합을 나타내는 열로, 위의 행은 <span class="math inline">\(TSS-RSS\)</span>이고 아래 행은 <span class="math inline">\(RSS\)</span>이다.</li>
<li>분산분석표의 <code>Mean Sq</code>는 제곱합을 정규화 인자로 나눈 값으로 <span class="math inline">\((TSS-RSS)/p\)</span>와 <span class="math inline">\(RSS/(n-p-1)\)</span>로 <span class="math inline">\(F\)</span> 통계량의 분자와 분모의 값이다.</li>
<li>분산분석표의 <code>F value</code>는 <span class="math inline">\(F\)</span> 통계량 값이다.</li>
<li>분산분석표의 <code>Pr(&gt;F)</code>는 F-분포에서 <span class="math inline">\(F\)</span> 통계량보다 큰 값을 가질 확률이다. 이 값은 귀무가설 하에서 검정통계량에서 얼마나 예외적인 값이 발생했는지를 보여주는 p-값이다. 이 값이 매우 작으면 귀무가설로 설명하기에는 예외적인 데이터가 발생한 것으로 간주하여 대립가설을 채택한다.</li>
<li>분산분석표의 <code>Pr(&gt;F)</code>의 별표는 아래 <code>Signif. codes:</code>에 기술된 것처럼 p-값의 크기를 나타내며, 대립가설을 지지하는 통계적 유의성의 정도를 보여준다.
<ul>
<li><code>***</code>이면 p-값이 0.001보다 작다. 그리므로 귀무가설 하에 0.1% 이하로 발생하는 사건이 발생하였음을 의미한다.</li>
<li><code>**</code>이면 p-값이 0.001보다는 크고 0.01 이하</li>
<li><code>*</code>이면 p-값이 0.01보다는 크고 0.05 이하</li>
<li><code>.</code>이면 p-값이 0.05보다 크고 0.1 이하</li>
<li>아무 표시도 없으면 p-값이 0.1보다 크다.</li>
</ul></li>
</ul>
<p>분산분석 결과 p-값이 0.001보다도 작으므로 독립변수(<code>speed</code>)는 종속변수(<code>dist</code>)에 통계적으로 유의미한 영향력를 가지고 있다는 대립가설을 채택한다.</p>
</div>
<div id="모형의-설명력에-대한-평가" class="section level4 unnumbered hasAnchor">
<h4>모형의 설명력에 대한 평가<a href="#%EB%AA%A8%ED%98%95%EC%9D%98-%EC%84%A4%EB%AA%85%EB%A0%A5%EC%97%90-%EB%8C%80%ED%95%9C-%ED%8F%89%EA%B0%80" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>모형의 통계적 유의성에 대한 검정은 독립변수가 종속변수에 유의미한 영향의 유무를 평가하는 것이지, 영향력의 크기는 평가하지 않는다.
그렇기 때문에 통계적으로 유의미한 모형이라도 종속변수의 변동성의 일부만을 설명할 수 있다.
예를 들어 가계의 소비지출액을 가구원의 라이프 스타일로 설명하는 회귀 모형을 만들었다고 하자.
라이프 스타일이 가구원의 소비 행태에 영향을 미치기 때문에 이 모형은 통계적으로 유의미한 모형이 될 수 있다.
그러나 소비지출에 가장 큰 영향력을 미치는 가계의 소득수준이 빠져있기 때문에 이 모형의 소비지출액에 대한 설명력은 제한될 것이다.</p>
<p>모형의 설명력을 평가하는 대표적인 척도가 결정계수(the coefficient of determination) <span class="math inline">\(R^2\)</span>이다.
<span class="math inline">\(R^2\)</span>은 종속변수의 총 변동성(TSS) 중 모형에 의해 설명된 변동성(TSS-RSS)의 비율이다.</p>
<p><span class="math display">\[\begin{equation}
    R^2 = \frac{TSS-RSS}{TSS} = 1 - \frac{RSS}{TSS}
\end{equation}\]</span></p>
<p><span class="math inline">\(R^2\)</span>은 0과 1 사이의 값을 가지며, 모형의 설명력이 커질수록 1에 가까워진다.
단순 선형 회귀 모형에서는 독립변수와 종속변수의 상관계수 <span class="math inline">\(r\)</span>은 <span class="math inline">\(R^2\)</span>와 <span class="math inline">\(R^2 = r^2\)</span>의 관계를 가진다.</p>
<p><span class="math inline">\(R^2\)</span> 척도에 대한 감각을 얻기 위하여 동일한 관계를 가지는 다음 세 가지 시뮬레이션 데이터를 비교해 보자.
세 사례는 모두 <span class="math inline">\(y = 2 + 3x\)</span> 관계에 오차항으로 표준편차가 1, 2, 4인 정규분포를 더하여 데이터를 생성한 것이다.</p>
<p><img src="R-linear-regression_files/figure-html/unnamed-chunk-22-1.png" width="100%" style="display: block; margin: auto;" /></p>
<pre><code>  sigma_1   sigma_2   sigma_4 
0.9109236 0.7146256 0.4292769 </code></pre>
<p>모형으로 설명될 수 없는 오차항의 표준편차가 커질수록 회귀모형에 의해 설명되는 부분이 줄어드는 것을 확인할 수 있다.</p>
<p>그러면 어느 정도의 <span class="math inline">\(R^2\)</span> 값이어야 모형 종속변수를 잘 설명하는 것일까?
이는 문제 상황에 따라 달라진다.
물리 실험 같이 여러 요인을 통제할 수 있는 상황에서 얻은 데이터에서는 <span class="math inline">\(R^2\)</span>가 맨 왼편의 사례처럼 1에 가까워야 한다.
반면 마케팅, 사회과학의 인과관계의 조사처럼 통제할 수 있는 많은 변인들이 존재하는 경우에는 맨 오른편의 사례처럼 훨씬 더 낮은 <span class="math inline">\(R^2\)</span> 값을 보인다.
그러므로 <span class="math inline">\(R^2\)</span>의 적절성은 선행 연구와 도메인 지식을 사용하여 판단해야 한다.</p>
<p>모형의 설명력을 평가하는 또 다른 방법은 모형 오차항의 절대적 크기를 측정하는 것이다.
선형 회귀 모형에서 오차항 <span class="math inline">\(\varepsilon\)</span>은 정규분포 <span class="math inline">\(\mathcal{N}(0, \sigma^2)\)</span>을 따르다고 가정하므로, <span class="math inline">\(\sigma\)</span>의 값이 클수록 모형이 설명하지 못하는 종속변수의 절대적 양이 크다는 것을 의미한다.
오차항의 표준편차 <span class="math inline">\(\sigma\)</span>는 잔차의 표준오차인 RSE(Residual Standard Error)로 추정한다.
RSE는 잔차제곱합(RSS)을 이용하여 다음과 같이 정의된다.</p>
<p><span class="math display">\[\begin{equation}
  RSE = \sqrt{\frac{1}{n-p-1} RSS} = \sqrt{\frac{1}{n-p-1} \sum_{i=1}^{n-2} (y_i - \hat{y}_i)^2}
\end{equation}\]</span></p>
<p>RSE는 데이터가 모회귀선에서 평균적으로 얼마큼 떨어져 있는지에 대한 추정치이다.
<span class="math display">\[
E[RSE] = \sigma
\]</span></p>
<p>다음은 앞서 <span class="math inline">\(R^2\)</span>을 설명할 때 소개한 <span class="math inline">\(y = 2 + 3x\)</span> 관계에 오차항으로 표준편차가 1, 2, 4인 정규분포를 더한 사례에서의 RSE의 추정치를 보여준다.
오류항의 표준편차 1, 2, 4와 가까운 값이 추정되었다.</p>
<pre><code> sigma_1  sigma_2  sigma_4 
1.021690 2.098794 3.935712 </code></pre>
<p>RSE의 크기는 종속변수의 측정 척도에 따라 달라지므로, 모형의 상대적 적합성을 확인할 때는 다음처럼 종속변수의 평균 대비 잔차의 표준오차를 비율을 계산하기도 한다.
<span class="math display">\[
RSE/(\text{종속변수 평균})
\]</span></p>
<p><code>lm()</code> 결과를 <code>summary()</code> 함수로 요약하면 <span class="math inline">\(R^2\)</span>와 RSE 값을 확인할 수 있다.</p>
<div class="sourceCode" id="cb2809"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2809-1"><a href="ch-R-linear-regression.html#cb2809-1" tabindex="-1"></a><span class="fu">summary</span>(lm_cars)</span></code></pre></div>
<pre><code>
Call:
lm(formula = dist ~ speed, data = cars)

Residuals:
    Min      1Q  Median      3Q     Max 
-29.069  -9.525  -2.272   9.215  43.201 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) -17.5791     6.7584  -2.601   0.0123 *  
speed         3.9324     0.4155   9.464 1.49e-12 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 15.38 on 48 degrees of freedom
Multiple R-squared:  0.6511,    Adjusted R-squared:  0.6438 
F-statistic: 89.57 on 1 and 48 DF,  p-value: 1.49e-12</code></pre>
<p><code>summary()</code> 결과는 다음 정보를 보여준다.</p>
<ul>
<li><code>Call:</code> 영역은 <code>lm()</code> 함수 호출 정보</li>
<li><code>Residuals:</code> 영역은 모형의 잔차의 기본 통계량 정보</li>
<li><code>Coefficients:</code> 영역은 모형의 계수 정보로 절편과 기울기에 대한 추정값(<code>Estimate</code>), 추정값의 표준 오차(<code>Std. Error</code>), t-검정량(<code>t value</code>), t-검정량의 p-값(<code>Pr(&gt;|t|)</code>)을 제공</li>
<li><code>Residual standard error:</code>는 RSE 값과 RSE의 자유도 정보</li>
<li><code>Multiple R-squared:</code>는 <span class="math inline">\(R^2\)</span> 값</li>
<li><code>Adjusted R-squared:</code>는 독립변수의 수에 따라 조정된 <span class="math inline">\(R^2\)</span> 값으로 변수 선택을 할 때 이용된다.</li>
<li><code>F-statistic:</code>는 모형의 유의성에 대한 <span class="math inline">\(F\)</span>-검정통계량</li>
<li><code>p-value:</code>는 F-검정통계량의 p-값</li>
</ul>
<p><code>speed</code>로 <code>dist</code>를 설명하는 선형 회귀 모형은 <code>dist</code>의 변동성 중 65.1% 설명하고 있으며, 모형의 RSE는 15.38였다.
<code>dist</code>의 평균 대비 RSE의 크기는 약 0.36이다.</p>
<div class="sourceCode" id="cb2811"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2811-1"><a href="ch-R-linear-regression.html#cb2811-1" tabindex="-1"></a><span class="fl">15.38</span> <span class="sc">/</span> <span class="fu">mean</span>(cars<span class="sc">$</span>dist)</span></code></pre></div>
<pre><code>[1] 0.3578409</code></pre>
</div>
<div id="모형의-예측력에-대한-평가" class="section level4 unnumbered hasAnchor">
<h4>모형의 예측력에 대한 평가<a href="#%EB%AA%A8%ED%98%95%EC%9D%98-%EC%98%88%EC%B8%A1%EB%A0%A5%EC%97%90-%EB%8C%80%ED%95%9C-%ED%8F%89%EA%B0%80" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>모형의 계수를 추정할 때 사용한 데이터를 훈련집합이라고 한다.
모형의 예측력에 대한 평가를 훈련집합으로 하게 되면 모형의 성능을 과대평가하게 된다.
그러므로 훈련집합과 별도의 데이터로 모형의 예측력을 평가해 봐야 한다.
이렇듯 모형의 훈련집합과 별개로 모형의 예측성능을 평가할 때 사용하는 데이터를 평가집합이라고 한다.</p>
<p>앞의 예에서는 <code>cars</code>의 모든 데이터로 모형을 적합하였다.
이번에는 <code>cars</code>의 데이터를 무작위 추출로 7:3 비율로 훈련집합과 평가집합으로 나눠보자.</p>
<p><code>sample()</code> 함수는 벡터의 요소를 무작위 추출해 준다.</p>
<ul>
<li><code>x</code> 인수는 첫 번째 인수로 무작위 추출을 할 벡터가 지정된다. 1보다 큰 자연수가 입력되면 <code>1:x</code> 벡터를 이용하여 무작위 추출된다.</li>
<li><code>size</code> 인수는 무작위 추출의 횟수</li>
<li><code>replace</code> 인수는 복원 추출 여부인데, 기본값은 <code>replace=FALSE</code>로 비복원 추출을 한다.</li>
<li><code>prob</code>는 벡터의 각 요소가 추출될 확률을 나타낸다. 기본값은 <code>NULL</code>로 모든 요소가 동일한 확률로 추출된다.</li>
</ul>
<p><code>cars</code>의 행의 수는 <code>nrow(cars)</code>이므로 1부터 시작하여 <code>nrow(cars)</code>까지의 자연수에서 15 개를 무작위 추출하여 평가집합으로 할당하자.</p>
<div class="sourceCode" id="cb2813"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2813-1"><a href="ch-R-linear-regression.html#cb2813-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)  <span class="co"># 무작위 추출이 동일해지도록 랜덤시드 설정</span></span>
<span id="cb2813-2"><a href="ch-R-linear-regression.html#cb2813-2" tabindex="-1"></a>test_idx <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(cars), <span class="dv">15</span>)</span>
<span id="cb2813-3"><a href="ch-R-linear-regression.html#cb2813-3" tabindex="-1"></a>test_idx</span></code></pre></div>
<pre><code> [1] 31 15 14  3 42 43 37 48 25 26 27  5 40 28  9</code></pre>
<div class="sourceCode" id="cb2815"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2815-1"><a href="ch-R-linear-regression.html#cb2815-1" tabindex="-1"></a>test_df <span class="ot">&lt;-</span> cars[test_idx, ]  <span class="co"># 추출된 인덱스의 행으로 평가집합 할당</span></span>
<span id="cb2815-2"><a href="ch-R-linear-regression.html#cb2815-2" tabindex="-1"></a>test_df</span></code></pre></div>
<pre><code>   speed dist
31    17   50
15    12   28
14    12   24
3      7    4
42    20   56
43    20   64
37    19   46
48    24   93
25    15   26
26    15   54
27    16   32
5      8   16
40    20   48
28    16   40
9     10   34</code></pre>
<div class="sourceCode" id="cb2817"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2817-1"><a href="ch-R-linear-regression.html#cb2817-1" tabindex="-1"></a>train_df <span class="ot">&lt;-</span> cars[<span class="sc">-</span>test_idx, ]  <span class="co"># 추출된 인덱스 이외의 행으로 훈련집합 할당</span></span>
<span id="cb2817-2"><a href="ch-R-linear-regression.html#cb2817-2" tabindex="-1"></a>train_df</span></code></pre></div>
<pre><code>   speed dist
1      4    2
2      4   10
4      7   22
6      9   10
7     10   18
8     10   26
10    11   17
11    11   28
12    12   14
13    12   20
16    13   26
17    13   34
18    13   34
19    13   46
20    14   26
21    14   36
22    14   60
23    14   80
24    15   20
29    17   32
30    17   40
32    18   42
33    18   56
34    18   76
35    18   84
36    19   36
38    19   68
39    20   32
41    20   52
44    22   66
45    23   54
46    24   70
47    24   92
49    24  120
50    25   85</code></pre>
<p>그런 다음 훈련집합으로 선형 회귀 모형을 적합한다.</p>
<div class="sourceCode" id="cb2819"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2819-1"><a href="ch-R-linear-regression.html#cb2819-1" tabindex="-1"></a>lm_train <span class="ot">&lt;-</span> <span class="fu">lm</span>(dist <span class="sc">~</span> speed, <span class="at">data=</span>train_df)</span>
<span id="cb2819-2"><a href="ch-R-linear-regression.html#cb2819-2" tabindex="-1"></a>lm_train</span></code></pre></div>
<pre><code>
Call:
lm(formula = dist ~ speed, data = train_df)

Coefficients:
(Intercept)        speed  
     -16.54         3.92  </code></pre>
<p>이 모형으로 평가집합을 예측한 후, 모형의 예측값과 실제 관측값을 비교해 보자.
<code>predict()</code> 함수에 모형과 예측할 데이터를 지정하면 독립변수만 사용하여 모형으로 종속변수를 예측한다.</p>
<div class="sourceCode" id="cb2821"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2821-1"><a href="ch-R-linear-regression.html#cb2821-1" tabindex="-1"></a>y_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(lm_train, test_df)</span>
<span id="cb2821-2"><a href="ch-R-linear-regression.html#cb2821-2" tabindex="-1"></a>y_pred</span></code></pre></div>
<pre><code>      31       15       14        3       42       43       37       48 
50.10037 30.50099 30.50099 10.90161 61.86000 61.86000 57.94013 77.53951 
      25       26       27        5       40       28        9 
42.26062 42.26062 46.18050 14.82148 61.86000 46.18050 22.66124 </code></pre>
<p><code>forecast</code> 패키지의 <code>accuracy()</code> 함수는 다양한 지표로 예측성능을 평가해 준다.
먼저 <code>forecast</code> 패키지를 설치하자.</p>
<div class="sourceCode" id="cb2823"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2823-1"><a href="ch-R-linear-regression.html#cb2823-1" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;forecast&quot;</span>)</span></code></pre></div>
<p><code>accuracy()</code> 함수는 다음 두 인수를 입력 받는다.</p>
<ul>
<li>첫 번째 인수는 예측한 값</li>
<li>두 번째 인수는 실제 관측값</li>
</ul>
<div class="sourceCode" id="cb2824"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2824-1"><a href="ch-R-linear-regression.html#cb2824-1" tabindex="-1"></a><span class="fu">library</span>(forecast)</span></code></pre></div>
<pre><code>Registered S3 method overwritten by &#39;quantmod&#39;:
  method            from
  as.zoo.data.frame zoo </code></pre>
<div class="sourceCode" id="cb2826"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2826-1"><a href="ch-R-linear-regression.html#cb2826-1" tabindex="-1"></a><span class="fu">accuracy</span>(y_pred, test_df<span class="sc">$</span>dist)</span></code></pre></div>
<pre><code>                ME     RMSE      MAE       MPE     MAPE
Test set -2.828571 9.933897 8.409524 -20.92935 31.91902</code></pre>
<ul>
<li>ME(mean errors)는 오차의 평균이다.</li>
<li>RMSE(root mean squared errors)는 오차 제곱의 평균을 제곱근한 값이다.<br />
</li>
<li>MAE(mean absolute errors)는 오차의 절대값의 평균이다.<br />
</li>
<li>MPE(mean percentage errors)는 관측값 대비 오차의 백분율을 평균한 것이다.<br />
</li>
<li>MAPE(mean absolute percentage errors)는 관측값 대비 오차의 백분율을 절대값을 취한 후 평균한 것이다.</li>
</ul>
<p>다음은 평가집합에서 모형의 회귀적합선과 실제 관측값을 보여준다.</p>
<div class="sourceCode" id="cb2828"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2828-1"><a href="ch-R-linear-regression.html#cb2828-1" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb2828-2"><a href="ch-R-linear-regression.html#cb2828-2" tabindex="-1"></a><span class="fu">ggplot</span>(test_df, <span class="fu">aes</span>(speed, dist)) <span class="sc">+</span></span>
<span id="cb2828-3"><a href="ch-R-linear-regression.html#cb2828-3" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb2828-4"><a href="ch-R-linear-regression.html#cb2828-4" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y=</span>y_pred), <span class="at">color=</span><span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="R-linear-regression_files/figure-html/unnamed-chunk-34-1.png" width="70%" style="display: block; margin: auto;" /></p>
</div>
<div id="모형의-기본-가정의-확인" class="section level4 unnumbered hasAnchor">
<h4>모형의 기본 가정의 확인<a href="#%EB%AA%A8%ED%98%95%EC%9D%98-%EA%B8%B0%EB%B3%B8-%EA%B0%80%EC%A0%95%EC%9D%98-%ED%99%95%EC%9D%B8" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>선형 회귀 모형과 관련된 가설검정은 다음과 같은 가정이 만족될 때만 성립한다.</p>
<ul>
<li>독립변수와 종속변수 관계의 선형성</li>
<li>오류항의 정규성, 독립성, 분산의 동일성. 즉, 오류항이 독립이고 동일한 정규분포 <span class="math inline">\(\mathcal{N}(0, \sigma^2)\)</span>을 따라야 한다.</li>
</ul>
<p>이러한 기본 가정은 주로 잔차 그래프를 그려서 확인한다.
잔차 그래프는 모형의 기본 가정의 확인뿐 아니라 특이점(outliers)과 영향점(influential points)이 있는지를 파악하게 해준다.
선형 회귀 모형에서 특이치는 두 가지 관점에서 생각해 볼 수 있다.</p>
<ul>
<li>종속변수의 값이 모형의 예측에서 벗어나는 특이한 관측치</li>
<li>독립변수 측면에서 다른 사례들의 경향에서 벗어나 있는 관측치</li>
</ul>
<p>종속변수 측면의 이상치를 특이점이라 하고, 표준화된 잔차(standardized residuals)를 사용하여 파악한다. 표준화된 잔차의 절대값이 2, 3 이상이면 특이점으로 간주한다.</p>
<p>독립변수 측면에서의 이상치는 레버리지(leverage) 또는 hat-value를 계산하여 파악한다.
레버리지의 평균은 <span class="math inline">\(p/n\)</span>인데 이보다 2, 3배 크면 독립변수 측면에서의 특이치로 간주한다.</p>
<p>한 관측 사례는 종속변수와 독립변수 측면에서 모두 특이치가 아닐 수 있으며, 종속변수 측면에서만 특이치이거나, 독립변수 측면에서만 특이치일 수 있다.
관측 사례가 종속변수와 독립변수 측면에서 모두 특이치인 경우에는 선형 회귀 모형의 결과에 매우 큰 영향을 미칠 가능성이 커진다.</p>
<p>영향점은 선형 회귀 모형의 결과에 크게 영향을 주는 관측치로서, 이 점이 제외되면 선형 회귀 모형의 계수가 크게 바뀐다.
Cook 거리는 관측치의 유무에 따라 회귀계수의 변화 정도를 측정하는데, <strong>R</strong>의 기본 패키지에서는 Cook 거리가 <span class="math inline">\(F_{0.5, p, n-p} \approx 1\)</span>에 근접하면 영향점으로 간주한다.
데이터에서 특이점과 영향점이 있으면 이 관측치가 올바른지 확인해 보고 주의깊게 탐색해 보아야 한다.</p>
<p>모형의 선형성과 오차항의 가정에 대한 탐색뿐 아니라, 특이점과 영향점처럼 선형 회귀 모형에서 나타날 수 있는 많은 문제를 잔차 그래프를 분석함으로써 어느 정도 확인이 가능하다.</p>
<p><code>lm()</code> 결과를 <code>plot()</code> 함수의 첫 번째 인수로 전달하면 잔차를 다양한 형식으로 시각화를 해 준다.
<code>plot()</code> 함수의 <code>which</code> 인수를 1부터 6까지 설정하여 서로 다른 관점의 6 개의 잔차 그래프를 그릴 수 있다.</p>
<ol style="list-style-type: decimal">
<li>“Residuals vs Fitted”, aka ‘Tukey-Anscombe’ plot:</li>
</ol>
<ul>
<li>모형의 예측값을 가로축으로 잔차를 세로축으로 하는 산점도이다.</li>
<li>독립변수와 종속변수 사이의 비선형 관계가 있는지를 탐색하거나 잔차의 등분산성을 탐색하기 위해 사용한다.</li>
<li>잔차가 별다른 경향이 없이 분포되어 있으면 모형의 선형성이 어느 정도 만족되는 것으로 판단한다.</li>
<li>잔차가 비선형적인 패턴을 보이면 독립변수와 종속변수 사이의 비선형적 관계가 있는 것을 암시한다. 이 경우에는 독립변수를 변환하여 비선형 항을 모형에 도입하거나 종속변수의 변환을 시도해 본다.</li>
<li>잔차가 종속변수의 예측값에 따라 일정한 분산을 가지고 있으면 어느 정도 등분산성이 만족되는 것으로 판단한다.</li>
<li><code>cars</code> 데이터에 대한 단순 선형 회귀 모형의 잔차 그래프에서 아주 약한 비선형성이 감지된다. 그리고 종속변수의 예측값이 커질수록 잔차의 분포가 점차 커지는 경향이 나타난다.</li>
</ul>
<div class="sourceCode" id="cb2829"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2829-1"><a href="ch-R-linear-regression.html#cb2829-1" tabindex="-1"></a><span class="fu">plot</span>(lm_cars, <span class="at">which=</span><span class="dv">1</span>)</span></code></pre></div>
<p><img src="R-linear-regression_files/figure-html/unnamed-chunk-35-1.png" width="70%" style="display: block; margin: auto;" /></p>
<ol start="2" style="list-style-type: decimal">
<li>“Residual Q-Q” plot:</li>
</ol>
<ul>
<li>표준화된 잔차를 세로축에 이론적인 표준정규분포의 값을 가로축으로 하는 Q-Q (Quantile-Quantile) 도표를 그리는데, 잔차의 정규성을 탐색하는데 사용된다.</li>
<li>잔차가 정규분포에 가까우면 Q-Q 도표을 가로지르는 점선에 가깝게 데이터가 놓인다.</li>
<li><code>cars</code> 데이터에 대한 단순 선형 회귀 모형은, 잔차가 큰 양수일 때 정규분포에서 약간 벗어나는 경향을 보인다.</li>
<li>잔차의 정규성은 Q-Q 도표뿐 아니라 Shapiro 검정을 이용해서도 파악해 볼 수 있다. Shapiro 검정은 데이터가 정규분포를 따른다는 귀무가설을 가설검정한다. 다음 예에서는 p-값이 0.05보다 작아서 유의수준 5%에서 표준화 잔차가 정규분포를 따른다는 귀무가설이 기각된다.</li>
</ul>
<div class="sourceCode" id="cb2830"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2830-1"><a href="ch-R-linear-regression.html#cb2830-1" tabindex="-1"></a><span class="fu">plot</span>(lm_cars, <span class="at">which=</span><span class="dv">2</span>)</span></code></pre></div>
<p><img src="R-linear-regression_files/figure-html/unnamed-chunk-36-1.png" width="70%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb2831"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2831-1"><a href="ch-R-linear-regression.html#cb2831-1" tabindex="-1"></a><span class="fu">shapiro.test</span>(<span class="fu">rstandard</span>(lm_cars))</span></code></pre></div>
<pre><code>
    Shapiro-Wilk normality test

data:  rstandard(lm_cars)
W = 0.94518, p-value = 0.0217</code></pre>
<ol start="3" style="list-style-type: decimal">
<li>“Scale-Location” plot:</li>
</ol>
<ul>
<li>모형의 예측값을 가록축, 표준화된 잔차의 절대값의 제곱근을 세로축으로 하는 그래프이다. 잔차의 절대값에 제곱근을 취하는 이유는 잔차의 절대값의 분포가 왼쪽으로 치우친 분포이기 때문에 왜도를 줄이기 위해서이다.</li>
<li>잔차의 등분산성을 확인하기 위하여 모형의 예측값에 무관하게 잔차의 분산이 일정한지 확인한다.</li>
<li><code>cars</code> 데이터에 대한 단순 선형 회귀 모형은 예측값이 커지면 잔차의 분산이 약간 증가하는 경향을 보인다.</li>
</ul>
<div class="sourceCode" id="cb2833"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2833-1"><a href="ch-R-linear-regression.html#cb2833-1" tabindex="-1"></a><span class="fu">plot</span>(lm_cars, <span class="at">which=</span><span class="dv">3</span>)</span></code></pre></div>
<p><img src="R-linear-regression_files/figure-html/unnamed-chunk-38-1.png" width="70%" style="display: block; margin: auto;" />
4. “Cook’s distance” plot:
- 관측 사례의 순서대로 Cook 거리를 시각화 한다.
- 다음은 <code>cars</code> 데이터의 단순 선형 회귀 모형의 Cook 거리 도표이다. Cook 거리가 1에 근접하는 영향점은 보이지 않는다.</p>
<div class="sourceCode" id="cb2834"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2834-1"><a href="ch-R-linear-regression.html#cb2834-1" tabindex="-1"></a><span class="fu">plot</span>(lm_cars, <span class="at">which=</span><span class="dv">4</span>)</span></code></pre></div>
<p><img src="R-linear-regression_files/figure-html/unnamed-chunk-39-1.png" width="70%" style="display: block; margin: auto;" /></p>
<ol start="5" style="list-style-type: decimal">
<li>“Residuals vs Leverage” plot:</li>
</ol>
<ul>
<li>가로축은 레버리지, 세로축은 표준화된 잔차를 시각화하여 독립변수와 종속변수 측면의 특이치가 있는지를 살펴볼 수 있다.</li>
<li><code>cars</code> 데이터의 그래프에서 표준화된 잔차의 절대값이 2보다 큰 관측치는 23, 39, 49 번 관측치로서 종속변수 측면에서 특이치라 할 수 있다. <span class="math inline">\(p=1\)</span>이고 <span class="math inline">\(n=50\)</span>이므로 레버리지의 평균은 0.02인데 23과 39 번은 레버리지가 평균의 2 배 이내이므로 독립변수 측면에서 특이치라 보기 어렵다. 반면 49 번은 레버리지도 평균의 3 배 정도로 독립변수 측면에서도 어느 정도 특이치라 할 수 있다. 그러므로 49 번은 모형의 계수에 영향을 주는 관측치이다. 그렇기 때문에 4 번째 그래프에서도 Cook 거리가 가장 크게 나왔다.</li>
</ul>
<div class="sourceCode" id="cb2835"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2835-1"><a href="ch-R-linear-regression.html#cb2835-1" tabindex="-1"></a><span class="fu">plot</span>(lm_cars, <span class="at">which=</span><span class="dv">5</span>)</span></code></pre></div>
<p><img src="R-linear-regression_files/figure-html/unnamed-chunk-40-1.png" width="70%" style="display: block; margin: auto;" /></p>
<ol start="6" style="list-style-type: decimal">
<li>“Cook’s dist vs Lev./(1-Lev.)” plot:</li>
</ol>
<ul>
<li>Cook 거리, 레버리지, 표준화된 잔차를 한 그래프에서 시각화한다. 가로축은 레버리지, 세로축은 Cook 거리이다. 점선의 등고선은 표준화된 잔차이고 그래프의 오른편과 상단에 등고선이 나타내는 표준화된 잔차의 크기를 보여준다.</li>
<li><code>cars</code> 데이터의 예에서는 49 번 데이터는 가장 높은 Cook 거리를 보여주고 있고 표준화된 잔차의 등고선 3 근처에 있다.</li>
</ul>
<div class="sourceCode" id="cb2836"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2836-1"><a href="ch-R-linear-regression.html#cb2836-1" tabindex="-1"></a><span class="fu">plot</span>(lm_cars, <span class="at">which=</span><span class="dv">6</span>)</span></code></pre></div>
<p><img src="R-linear-regression_files/figure-html/unnamed-chunk-41-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>다음처럼 <code>which</code> 인수를 지정하지 않으면 1, 2, 3, 5 번 그래프가 차례로 출력된다.</p>
<div class="sourceCode" id="cb2837"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2837-1"><a href="ch-R-linear-regression.html#cb2837-1" tabindex="-1"></a><span class="fu">plot</span>(lm_cars)</span></code></pre></div>
<p><img src="R-linear-regression_files/figure-html/unnamed-chunk-42-1.png" width="50%" style="display: block; margin: auto;" /><img src="R-linear-regression_files/figure-html/unnamed-chunk-42-2.png" width="50%" style="display: block; margin: auto;" /><img src="R-linear-regression_files/figure-html/unnamed-chunk-42-3.png" width="50%" style="display: block; margin: auto;" /><img src="R-linear-regression_files/figure-html/unnamed-chunk-42-4.png" width="50%" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="모형의-개선" class="section level3 hasAnchor" number="17.1.5">
<h3><span class="header-section-number">17.1.5</span> 모형의 개선<a href="#%EB%AA%A8%ED%98%95%EC%9D%98-%EA%B0%9C%EC%84%A0" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><code>cars</code> 데이터에 대한 단순 선형 회귀 모형은 통계적 유의성도 있었고 적절한 설명력도 가진 모형이지만, 잔차 분석해 본 결과 다음의 문제점이 있었다.</p>
<ul>
<li>잔차에서 비선형적 경향이 나타난다.</li>
<li>표준화 잔차가 정규분포를 따르지 않는다.</li>
<li>잔차의 분산이 동일하지 않다.</li>
</ul>
<p>이러한 문제점이 심각한 정도는 아니지만 모형이 개선될 수 있는지 탐색해 보자.
잔차의 등분산성이 만족되지 않을 때는 종속변수의 변환을 고려해 볼 수 있다.
특히 종속변수가 양수이고 종속변수의 크기가 커질수록 잔차의 분산이 점차 커지면 제곱근이나 로그 변환을 고려해 본다.</p>
<p>잔차의 분산이 크게 증가하지는 않으므로 다음과 같이 제동거리를 제곱근으로 변환하는 모형을 탐색해 보자.</p>
<p><span class="math display">\[
\sqrt{dist} = \beta_0 + \beta_1 \, speed + \varepsilon
\]</span></p>
<p>다음은 <code>dist</code>를 제곱근 변환한 선형 모형을 적합한 결과이다.</p>
<div class="sourceCode" id="cb2838"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2838-1"><a href="ch-R-linear-regression.html#cb2838-1" tabindex="-1"></a>lm_cars_trans <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="fu">sqrt</span>(dist) <span class="sc">~</span> speed, <span class="at">data=</span>cars)</span>
<span id="cb2838-2"><a href="ch-R-linear-regression.html#cb2838-2" tabindex="-1"></a>lm_cars_trans</span></code></pre></div>
<pre><code>
Call:
lm(formula = sqrt(dist) ~ speed, data = cars)

Coefficients:
(Intercept)        speed  
     1.2771       0.3224  </code></pre>
<p>모형의 통계적 유의성과 설명력을 파악하기 위하여 <code>summary()</code> 함수로 모형을 요약해 보자.</p>
<div class="sourceCode" id="cb2840"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2840-1"><a href="ch-R-linear-regression.html#cb2840-1" tabindex="-1"></a><span class="fu">summary</span>(lm_cars_trans)</span></code></pre></div>
<pre><code>
Call:
lm(formula = sqrt(dist) ~ speed, data = cars)

Residuals:
    Min      1Q  Median      3Q     Max 
-2.0684 -0.6983 -0.1799  0.5909  3.1534 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  1.27705    0.48444   2.636   0.0113 *  
speed        0.32241    0.02978  10.825 1.77e-14 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 1.102 on 48 degrees of freedom
Multiple R-squared:  0.7094,    Adjusted R-squared:  0.7034 
F-statistic: 117.2 on 1 and 48 DF,  p-value: 1.773e-14</code></pre>
<p>F-검정의 p-값이 매우 작아서 독립변수가 종속변수에 대해 통계적으로 유의한 영향을 주고있음을 확인할 수 있다.
아울러 <span class="math inline">\(R^2\)</span>의 값도 0.651에서 0.709로 증가하여 모형의 설명력도 증가하였다.</p>
<p>잔차 분석을 위하여 잔차 그래프를 그려보면, 잔차에 있던 비선형적 패턴과 잔차의 분산이 종속변수의 예측값이 커지는 경향이 거의 사라진 것을 볼 수 있다.</p>
<div class="sourceCode" id="cb2842"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2842-1"><a href="ch-R-linear-regression.html#cb2842-1" tabindex="-1"></a><span class="fu">plot</span>(lm_cars_trans)</span></code></pre></div>
<p><img src="R-linear-regression_files/figure-html/unnamed-chunk-45-1.png" width="70%" style="display: block; margin: auto;" /><img src="R-linear-regression_files/figure-html/unnamed-chunk-45-2.png" width="70%" style="display: block; margin: auto;" /><img src="R-linear-regression_files/figure-html/unnamed-chunk-45-3.png" width="70%" style="display: block; margin: auto;" /><img src="R-linear-regression_files/figure-html/unnamed-chunk-45-4.png" width="70%" style="display: block; margin: auto;" /></p>
<p>아울러 표준화 잔차의 Q-Q 도표도 점선에 더 가까워진 것을 볼 수 있다.
Shapiro 검정을 한 결과도 p-값이 커서 표준화 잔차가 정규분포를 따른다는 귀무가설이 채택된다.</p>
<div class="sourceCode" id="cb2843"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2843-1"><a href="ch-R-linear-regression.html#cb2843-1" tabindex="-1"></a><span class="fu">shapiro.test</span>(<span class="fu">rstandard</span>(lm_cars_trans))</span></code></pre></div>
<pre><code>
    Shapiro-Wilk normality test

data:  rstandard(lm_cars_trans)
W = 0.97386, p-value = 0.3298</code></pre>
<p>종속변수를 제곱근 변환한 모형은 원래의 모형이 가지고 있던 대부분의 문제를 해결했으므로, 이 모형을 최종 모형으로 선택할 수 있을 것이다.
이 모형을 산점도에 표시해 보자.
이 때 주의할 점은 제곱근 변환한 모형으로 종속변수를 예측값을 구하려면 모형의 예측값을 제곱해야 한다는 것이다.
다음 그래프에서 보듯이 직선 형태의 원래의 모형보다 데이터에 더 자연스럽게 적합되는 것을 확인할 수 있다. 비교를 위해 원래의 직선 모형을 점선으로 나타내었다.</p>
<div class="sourceCode" id="cb2845"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2845-1"><a href="ch-R-linear-regression.html#cb2845-1" tabindex="-1"></a><span class="fu">ggplot</span>(cars, <span class="fu">aes</span>(<span class="at">x=</span>speed, <span class="at">y=</span>dist)) <span class="sc">+</span></span>
<span id="cb2845-2"><a href="ch-R-linear-regression.html#cb2845-2" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb2845-3"><a href="ch-R-linear-regression.html#cb2845-3" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y=</span>lm_cars_trans<span class="sc">$</span>fitted.values<span class="sc">^</span><span class="dv">2</span>), <span class="at">color=</span><span class="st">&quot;red&quot;</span>) <span class="sc">+</span></span>
<span id="cb2845-4"><a href="ch-R-linear-regression.html#cb2845-4" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y=</span>lm_cars<span class="sc">$</span>fitted.values), <span class="at">color=</span><span class="st">&quot;blue&quot;</span>, <span class="at">linetype=</span><span class="dv">3</span>) </span></code></pre></div>
<p><img src="R-linear-regression_files/figure-html/unnamed-chunk-47-1.png" width="70%" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="sec-multiple-linear-regression" class="section level2 hasAnchor" number="17.2">
<h2><span class="header-section-number">17.2</span> 다중 선형 회귀<a href="ch-R-linear-regression.html#sec-multiple-linear-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="galtonfamilies-데이터" class="section level3 hasAnchor" number="17.2.1">
<h3><span class="header-section-number">17.2.1</span> <code>GaltonFamilies</code> 데이터<a href="#galtonfamilies-%EB%8D%B0%EC%9D%B4%ED%84%B0" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>다중 선형 회귀를 설명하기 위하여 이 장의 서두에서 설명한 부모의 키와 자신의 키를 수집한 갈톤의 데이터를 이용해 보자.
이 데이터는 <code>HistData</code> 패키지에 포함되어 있다.
<code>HistData</code> 패키지를 설치하고 적재한 후, <code>GaltonFamilies</code> 데이터의 처음 6 줄을 출력해 보자.</p>
<div class="sourceCode" id="cb2846"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2846-1"><a href="ch-R-linear-regression.html#cb2846-1" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;HistData&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb2847"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2847-1"><a href="ch-R-linear-regression.html#cb2847-1" tabindex="-1"></a><span class="fu">library</span>(HistData)</span>
<span id="cb2847-2"><a href="ch-R-linear-regression.html#cb2847-2" tabindex="-1"></a><span class="fu">head</span>(GaltonFamilies)</span></code></pre></div>
<pre><code>  family father mother midparentHeight children childNum gender childHeight
1    001   78.5   67.0           75.43        4        1   male        73.2
2    001   78.5   67.0           75.43        4        2 female        69.2
3    001   78.5   67.0           75.43        4        3 female        69.0
4    001   78.5   67.0           75.43        4        4 female        69.0
5    002   75.5   66.5           73.66        4        1   male        73.5
6    002   75.5   66.5           73.66        4        2   male        72.5</code></pre>
<ul>
<li><code>family</code>는 조사하 가구의 일련번호</li>
<li><code>father</code>, <code>mother</code>, <code>midparentHeight</code>는 부모의 키(인치)로 <code>midparentHeight</code>는 다음 공식으로 계산된다.
<span class="math display">\[
midparentHeight = \frac{father + 1.08 \times mother}{2}
\]</span></li>
<li><code>children</code>은 가구의 자식의 수</li>
<li><code>childNum</code>은 동일 가주의 자식에게 부여한 일련 번호. 아들을 키 순으로 내림차순으로 배열한 후, 딸은 다시 키 순으로 내림차순으로 배열하여 번호를 부여<br />
</li>
<li><code>gender</code>는 자식의 성별</li>
<li><code>childHeight</code>는 자식의 키</li>
</ul>
<p>본격적으로 종속변수인 <code>childHeight</code>와 이에 영향을 미칠 것으로 예상되는 독립변수들의 관계를 살펴보기 전에, 변수들의 기본 통계치와 분포를 확인해 보자.</p>
<div class="sourceCode" id="cb2849"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2849-1"><a href="ch-R-linear-regression.html#cb2849-1" tabindex="-1"></a><span class="fu">summary</span>(GaltonFamilies)</span></code></pre></div>
<pre><code>     family        father         mother      midparentHeight    children     
 185    : 15   Min.   :62.0   Min.   :58.00   Min.   :64.40   Min.   : 1.000  
 066    : 11   1st Qu.:68.0   1st Qu.:63.00   1st Qu.:68.14   1st Qu.: 4.000  
 120    : 11   Median :69.0   Median :64.00   Median :69.25   Median : 6.000  
 130    : 11   Mean   :69.2   Mean   :64.09   Mean   :69.21   Mean   : 6.171  
 166    : 11   3rd Qu.:71.0   3rd Qu.:65.88   3rd Qu.:70.14   3rd Qu.: 8.000  
 097    : 10   Max.   :78.5   Max.   :70.50   Max.   :75.43   Max.   :15.000  
 (Other):865                                                                  
    childNum         gender     childHeight   
 Min.   : 1.000   female:453   Min.   :56.00  
 1st Qu.: 2.000   male  :481   1st Qu.:64.00  
 Median : 3.000                Median :66.50  
 Mean   : 3.586                Mean   :66.75  
 3rd Qu.: 5.000                3rd Qu.:69.70  
 Max.   :15.000                Max.   :79.00  
                                              </code></pre>
<div class="sourceCode" id="cb2851"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2851-1"><a href="ch-R-linear-regression.html#cb2851-1" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb2851-2"><a href="ch-R-linear-regression.html#cb2851-2" tabindex="-1"></a>bins <span class="ot">&lt;-</span> <span class="dv">15</span></span>
<span id="cb2851-3"><a href="ch-R-linear-regression.html#cb2851-3" tabindex="-1"></a><span class="fu">ggplot</span>(GaltonFamilies, <span class="fu">aes</span>(father)) <span class="sc">+</span> <span class="fu">geom_histogram</span>(<span class="at">bins=</span>bins)</span></code></pre></div>
<p><img src="R-linear-regression_files/figure-html/unnamed-chunk-51-1.png" width="70%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb2852"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2852-1"><a href="ch-R-linear-regression.html#cb2852-1" tabindex="-1"></a><span class="fu">ggplot</span>(GaltonFamilies, <span class="fu">aes</span>(mother)) <span class="sc">+</span> <span class="fu">geom_histogram</span>(<span class="at">bins=</span>bins)</span></code></pre></div>
<p><img src="R-linear-regression_files/figure-html/unnamed-chunk-51-2.png" width="70%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb2853"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2853-1"><a href="ch-R-linear-regression.html#cb2853-1" tabindex="-1"></a><span class="fu">ggplot</span>(GaltonFamilies, <span class="fu">aes</span>(midparentHeight)) <span class="sc">+</span> <span class="fu">geom_histogram</span>(<span class="at">bins=</span>bins)</span></code></pre></div>
<p><img src="R-linear-regression_files/figure-html/unnamed-chunk-51-3.png" width="70%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb2854"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2854-1"><a href="ch-R-linear-regression.html#cb2854-1" tabindex="-1"></a><span class="fu">ggplot</span>(GaltonFamilies, <span class="fu">aes</span>(children)) <span class="sc">+</span> <span class="fu">geom_bar</span>()</span></code></pre></div>
<p><img src="R-linear-regression_files/figure-html/unnamed-chunk-51-4.png" width="70%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb2855"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2855-1"><a href="ch-R-linear-regression.html#cb2855-1" tabindex="-1"></a><span class="fu">ggplot</span>(GaltonFamilies, <span class="fu">aes</span>(childHeight, <span class="at">fill=</span>gender)) <span class="sc">+</span> </span>
<span id="cb2855-2"><a href="ch-R-linear-regression.html#cb2855-2" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">bins=</span>bins) </span></code></pre></div>
<p><img src="R-linear-regression_files/figure-html/unnamed-chunk-51-5.png" width="70%" style="display: block; margin: auto;" /></p>
<p>변수 사이의 상관성을 분석하기 위하여 산점도를 그려보자.
부모의 키가 커지면 자식의 키가 커지는 양의 상관성이 있음을 확인할 수 있다.
반면 자식의 수가 많아지면 자식의 키가 작아지는 약한 음의 상관성도 보인다.
특히 자식의 수가 많은 가구에서 이러한 현상이 두드러지는데, 식구의 수가 늘어남에 따라 영양공급이 제한되기 때문인 것으로 보인다.
자식의 성별에 따른 키의 차이도 뚜렷이 나타난다.</p>
<div class="sourceCode" id="cb2856"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2856-1"><a href="ch-R-linear-regression.html#cb2856-1" tabindex="-1"></a><span class="fu">ggplot</span>(GaltonFamilies, <span class="fu">aes</span>(father, childHeight, <span class="at">color=</span>gender)) <span class="sc">+</span> </span>
<span id="cb2856-2"><a href="ch-R-linear-regression.html#cb2856-2" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">geom_smooth</span>()</span></code></pre></div>
<p><img src="R-linear-regression_files/figure-html/unnamed-chunk-52-1.png" width="70%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb2857"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2857-1"><a href="ch-R-linear-regression.html#cb2857-1" tabindex="-1"></a><span class="fu">ggplot</span>(GaltonFamilies, <span class="fu">aes</span>(mother, childHeight, <span class="at">color=</span>gender)) <span class="sc">+</span> </span>
<span id="cb2857-2"><a href="ch-R-linear-regression.html#cb2857-2" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">geom_smooth</span>()</span></code></pre></div>
<p><img src="R-linear-regression_files/figure-html/unnamed-chunk-52-2.png" width="70%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb2858"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2858-1"><a href="ch-R-linear-regression.html#cb2858-1" tabindex="-1"></a><span class="fu">ggplot</span>(GaltonFamilies, <span class="fu">aes</span>(midparentHeight, childHeight, <span class="at">color=</span>gender)) <span class="sc">+</span> </span>
<span id="cb2858-2"><a href="ch-R-linear-regression.html#cb2858-2" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">geom_smooth</span>()</span></code></pre></div>
<p><img src="R-linear-regression_files/figure-html/unnamed-chunk-52-3.png" width="70%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb2859"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2859-1"><a href="ch-R-linear-regression.html#cb2859-1" tabindex="-1"></a><span class="fu">ggplot</span>(GaltonFamilies, <span class="fu">aes</span>(children, childHeight, <span class="at">color=</span>gender)) <span class="sc">+</span> </span>
<span id="cb2859-2"><a href="ch-R-linear-regression.html#cb2859-2" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">geom_smooth</span>()</span></code></pre></div>
<p><img src="R-linear-regression_files/figure-html/unnamed-chunk-52-4.png" width="70%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb2860"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2860-1"><a href="ch-R-linear-regression.html#cb2860-1" tabindex="-1"></a><span class="fu">ggplot</span>(GaltonFamilies, <span class="fu">aes</span>(gender, childHeight)) <span class="sc">+</span></span>
<span id="cb2860-2"><a href="ch-R-linear-regression.html#cb2860-2" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>(<span class="at">notch=</span>T)</span></code></pre></div>
<p><img src="R-linear-regression_files/figure-html/unnamed-chunk-52-5.png" width="70%" style="display: block; margin: auto;" /></p>
<p>상관계수를 그려보면 <code>childHeigt</code>와 <code>midparentHeight</code>가 가장 높은 상관성을 보이이고, <code>father</code>가 <code>mother</code>에 비해 더 높은 양으 상관성을 보이고, 자식의 수는 약한 음의 상관성을 보인다.
아버지와 어머니 키로 이루어진 <code>midparentHeight</code>는 <code>father</code>와 <code>mother</code>와 강한 양의 상관성을 보인다. 반면 아버지와 어머니의 키의 상관성은 그리 높지는 않았다.</p>
<div class="sourceCode" id="cb2861"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2861-1"><a href="ch-R-linear-regression.html#cb2861-1" tabindex="-1"></a><span class="fu">library</span>(corrplot)</span></code></pre></div>
<pre><code>corrplot 0.92 loaded</code></pre>
<div class="sourceCode" id="cb2863"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2863-1"><a href="ch-R-linear-regression.html#cb2863-1" tabindex="-1"></a>cor_matrix <span class="ot">&lt;-</span> <span class="fu">cor</span>(<span class="fu">select</span>(GaltonFamilies, <span class="sc">-</span>family, <span class="sc">-</span>childNum, <span class="sc">-</span>gender))</span>
<span id="cb2863-2"><a href="ch-R-linear-regression.html#cb2863-2" tabindex="-1"></a><span class="fu">corrplot.mixed</span>(cor_matrix)</span></code></pre></div>
<p><img src="R-linear-regression_files/figure-html/unnamed-chunk-53-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>다중 선형 회귀 모형을 수립하기 전에 독립변수를 <code>midparentHeight</code>만 사용하여 <code>childHeight</code>에 대한 단순 선형 회귀를 수행해 보자.</p>
<div class="sourceCode" id="cb2864"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2864-1"><a href="ch-R-linear-regression.html#cb2864-1" tabindex="-1"></a>lm_galton_simple <span class="ot">&lt;-</span> <span class="fu">lm</span>(childHeight <span class="sc">~</span> midparentHeight, <span class="at">data=</span>GaltonFamilies)</span>
<span id="cb2864-2"><a href="ch-R-linear-regression.html#cb2864-2" tabindex="-1"></a>lm_galton_simple</span></code></pre></div>
<pre><code>
Call:
lm(formula = childHeight ~ midparentHeight, data = GaltonFamilies)

Coefficients:
    (Intercept)  midparentHeight  
        22.6362           0.6374  </code></pre>
<p>부모의 중간키(midparentHeight)가 1인치 커지면 자식의 키는 평균적으로 0.6374 커진다.
이러한 선형 관계를 그래프로 그려보면 다음과 같다.</p>
<div class="sourceCode" id="cb2866"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2866-1"><a href="ch-R-linear-regression.html#cb2866-1" tabindex="-1"></a><span class="fu">ggplot</span>(GaltonFamilies, <span class="fu">aes</span>(midparentHeight, childHeight)) <span class="sc">+</span></span>
<span id="cb2866-2"><a href="ch-R-linear-regression.html#cb2866-2" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb2866-3"><a href="ch-R-linear-regression.html#cb2866-3" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y=</span>lm_galton_simple<span class="sc">$</span>fitted.values), <span class="at">color=</span><span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="R-linear-regression_files/figure-html/unnamed-chunk-55-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p><code>summary()</code> 함수로 모형의 통계적 유의성과 설명력을 확인해 보자.</p>
<div class="sourceCode" id="cb2867"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2867-1"><a href="ch-R-linear-regression.html#cb2867-1" tabindex="-1"></a><span class="fu">summary</span>(lm_galton_simple)</span></code></pre></div>
<pre><code>
Call:
lm(formula = childHeight ~ midparentHeight, data = GaltonFamilies)

Residuals:
    Min      1Q  Median      3Q     Max 
-8.9570 -2.6989 -0.2155  2.7961 11.6848 

Coefficients:
                Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)     22.63624    4.26511   5.307 1.39e-07 ***
midparentHeight  0.63736    0.06161  10.345  &lt; 2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 3.392 on 932 degrees of freedom
Multiple R-squared:  0.103, Adjusted R-squared:  0.102 
F-statistic:   107 on 1 and 932 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>F-검정의 p-값이 매우 작아서 독립변수(<code>midparentHeight</code>)가 종속변수(<code>childHeight</code>)에 영향을 미친다는 대립가설을 채택한다.
그런데 <span class="math inline">\(R^2\)</span> 값이 0.103로 자식의 키의 변동을 모형이 설명하는 정도가 그리 크지 않다.
앞으로 부모의 중간키뿐 아니라 다른 변수들을 더 사용하는 다중 선형 회귀 모형을 만들어 자식 키의 설명력을 높여 보자.</p>
<p>마지막으로 잔차 그래프를 보면 모형의 선형성이나 등분산성에는 큰 문제가 없어 보인다.
다만 정규 분포보다는 꼬리가 약간 짧은 분포를 보인다.</p>
<div class="sourceCode" id="cb2869"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2869-1"><a href="ch-R-linear-regression.html#cb2869-1" tabindex="-1"></a><span class="fu">plot</span>(lm_galton_simple)</span></code></pre></div>
<p><img src="R-linear-regression_files/figure-html/unnamed-chunk-57-1.png" width="70%" style="display: block; margin: auto;" /><img src="R-linear-regression_files/figure-html/unnamed-chunk-57-2.png" width="70%" style="display: block; margin: auto;" /><img src="R-linear-regression_files/figure-html/unnamed-chunk-57-3.png" width="70%" style="display: block; margin: auto;" /><img src="R-linear-regression_files/figure-html/unnamed-chunk-57-4.png" width="70%" style="display: block; margin: auto;" /></p>
</div>
<div id="sec-multiple-linear-regression-theory" class="section level3 hasAnchor" number="17.2.2">
<h3><span class="header-section-number">17.2.2</span> 다중 선형 회귀 모형<a href="ch-R-linear-regression.html#sec-multiple-linear-regression-theory" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>다중 선형 회귀는 다수의 독립변수를 사용하여 종속변수를 설명(예측)하는 모형이다.
다중 선형 회귀 모형은 <span class="math inline">\(p\)</span> 개의 독립변수 <span class="math inline">\(X_1, X_2, \dots, X_p\)</span>와 종속변수 <span class="math inline">\(Y\)</span>의 관계에 대해 다음과 같은 선형 모형을 가정한다.</p>
<p><span class="math display" id="eq:multiple-reg">\[\begin{equation}
  Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \cdots + \beta_p X_p + \varepsilon
  \tag{17.2}
\end{equation}\]</span></p>
<p><span class="math inline">\(\beta_j\)</span>는 독립변수 <span class="math inline">\(X_j\)</span>가 한 단위 증가될 때 - 모든 다른 변수는 변화가 없을 때 - 반응변수 <span class="math inline">\(Y\)</span>에 미치는 영향을 나타낸다.</p>
<p><code>GaltonFamilies</code> 데이터에서 부모의 중간키가 아니라 아버지의 키와 어머니의 키를 독립적으로 사용하여 다음과 같은 다중 선형 회귀 모형을 만들 수 있다.</p>
<p><span class="math display">\[\begin{equation}
childHeight = \beta_0 + \beta_1 \times father + \beta_2 \times mother + \varepsilon
\end{equation}\]</span></p>
<p>그러면 계수 <span class="math inline">\(\beta_1\)</span>은 어머니 키가 동일할 때, 아머지 키가 1 인치 더 커지면 자신의 키가 얼마만큼 증가 또는 감소하는지를 나타내고, 계수 <span class="math inline">\(\beta_2\)</span>는 아버지 키가 동일할 때 어머니 키 한 단위가 증가할 때 자식의 키가 증가 또는 감소하는 양을 나타낸다.</p>
<p>독립변수로 수치형 변수뿐 아니라 범주형 변수도 사용될 수 있다.
그런데 <a href="ch-R-linear-regression.html#eq:multiple-reg">(17.2)</a>에서 보듯이 선형 회귀 모형은 모든 변수가 수치여야 종속변수의 값을 예측할 수 있다.
그러므로 범주형 변수는 수치형 지시변수로 변환한다.
<code>GaltonFamilies</code>의 <code>gender</code> 열처럼 female과 male의 두 범주의 값만 가지는 변수는 하나의 지시변수로 변환(코딩)된다.
지시변수는 0 또는 1의 값을 가지는 다음처럼 첫 번째 범주이면 0, 두 번째 범주이면 1로 코딩된다.</p>
<p><span class="math display">\[
\mathbf{1}(gender=male)
=\begin{cases}
  0, &amp; gender = female \\
  1, &amp; gender = male
\end{cases}
\]</span></p>
<p>앞서 설명한 <code>childHeight</code>에 대한 다중 선형 회귀 모형에 <code>gender</code> 변수도 포함시키면 다음과 같은 선형 회귀 모형이 된다.</p>
<p><span class="math display">\[\begin{equation}
childHeight = \beta_0 + \beta_1 \times father + \beta_2 \times mother
              + \beta_3 \times \mathbf{1}(gender=male)
              + \varepsilon
\end{equation}\]</span></p>
<p>이 모형의 의미를 해석해 보자. 위의 식은 다음처럼 표현될 수 있다.</p>
<p><span class="math display">\[
childHeight =
  \begin{cases}
\beta_0 + \beta_1 \times father + \beta_2 \times mother
              + \varepsilon, &amp; gender = female \\
(\beta_0 + \beta_3) + \beta_1 \times father + \beta_2 \times mother
              + \varepsilon, &amp; gender = male \\
  \end{cases}
\]</span></p>
<p>따라서 <span class="math inline">\(\beta_3\)</span>은 아들과 딸의 키에 대한 회귀식의 절편의 차이이고, 회귀 모형에서 부모의 중간키에 무관하게 평균적으로 아들과 딸은 <span class="math inline">\(\beta_3\)</span> 만큼의 차이가 발생한다.</p>
<p>다중 선형 회귀도 단순 선형 회귀처럼 모형의 예측과 관측값의 차이인 잔차를 계산하여, 잔차제곱합(RSS)를 최소로 하는 계수를 추정한다.</p>
</div>
<div id="lm을-이용한-다중-선형-회귀" class="section level3 hasAnchor" number="17.2.3">
<h3><span class="header-section-number">17.2.3</span> <code>lm()</code>을 이용한 다중 선형 회귀<a href="#lm%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%9C-%EB%8B%A4%EC%A4%91-%EC%84%A0%ED%98%95-%ED%9A%8C%EA%B7%80" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>다중 선형 회귀도 단순 선형 회귀처럼 <code>lm()</code> 함수로 모형을 적합한다.
오직 다른 점은 첫 번째 인수인 <code>formula</code>에서 다음처럼 독립변수로 사용할 열을 <code>+</code>를 사용하여 모두 기술한다는 점만 다르다.</p>
<pre><code>lm(종속변수_열 ~ 독립변수_열1 + 독립변수_열2 + ... + 독립변수_열p, data=데이터) </code></pre>
<p>다음은 <code>midparentHeight</code>와 <code>gender</code>를 독립변수로 하는 다중 선형 회귀를 수행한 결과이다.</p>
<div class="sourceCode" id="cb2871"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2871-1"><a href="ch-R-linear-regression.html#cb2871-1" tabindex="-1"></a>lm_galton_multiple <span class="ot">&lt;-</span> <span class="fu">lm</span>(childHeight <span class="sc">~</span> midparentHeight <span class="sc">+</span> gender,</span>
<span id="cb2871-2"><a href="ch-R-linear-regression.html#cb2871-2" tabindex="-1"></a>                         <span class="at">data=</span>GaltonFamilies)</span>
<span id="cb2871-3"><a href="ch-R-linear-regression.html#cb2871-3" tabindex="-1"></a>lm_galton_multiple</span></code></pre></div>
<pre><code>
Call:
lm(formula = childHeight ~ midparentHeight + gender, data = GaltonFamilies)

Coefficients:
    (Intercept)  midparentHeight       gendermale  
         16.514            0.687            5.215  </code></pre>
<p>모형을 적합한 결과는 다음과 같은 수식을 표현할 수 있다.</p>
<p><span class="math display">\[
childHeight = 16.514
              + 0.687 \times midparentHeight  
              + 5.215 \times \mathbf{1}(gender=male)
              + \varepsilon
\]</span></p>
<p>따라서 부모의 중간키가 1인치 커지면 자식의 키는 평균적으로 0.687 인치 커지고, 아들이 딸보다 평균적으로 5.215 인치 더 크다.</p>
<p>단순 선형 회귀 모형에 <code>gender</code> 변수를 더 도입한 모형의 설명력과 통계적 유의성을 확인해 보자.</p>
<div class="sourceCode" id="cb2873"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2873-1"><a href="ch-R-linear-regression.html#cb2873-1" tabindex="-1"></a><span class="fu">summary</span>(lm_galton_multiple)</span></code></pre></div>
<pre><code>
Call:
lm(formula = childHeight ~ midparentHeight + gender, data = GaltonFamilies)

Residuals:
    Min      1Q  Median      3Q     Max 
-9.5317 -1.4600  0.0979  1.4566  9.1110 

Coefficients:
                Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)     16.51410    2.73392    6.04 2.22e-09 ***
midparentHeight  0.68702    0.03944   17.42  &lt; 2e-16 ***
gendermale       5.21511    0.14216   36.69  &lt; 2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 2.17 on 931 degrees of freedom
Multiple R-squared:  0.6332,    Adjusted R-squared:  0.6324 
F-statistic: 803.6 on 2 and 931 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>F-검정의 p-값이 매우 작아서 독립변수들이 종속변수를 유의미하게 영향을 준다는 대립가설이 채택되며, <span class="math inline">\(R^2\)</span> 값도 0.633으로 크게 개선되는 것을 확인할 수 있다.</p>
<p>이 모형을 시각화하면 다음과 같다.
자식의 성별 차이를 모형에 도입하자 모형의 오차가 크게 감소하는 것을 볼 수 있다.</p>
<div class="sourceCode" id="cb2875"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2875-1"><a href="ch-R-linear-regression.html#cb2875-1" tabindex="-1"></a><span class="fu">ggplot</span>(GaltonFamilies, <span class="fu">aes</span>(midparentHeight, childHeight, <span class="at">color=</span>gender)) <span class="sc">+</span></span>
<span id="cb2875-2"><a href="ch-R-linear-regression.html#cb2875-2" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">shape=</span>gender)) <span class="sc">+</span></span>
<span id="cb2875-3"><a href="ch-R-linear-regression.html#cb2875-3" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y=</span>lm_galton_multiple<span class="sc">$</span>fitted.values))</span></code></pre></div>
<p><img src="R-linear-regression_files/figure-html/unnamed-chunk-60-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>이 모형의 잔차 그래프를 그려보자.
모형의 선형성, 등분산성뿐 아니라 정규성도 더 개선된 것을 확인할 수 있다.</p>
<div class="sourceCode" id="cb2876"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2876-1"><a href="ch-R-linear-regression.html#cb2876-1" tabindex="-1"></a><span class="fu">plot</span>(lm_galton_multiple)</span></code></pre></div>
<p><img src="R-linear-regression_files/figure-html/unnamed-chunk-61-1.png" width="70%" style="display: block; margin: auto;" /><img src="R-linear-regression_files/figure-html/unnamed-chunk-61-2.png" width="70%" style="display: block; margin: auto;" /><img src="R-linear-regression_files/figure-html/unnamed-chunk-61-3.png" width="70%" style="display: block; margin: auto;" /><img src="R-linear-regression_files/figure-html/unnamed-chunk-61-4.png" width="70%" style="display: block; margin: auto;" /></p>
<p>마지막으로 부모의 중간키 대신 아버지와 어머니의 키를 사용하여 자식의 키를 설명해 보자.
그러면 아버지와 어머니 중 누가 더 자식의 키에 영향을 주는지를 확인해 볼 수 있다.</p>
<div class="sourceCode" id="cb2877"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2877-1"><a href="ch-R-linear-regression.html#cb2877-1" tabindex="-1"></a>lm_galton_fm <span class="ot">&lt;-</span> <span class="fu">lm</span>(childHeight <span class="sc">~</span> father <span class="sc">+</span> mother <span class="sc">+</span> gender, </span>
<span id="cb2877-2"><a href="ch-R-linear-regression.html#cb2877-2" tabindex="-1"></a>                   <span class="at">data=</span>GaltonFamilies)</span>
<span id="cb2877-3"><a href="ch-R-linear-regression.html#cb2877-3" tabindex="-1"></a>lm_galton_fm</span></code></pre></div>
<pre><code>
Call:
lm(formula = childHeight ~ father + mother + gender, data = GaltonFamilies)

Coefficients:
(Intercept)       father       mother   gendermale  
    16.5212       0.3928       0.3176       5.2150  </code></pre>
<p>회귀 결과에서 보듯이 아버지의 키의 계수가 어머니 키의 계수보다 커서 아버지 키의 영향력이 더 큰 것을 볼 수 있다.</p>
<div class="sourceCode" id="cb2879"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2879-1"><a href="ch-R-linear-regression.html#cb2879-1" tabindex="-1"></a><span class="fu">summary</span>(lm_galton_fm)</span></code></pre></div>
<pre><code>
Call:
lm(formula = childHeight ~ father + mother + gender, data = GaltonFamilies)

Residuals:
    Min      1Q  Median      3Q     Max 
-9.5247 -1.4653  0.0943  1.4860  9.1201 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 16.52124    2.72720   6.058    2e-09 ***
father       0.39284    0.02868  13.699   &lt;2e-16 ***
mother       0.31761    0.03100  10.245   &lt;2e-16 ***
gendermale   5.21499    0.14181  36.775   &lt;2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 2.165 on 930 degrees of freedom
Multiple R-squared:  0.6354,    Adjusted R-squared:  0.6342 
F-statistic: 540.3 on 3 and 930 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>부모의 중간키와 성별을 이용한 모형처럼 모형의 통계적 유의성이 채택되고, <span class="math inline">\(R^2\)</span> 값도 조금 더 상승한 것을 볼 수 있다.</p>
<p>다중 선형 회귀를 한 후에는 <code>summary()</code> 결과에서 <code>coefficients:</code> 영역을 유심히 살펴볼 필요가 있다.
다중 선형 회귀에는 여러 독립변수가 사용되기 때문에, 변수들 사이에 정보의 중복성이 있을 수 있기 때문이다.
중복된 정보를 가진 변수들이 있으면 이 중 한 독립변수는 다른 독립변수가 모형에 있으면 모형에 불필요해질 수 있다.
다중 선형 모형에서는 각각의 독립변수마다 다음의 가설검정을 수행한다.</p>
<p><span class="math inline">\(H_0\)</span>: 독립변수 <span class="math inline">\(X_i\)</span>를 제외한 다른 모든 독립변수가 모형에 있으면, 독립변수 <span class="math inline">\(X_i\)</span>는 종속변수 <span class="math inline">\(Y\)</span>에 전혀 독자적인 영향을 미치지 못한다. 즉,
<span class="math display">\[
\beta_j = 0
\]</span></p>
<p><span class="math inline">\(H_1\)</span>: 독립변수 <span class="math inline">\(X_i\)</span>를 제외한 다른 모든 독립변수가 모형에 있어도, 독립변수 <span class="math inline">\(X_i\)</span>는 종속변수 <span class="math inline">\(Y\)</span>에 독자적인 영향을 미친다. 즉,<br />
<span class="math display">\[
\beta_j \neq 0
\]</span></p>
<p>이 가설검정은 T-검정통계량으로 수해되면 T-검정통계량은 t-분포를 따른다.
이 가설검정의 T-검정통계량과 p-값은 <code>summary()</code>의 <code>Coefficients:</code> 표의 <code>t value</code>열과 <code>Pr(&gt;|t|)</code> 열에 제시되어 있다.
아버지와 어머니 키가 모두 들어간 다중 선형 회귀 모형에서는 <code>father</code>, <code>mother</code>, <code>gendermale</code> 모두 T-검정의 p-값이 매우 작아서 다른 변수가 모형에 있더라도 독자적으로 유의미한 영향력을 가지고 있다는 대립가설이 채택된다.</p>
<p>이 모형의 잔차 그래프를 그려보자.
앞의 모형과 마찬가지로 잔차에서 모형의 문제점은 크게 발견되지 않는다.</p>
<div class="sourceCode" id="cb2881"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2881-1"><a href="ch-R-linear-regression.html#cb2881-1" tabindex="-1"></a><span class="fu">plot</span>(lm_galton_fm)</span></code></pre></div>
<p><img src="R-linear-regression_files/figure-html/unnamed-chunk-64-1.png" width="70%" style="display: block; margin: auto;" /><img src="R-linear-regression_files/figure-html/unnamed-chunk-64-2.png" width="70%" style="display: block; margin: auto;" /><img src="R-linear-regression_files/figure-html/unnamed-chunk-64-3.png" width="70%" style="display: block; margin: auto;" /><img src="R-linear-regression_files/figure-html/unnamed-chunk-64-4.png" width="70%" style="display: block; margin: auto;" /></p>
<p>마지막으로 자식의 수(<code>children</code>) 변수를 도입하면 모형의 설명력이 더 향상되는지 확인해 보자.</p>
<div class="sourceCode" id="cb2882"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2882-1"><a href="ch-R-linear-regression.html#cb2882-1" tabindex="-1"></a>lm_galton_fmc <span class="ot">&lt;-</span> <span class="fu">lm</span>(childHeight <span class="sc">~</span> father <span class="sc">+</span> mother <span class="sc">+</span> gender <span class="sc">+</span> children,</span>
<span id="cb2882-2"><a href="ch-R-linear-regression.html#cb2882-2" tabindex="-1"></a>                    <span class="at">data=</span>GaltonFamilies) </span>
<span id="cb2882-3"><a href="ch-R-linear-regression.html#cb2882-3" tabindex="-1"></a><span class="fu">summary</span>(lm_galton_fmc)</span></code></pre></div>
<pre><code>
Call:
lm(formula = childHeight ~ father + mother + gender + children, 
    data = GaltonFamilies)

Residuals:
    Min      1Q  Median      3Q     Max 
-9.4759 -1.4743  0.0906  1.4789  9.1734 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 17.43103    2.77407   6.284 5.08e-10 ***
father       0.38521    0.02898  13.292  &lt; 2e-16 ***
mother       0.31619    0.03098  10.207  &lt; 2e-16 ***
gendermale   5.19852    0.14197  36.617  &lt; 2e-16 ***
children    -0.04573    0.02631  -1.738   0.0825 .  
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 2.162 on 929 degrees of freedom
Multiple R-squared:  0.6366,    Adjusted R-squared:  0.635 
F-statistic: 406.8 on 4 and 929 DF,  p-value: &lt; 2.2e-16</code></pre>
<p><span class="math inline">\(R^2\)</span>이 조금 더 상승하여 모형의 설명력은 증가하였다.
그러나 독립변수가 추가되면 모형의 설명력은 계속 증가하게 된다.
새롭게 도입된 변수가 모형을 유의미하게 설명하고 있는지를 확인해 보아야 한다.
<code>children</code>의 T-검정의 p-값이 0.05보다 크므로 5% 유의수준에서 아버지와 어머니의 키와 성별 정보가 모형에 있으면 <code>children</code> 변수는 <code>childHeight</code>에 유의미한 영향력을 미치지 않는다는 귀무가설이 채택되었다.</p>
<p>지금까지 우리는 자식의 키를 설명하는 다음과 같은 세 개의 다중 회귀 모형을 다루었다.</p>
<ul>
<li>모형 1: 부모의 중간키와 성별로 설명하는 모형</li>
<li>모형 2: 아버지와 어머니의 키와 성별로 설명하는 모형</li>
<li>모형 3: 아버지와 어머니의 키, 성별, 자식의 수로 설명하는 모형</li>
</ul>
<p>부모의 중간키는 아버지와 어머니 키를 선형 조합하여 만들어낸 변수이므로 독립변수에 대한 정보가 다음과 같은 관계를 가진다.</p>
<p><span class="math display">\[
모형 1 \subset 모형 2 \subset 모형 3
\]</span></p>
<p>그러므로 다음과 같은 ANOVA 분석을 사용하며 더 많은 정보를 사용하는 모형이 자식의 키에 대하여 통계적으로 더 유의미한 정보를 가지고 있는지를 가설검정해 볼 수 있다.</p>
<div class="sourceCode" id="cb2884"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2884-1"><a href="ch-R-linear-regression.html#cb2884-1" tabindex="-1"></a><span class="fu">anova</span>(lm_galton_multiple, lm_galton_fm, lm_galton_fmc)</span></code></pre></div>
<pre><code>Analysis of Variance Table

Model 1: childHeight ~ midparentHeight + gender
Model 2: childHeight ~ father + mother + gender
Model 3: childHeight ~ father + mother + gender + children
  Res.Df    RSS Df Sum of Sq      F  Pr(&gt;F)  
1    931 4384.1                              
2    930 4357.9  1    26.196 5.6025 0.01814 *
3    929 4343.7  1    14.127 3.0215 0.08250 .
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>위의 결과에서 보듯이 ANOVA의 F-검정의 p-값에서 모형 2는 모형 1보다 통계적으로 유의미한 정보를 더 가지고 있다는 대립가설이 채택되나, 모형 3와 모형 2보다 통계적으로 유의미한 정보가 같다는 귀무가설이 채택된다.</p>
</div>
<div id="sec-interaction-terms" class="section level3 hasAnchor" number="17.2.4">
<h3><span class="header-section-number">17.2.4</span> 교차항의 도입<a href="ch-R-linear-regression.html#sec-interaction-terms" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="교차항의-의미" class="section level4 unnumbered hasAnchor">
<h4>교차항의 의미<a href="#%EA%B5%90%EC%B0%A8%ED%95%AD%EC%9D%98-%EC%9D%98%EB%AF%B8" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>자식의 키를 부모의 중간키와 자식의 성별로 설명하는 선형 회귀 모형을 다시 고려해 보자.
이 모형은 다음과 같은 회귀식을 데이터에 적합한다.</p>
<p><span class="math display">\[
childHeight = \beta_0 + \beta_1 \times midparentHeight  
              + \beta_2 \times \mathbf{1}(gender=male)
              + \varepsilon
\]</span>
그리고 <code>GaltonFamilies</code> 데이터를 사용하여 <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span>, <span class="math inline">\(\beta_2\)</span>를 추정한 결과는 다음과 같다.</p>
<div class="sourceCode" id="cb2886"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2886-1"><a href="ch-R-linear-regression.html#cb2886-1" tabindex="-1"></a>lm_galton_multiple</span></code></pre></div>
<pre><code>
Call:
lm(formula = childHeight ~ midparentHeight + gender, data = GaltonFamilies)

Coefficients:
    (Intercept)  midparentHeight       gendermale  
         16.514            0.687            5.215  </code></pre>
<p>이 모형은 자식의 성별(<code>gender</code>)에 무관하게 부모의 중간키(<code>midparentHeight</code>)가 1 인치 커지면 자식의 키(<code>childHeight</code>)가 평균적으로 0.687 인치 더 커진다고 설명한다.
즉, 자식의 성별에 무관하게 부모의 중간키의 기울기는 동일하다.
그런데 부모의 키가 자식의 키에 미치는 영향력이 자식의 성별에 따라 달라질 수 있지 않을까?
아들과 딸인지에 무관하게 부모의 키가 미치는 영향력이 동일하다는 것에 의문이 든다.</p>
<p>다중 선형 회귀에서는 한 독립변수의 값에 따라 다른 독립변수의 영향력이 달라지는 것을 모형화 하려고 교차항(interaction terms)을 도입한다.
<span class="math inline">\(X_1\)</span>과 <span class="math inline">\(X_2\)</span>라는 독립변수로 이루어진 회귀 모형에서 두 독립변수의 교차항은 다음처럼 두 독립변수의 곱합으로 도입된다.</p>
<p><span class="math display">\[
Y = \beta_0 + \beta_1 \, X_1 + \beta_2 \, X_2+ \beta_3 \, X_1 \, X_2 + \varepsilon
\]</span></p>
<p>위의 회귀식을 <span class="math inline">\(X_1\)</span> 독립변수의 측면에서 정리하면 다음과 같이 표현된다.</p>
<p><span class="math display">\[
Y = \beta_0 +  \left( \beta_1 + \beta_3 \, X_2 \right) X_1 + \beta_2 \, X_2 + \varepsilon
\]</span></p>
<ul>
<li><span class="math inline">\(X_1\)</span> 한 단위가 증가할 때 <span class="math inline">\(Y\)</span>에 미치는 효과는 <span class="math inline">\(X_2\)</span>에 무관하게 일정한 <span class="math inline">\(\beta_1\)</span>과 <span class="math inline">\(X_2\)</span>의 값에 의해 조정되는 <span class="math inline">\(\beta_3 X_2\)</span>로 나눌 수 있다.</li>
<li><span class="math inline">\(X_1, X_2 &gt; 0\)</span>라고 하자.
<ul>
<li><span class="math inline">\(\beta_3 &gt; 0\)</span>이면 <span class="math inline">\(X_2\)</span>가 커지면 <span class="math inline">\(X_1\)</span>의 효과가 커지는 양의 교차효과(시너지)가 있다.</li>
<li><span class="math inline">\(\beta_3 = 0\)</span>이면 <span class="math inline">\(X_1\)</span>과 <span class="math inline">\(X_2\)</span> 사이의 교차효과(시너지)는 없다.</li>
<li><span class="math inline">\(\beta_3 &lt; 0\)</span>이면 <span class="math inline">\(X_2\)</span>가 커지면 <span class="math inline">\(X_1\)</span>의 효과가 감소하거나 음수가 되는 음의 교차효과(시너지)가 있다.</li>
</ul></li>
</ul>
<p><code>midparentHeight</code>와 <code>gender</code>로 <code>childHeight</code>를 설명하는 회귀 모형에 교차항을 도입해 보자.
그러면 회귀식은 다음과 같이 표현된다.</p>
<p><span class="math display">\[
\begin{split}
childHeight &amp;= \beta_0 + \beta_1 \times midparentHeight  
              + \beta_2 \times \mathbf{1}(gender=male) \\
              &amp;+ \beta_3 \times \mathbf{1}(gender=male) \times midparentHeight
              + \varepsilon
\end{split}
\]</span></p>
<p>범주형 변수는 지시변수로 변환되므로 수치형 변수 사이의 교차항보다 한층 더 세부적인 해석이 가능하다.
앞의 부모의 중간키와 성별의 교차항이 도입된 회귀식은 성별로 나누어 다음처럼 표현할 수 있다.</p>
<p><span class="math display">\[
childHeight =
  \begin{cases}
    \beta_0 + \beta_1 \times midparentHeight  
              + \varepsilon, &amp; gender = female \\
    (\beta_0 + \beta_2) + (\beta_1 + \beta_3) \times midparentHeight  
              + \varepsilon, &amp; gender = male
  \end{cases}
\]</span></p>
<ul>
<li><span class="math inline">\(\beta_0\)</span>는 딸의 회귀식의 절편의 값이고, <span class="math inline">\(\beta_2\)</span>는 아들과 딸의 회귀식에서 절편의 차이이다.
<ul>
<li><span class="math inline">\(\beta_2 &gt; 0\)</span>이면 동일한 부모의 중간키에 대해 아들이 딸보다 평균적으로 더 크다는 의미이다.</li>
<li><span class="math inline">\(\beta_2 = 0\)</span>이라는 T-검정의 귀무가설이 받아들여진다면 동일한 부모의 중간키에 대해 아들과 딸의 평균 키의 유의미한 차니는 없다는 것을 의미한다.</li>
<li><span class="math inline">\(\beta_2 &lt; 0\)</span>이면 동일한 부모의 중간키에 대해 아들이 딸보다 평균적으로 더 작다는 의미이다.</li>
</ul></li>
<li><span class="math inline">\(\beta_1\)</span>은 딸의 회귀식의 <code>midparentHeight</code>의 기울이고, <span class="math inline">\(\beta_3\)</span>는 아들과 딸의 회귀식에서 <code>midparentHeight</code>의 기울기의 차이이다.
<ul>
<li><span class="math inline">\(\beta_3 &gt; 0\)</span>이면 부모의 중간키의 효과가 딸보다는 아들에서 더 크게 나타난다는 의미이다.</li>
<li><span class="math inline">\(\beta_3 = 0\)</span>이라는 T-검정의 귀무가설이 받아들여진다면 자식의 성별에 무관하게 부모의 중간키의 효과의 유의미한 차이가 없다는 것이다.</li>
<li><span class="math inline">\(\beta_3 &lt; 0\)</span>이면 부모의 중간키의 효과가 딸보다는 아들에서 더 작게 나타난다는 의미이다.</li>
</ul></li>
</ul>
</div>
<div id="교차항으로-회귀식-적합하기" class="section level4 unnumbered hasAnchor">
<h4>교차항으로 회귀식 적합하기<a href="#%EA%B5%90%EC%B0%A8%ED%95%AD%EC%9C%BC%EB%A1%9C-%ED%9A%8C%EA%B7%80%EC%8B%9D-%EC%A0%81%ED%95%A9%ED%95%98%EA%B8%B0" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>데이터의 두 열의 교차항을 모형에 도입하려면 <code>lm()</code> 함수의 <code>formula</code> 인수에 <code>열이름_1:열이름_2</code> 형식으로 도입한다.
다음은 부모의 중간키와 자식의 성별의 교차항을 도입하여 모형을 적합한 결과이다.</p>
<div class="sourceCode" id="cb2888"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2888-1"><a href="ch-R-linear-regression.html#cb2888-1" tabindex="-1"></a>lm_galton_inter <span class="ot">&lt;-</span> <span class="fu">lm</span>(childHeight <span class="sc">~</span> midparentHeight <span class="sc">+</span> gender <span class="sc">+</span> midparentHeight<span class="sc">:</span>gender, </span>
<span id="cb2888-2"><a href="ch-R-linear-regression.html#cb2888-2" tabindex="-1"></a>                      <span class="at">data=</span>GaltonFamilies)</span>
<span id="cb2888-3"><a href="ch-R-linear-regression.html#cb2888-3" tabindex="-1"></a>lm_galton_inter</span></code></pre></div>
<pre><code>
Call:
lm(formula = childHeight ~ midparentHeight + gender + midparentHeight:gender, 
    data = GaltonFamilies)

Coefficients:
               (Intercept)             midparentHeight  
                  18.33348                     0.66075  
                gendermale  midparentHeight:gendermale  
                   1.57998                     0.05252  </code></pre>
<p>적합 결과를 회귀식으로 표현하면 다음과 같다.</p>
<p><span class="math display">\[
childHeight =
  \begin{cases}
    18.333 + 0.661 \, midparentHeight  
              + \varepsilon, &amp; gender = female \\
    (18.333 + 1.58) + (0.661 + 0.053) \, midparentHeight  
              + \varepsilon, &amp; gender = male
  \end{cases}
\]</span></p>
<p>그러므로 아들과 딸의 절편의 차이는 1.58이고 <code>midparentHeight</code>의 기울기의 차이는 0.053이다.
따라서 아들이 동일한 부모의 중간키에서 더 크고, 부모의 중간키의 효과더 더 컸다.
그러나 이러한 효과가 통계적으로 유의미한 것인지 확인해 보아야 한다.
이에 대한 통계적 확인은 이 계수들이 0이라는 귀무가설 하에 수행되는 T-검정으로 수행된다.</p>
<div class="sourceCode" id="cb2890"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2890-1"><a href="ch-R-linear-regression.html#cb2890-1" tabindex="-1"></a><span class="fu">summary</span>(lm_galton_inter)</span></code></pre></div>
<pre><code>
Call:
lm(formula = childHeight ~ midparentHeight + gender + midparentHeight:gender, 
    data = GaltonFamilies)

Residuals:
    Min      1Q  Median      3Q     Max 
-9.5431 -1.4568  0.0769  1.4795  9.0860 

Coefficients:
                           Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)                18.33348    3.86636   4.742 2.45e-06 ***
midparentHeight             0.66075    0.05580  11.842  &lt; 2e-16 ***
gendermale                  1.57998    5.46264   0.289    0.772    
midparentHeight:gendermale  0.05252    0.07890   0.666    0.506    
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 2.171 on 930 degrees of freedom
Multiple R-squared:  0.6334,    Adjusted R-squared:  0.6322 
F-statistic: 535.6 on 3 and 930 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>계수에 대한 T-검정 결과 성별에 따른 절편의 차이와 성별에 따른 부모의 중간키의 기울기의 차이 모두 p-값이 커서 차이가 없다는 귀무가설이 채택된다.
그러면 딸과 아들은 절편과 기울기 모두 차이가 없는 것일까?
교차항의 도입하기 전의 모형에서 딸과 아들의 절편의 차이가 뚜렷했었다는 사실을 상기해 보면, 교차항이 도입된 모형의 T-검정 결과가 어리둥절할 수도 있다.</p>
<p>그런데 이러한 결과가 나왔을 때 T-검정에 대한 해석에 주의가 필요하다.
T-검정은 나머지 독립변수가 모형에 있을 때 검정 대상인 독립변수가 통계적으로 유의미한 것인가를 평가하는 과정이다.
따라서 T-검정에서 귀무가설이 채택된 변수가 여러 개일 때는 서로 정보가 중복되는 것은 아닌지를 따져보아야 한다.
두 독립변수가 각각은 종속변수에 영향력이 있지만 서로 정보의 중복성이 매우 높으면 둘 다 모형에 도입되면 한 변수가 모형에 있으면 다른 변수의 통계적 영향력은 의미가 없어지므로 두 변수의 T-검정 결과에서 모두 귀무가설이 채택될 수 있다.
자식의 성별은 절편의 차이나 <code>midparentHeight</code>의 기울기의 차이로 나타나는데 이 두 정보는 통계적으로 뚜렷한 차이가 없어서 위와 같은 T-검정의 결과가 나왔을 수 있다.</p>
<p>이러한 경우에는 두 변수 중 하나를 제외한 후 계수의 통계적 유의성에 대한 판단을 다시 해보아야 한다.
그렇다면 절편과 기울기의 성별 차이 중에 무엇을 제거해야 할까?
일반적으로는 설명력이 더 적은 변수를 제거하는데, 이에 대해서는 뒤에서 살펴보자.
그러나 이렇게 원래 변수와 교차항이 중복되는 경우에는, 일차항인 원래 변수가 모형에 없는데 이차항인 교차항을 모형에 넣는 것은 부자연스러우므로 교차항을 제거한다.
그러면 원래의 회귀식이 되므로 교차항이 도입되는 것은 통계적으로 의미가 없다는 것이다.
교차항이 없는 모형과 교차항이 도입된 모형 사이의 통계적 유의성을 확인하는 ANOVA의 결과에서도 F-검정의 p-값이 커서 교차항이 도입된 모형이 종속변수를 더 설명하는 유의한 차이를 가지지 못하는 것을 확인할 수 있다.</p>
<div class="sourceCode" id="cb2892"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2892-1"><a href="ch-R-linear-regression.html#cb2892-1" tabindex="-1"></a><span class="fu">anova</span>(lm_galton_multiple, lm_galton_inter)</span></code></pre></div>
<pre><code>Analysis of Variance Table

Model 1: childHeight ~ midparentHeight + gender
Model 2: childHeight ~ midparentHeight + gender + midparentHeight:gender
  Res.Df    RSS Df Sum of Sq      F Pr(&gt;F)
1    931 4384.1                           
2    930 4382.0  1    2.0879 0.4431 0.5058</code></pre>
<p>다음으로 부모의 중간키 대신에 아버지와 어머니의 키를 사용한 다음과 같은 회귀 모형에 자식의 성별의 교차항을 도입해 보자.</p>
<div class="sourceCode" id="cb2894"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2894-1"><a href="ch-R-linear-regression.html#cb2894-1" tabindex="-1"></a>lm_galton_fm</span></code></pre></div>
<pre><code>
Call:
lm(formula = childHeight ~ father + mother + gender, data = GaltonFamilies)

Coefficients:
(Intercept)       father       mother   gendermale  
    16.5212       0.3928       0.3176       5.2150  </code></pre>
<p>이 경우에는 <code>father:gender</code>와 <code>mother:gender</code> 교차항을 모형에 도입하면 된다.
그런데 만약 수치형 변수가 두 개가 아니라 더 많으면 교차항을 일일이 기술하는 것은 귀찮은 일이 된다.
<code>lm()</code>의 <code>formula</code> 인수는 교차항을 나타내는 <code>:</code> 연산자뿐 아니라 <code>*</code> 연산자도 가지고 있는데, <code>*</code> 연산자는 곱해지는 두 변수들의 원래의 일차항뿐 아니라 두 변수의 교차항을 모형에 포함시킨다.
따라서 다음과 같은 선형 회귀 모형은 바로 앞서서 부모의 중간키와 성별의 일차항과 교차항을 도입한 모형과 동일하다.</p>
<div class="sourceCode" id="cb2896"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2896-1"><a href="ch-R-linear-regression.html#cb2896-1" tabindex="-1"></a><span class="fu">lm</span>(childHeight <span class="sc">~</span> midparentHeight <span class="sc">*</span> gender, <span class="at">data=</span>GaltonFamilies)</span></code></pre></div>
<pre><code>
Call:
lm(formula = childHeight ~ midparentHeight * gender, data = GaltonFamilies)

Coefficients:
               (Intercept)             midparentHeight  
                  18.33348                     0.66075  
                gendermale  midparentHeight:gendermale  
                   1.57998                     0.05252  </code></pre>
<p>따라서 다음과 같이 표현하면 각 독립변수의 일차항뿐 아니라 <code>father</code>와 <code>mother</code>는 <code>gender</code>에 대한 교차항이 생성되어 모형에 추가된다.</p>
<div class="sourceCode" id="cb2898"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2898-1"><a href="ch-R-linear-regression.html#cb2898-1" tabindex="-1"></a>lm_galton_fm_inter <span class="ot">&lt;-</span> <span class="fu">lm</span>(childHeight <span class="sc">~</span> (father <span class="sc">+</span> mother) <span class="sc">*</span> gender,</span>
<span id="cb2898-2"><a href="ch-R-linear-regression.html#cb2898-2" tabindex="-1"></a>                         <span class="at">data=</span>GaltonFamilies)</span>
<span id="cb2898-3"><a href="ch-R-linear-regression.html#cb2898-3" tabindex="-1"></a>lm_galton_fm_inter</span></code></pre></div>
<pre><code>
Call:
lm(formula = childHeight ~ (father + mother) * gender, data = GaltonFamilies)

Coefficients:
      (Intercept)             father             mother         gendermale  
         18.83358            0.37254            0.30348            0.47923  
father:gendermale  mother:gendermale  
          0.04501            0.02529  </code></pre>
<div class="sourceCode" id="cb2900"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2900-1"><a href="ch-R-linear-regression.html#cb2900-1" tabindex="-1"></a><span class="fu">summary</span>(lm_galton_fm_inter)</span></code></pre></div>
<pre><code>
Call:
lm(formula = childHeight ~ (father + mother) * gender, data = GaltonFamilies)

Residuals:
   Min     1Q Median     3Q    Max 
-9.539 -1.452  0.088  1.495  9.088 

Coefficients:
                  Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)       18.83358    3.87106   4.865 1.34e-06 ***
father             0.37254    0.03851   9.673  &lt; 2e-16 ***
mother             0.30348    0.04513   6.725 3.07e-11 ***
gendermale         0.47923    5.46978   0.088    0.930    
father:gendermale  0.04501    0.05776   0.779    0.436    
mother:gendermale  0.02529    0.06216   0.407    0.684    
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 2.166 on 928 degrees of freedom
Multiple R-squared:  0.6357,    Adjusted R-squared:  0.6338 
F-statistic: 323.9 on 5 and 928 DF,  p-value: &lt; 2.2e-16</code></pre>
<p><code>summary()</code> 결과의 T-검정 결과를 보면 성별, 아버지 키와 성별의 교차항, 어머니 키와 성별의 교차항 모두 다른 변수들이 모형에 있으면 통계적인 유의성이 없다는 귀무가설이 채택되었다.
이 경우에는 아버지 키와 성별의 교차항만 빼거나, 어머니의 키와 성별의 교차항만 빼거나, 아니면 두 교차항을 모두 빼 보면서 유의성이 낮은 변수들이 제거된 최적 모형을 탐색해 보아야 한다.
그런데 이렇게 3 개의 모형을 비교하는 작업도 번거로운데, 수치형 변수가 더 많아서 더 많은 교차항이 있어서 이 중 어떤 교차항이 유의미한지 파악하는 것은 더 힘든 작업이다.</p>
<p><code>stat</code> 기본 패키지의 <code>step()</code> 함수는 현재의 모형에서 가장 덜 유의미한 변수들을 하나씩 제거하면서 최적의 모형을 탐색해 준다.
이렇게 독립변수를 하나씩 제거하면 최적 모형을 탐색하는 방법을 ’후진법(backward selection)’이라고 한다.</p>
<p>다음은 앞의 모형을 후진법으로 변수를 제거하면서 최적의 모형을 선택한 결과이다.</p>
<div class="sourceCode" id="cb2902"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2902-1"><a href="ch-R-linear-regression.html#cb2902-1" tabindex="-1"></a>best_model <span class="ot">&lt;-</span> <span class="fu">step</span>(lm_galton_fm_inter, <span class="at">direction=</span><span class="st">&quot;backward&quot;</span>)</span></code></pre></div>
<pre><code>Start:  AIC=1449.79
childHeight ~ (father + mother) * gender

                Df Sum of Sq    RSS    AIC
- mother:gender  1   0.77664 4354.8 1448.0
- father:gender  1   2.84970 4356.9 1448.4
&lt;none&gt;                       4354.1 1449.8

Step:  AIC=1447.95
childHeight ~ father + mother + gender + father:gender

                Df Sum of Sq    RSS    AIC
- father:gender  1      3.05 4357.9 1446.6
&lt;none&gt;                       4354.8 1448.0
- mother         1    488.90 4843.7 1545.3

Step:  AIC=1446.61
childHeight ~ father + mother + gender

         Df Sum of Sq     RSS    AIC
&lt;none&gt;                 4357.9 1446.6
- mother  1     491.9  4849.7 1544.5
- father  1     879.4  5237.2 1616.3
- gender  1    6337.1 10695.0 2283.1</code></pre>
<p><code>step()</code> 함수는 <a href="https://en.wikipedia.org/wiki/Akaike_information_criterion">AIC(Akaike information criterion)</a>라는 지표를 사용하여 최적 모형을 선택한다.
AIC는 모형의 예측 오차와 관련된 추정치이다. 그러므로 AIC가 작은 모형일수록 예측 품질이 더 좋은 모형이다.</p>
<p><code>step()</code>은 단계적으로 변수를 제거한다.
첫 번째 단계(<code>Start:</code>)에서 <code>mother:gender</code> 교차항을 제거한 모형, <code>father:gender</code> 교차항을 제거한 모형, 아무것도 제거하지 않은 모형(<code>&lt;none&gt;</code>)의 AIC를 비교하였다.
<code>mother:gender</code> 교차항을 제거한 모형이 이 세 모형 중 가장 AIC가 낮으므로 <code>mother:gender</code> 교차항이 제거된 모형이 첫 번째 단계에서 선택된다.
<code>Step:  AIC=1447.95</code> 아래에 기술된 첫 번쩨 단계 후에 선택된 모형이다.</p>
<p>두 번째 단계(<code>Step:  AIC=1447.95</code>)에서는 <code>father:gender</code> 교차항을 제거한 모형, <code>mother</code>가 제거된 모형, 아무것도 제거하지 않은 모형(<code>&lt;none&gt;</code>)의 AIC를 비교하였다.
그 결과 <code>father:gender</code> 교차항을 제거한 모형이 가장 AIC가 낮으므로 이 모형이 선택된다.</p>
<p>세 번째 단게(<code>Step:  AIC=1446.61</code>)에서는 앞 선 두 단계의 결과로 두 교차항이 모두 제거된 모형에서 시작된다.
이 단계에서는 일차항이 각각 제거된 모형과, 아무것도 제거하지 않은 모형(<code>&lt;none&gt;</code>)의 AIC가 비교된다.
아무것도 제거되지 않은 모형의 AIC가 가장 낮으므로, 변수 제거 작업은 여기서 종료되고 현재 모형이 최적 모형으로 선택된다.</p>
<p><code>step()</code> 함수는 단계적 선택의 결과로 최종적으로 선택된 최적 모형을 반환한다.
성별과 부모 키의 교차항은 통계적 유의성이 없어서 일차항므로만 구성된 모형이 최적 모형이 되었다.</p>
<div class="sourceCode" id="cb2904"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2904-1"><a href="ch-R-linear-regression.html#cb2904-1" tabindex="-1"></a>best_model</span></code></pre></div>
<pre><code>
Call:
lm(formula = childHeight ~ father + mother + gender, data = GaltonFamilies)

Coefficients:
(Intercept)       father       mother   gendermale  
    16.5212       0.3928       0.3176       5.2150  </code></pre>
<p>지금까지는 수치형 변수와 범주형 변수의 교차항만 살펴보았다.
아버지와 어머니의 키는 자식의 키에 시너지 효과를 발생시킬 수도 있다.
이를 살펴보기 위하여 아버지와 어머니의 교차항을 모형에 도입해 보자.
다음처럼 <code>*</code> 연산자를 사용하여 아버지 키, 어머니 키, 성별의 모든 가능한 교차항을 모형에 도입할 수 있다.</p>
<div class="sourceCode" id="cb2906"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2906-1"><a href="ch-R-linear-regression.html#cb2906-1" tabindex="-1"></a><span class="fu">lm</span>(childHeight <span class="sc">~</span> (father <span class="sc">+</span> mother <span class="sc">+</span> gender) <span class="sc">*</span> (father <span class="sc">+</span> mother <span class="sc">+</span> gender),</span>
<span id="cb2906-2"><a href="ch-R-linear-regression.html#cb2906-2" tabindex="-1"></a>   <span class="at">data=</span>GaltonFamilies)</span></code></pre></div>
<pre><code>
Call:
lm(formula = childHeight ~ (father + mother + gender) * (father + 
    mother + gender), data = GaltonFamilies)

Coefficients:
      (Intercept)             father             mother         gendermale  
         71.54265           -0.38594           -0.51490            0.11844  
    father:mother  father:gendermale  mother:gendermale  
          0.01178            0.04769            0.02797  </code></pre>
<p>그런데 이러한 수식 표현은 중복된 입력을 두 번이나 해야 하므로 <code>^</code> 연산자를 사용하면 위의 표현을 더 간략하게 표현할 수 있다.</p>
<div class="sourceCode" id="cb2908"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2908-1"><a href="ch-R-linear-regression.html#cb2908-1" tabindex="-1"></a>lm_galton_inter_all <span class="ot">&lt;-</span> <span class="fu">lm</span>(childHeight <span class="sc">~</span> (father <span class="sc">+</span> mother <span class="sc">+</span> gender)<span class="sc">^</span><span class="dv">2</span>,</span>
<span id="cb2908-2"><a href="ch-R-linear-regression.html#cb2908-2" tabindex="-1"></a>   <span class="at">data=</span>GaltonFamilies)</span>
<span id="cb2908-3"><a href="ch-R-linear-regression.html#cb2908-3" tabindex="-1"></a>lm_galton_inter_all </span></code></pre></div>
<pre><code>
Call:
lm(formula = childHeight ~ (father + mother + gender)^2, data = GaltonFamilies)

Coefficients:
      (Intercept)             father             mother         gendermale  
         71.54265           -0.38594           -0.51490            0.11844  
    father:mother  father:gendermale  mother:gendermale  
          0.01178            0.04769            0.02797  </code></pre>
<p>아버지와 어머니 키의 교차항(<code>father:mother</code>)는 양의 값이 나와서 양의 시너지 효과를 보여준다.
그러나 이 값이 과연 통계적으로 유의한 것인지 T-검정 결과를 살펴보자.</p>
<div class="sourceCode" id="cb2910"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2910-1"><a href="ch-R-linear-regression.html#cb2910-1" tabindex="-1"></a><span class="fu">summary</span>(lm_galton_inter_all)</span></code></pre></div>
<pre><code>
Call:
lm(formula = childHeight ~ (father + mother + gender)^2, data = GaltonFamilies)

Residuals:
    Min      1Q  Median      3Q     Max 
-9.5340 -1.4709  0.1185  1.4702  9.0867 

Coefficients:
                  Estimate Std. Error t value Pr(&gt;|t|)
(Intercept)       71.54265   53.08884   1.348    0.178
father            -0.38594    0.76289  -0.506    0.613
mother            -0.51490    0.82332  -0.625    0.532
gendermale         0.11844    5.48180   0.022    0.983
father:mother      0.01178    0.01183   0.995    0.320
father:gendermale  0.04769    0.05782   0.825    0.410
mother:gendermale  0.02797    0.06222   0.450    0.653

Residual standard error: 2.166 on 927 degrees of freedom
Multiple R-squared:  0.6361,    Adjusted R-squared:  0.6338 
F-statistic: 270.1 on 6 and 927 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>아버지와 어머니 키의 교차항을 도입하자 아버지와 어머니 키의 일차항을 포함하여 모든 계수의 T-검정 결과가 귀무가설을 받아들인다.
그러면 모든 독립변수가 종속변수에 전혀 통계적으로 유의미한 영향력이 없는 것일까?
그렇지는 않다.
왜냐하면 모형의 통계적 유의성을 나타내는 F-검정의 p-값을 보면 독립변수가 종속변수의 변동을 통계적으로 유의하게 설명하는 것을 확인할 수 있기 때문이다.
그러면 왜 이러한 현상이 나타난 걸까?
앞서 설명한 것처럼 T-검정은 나머지 다른 변수가 모형에 도입되어 있을 때, 해당 변수가 과연 통계적으로 유의미한지를 판단하는 것이다.
<code>father:mother</code>의 교차항이 도입되자 <code>father</code>와 <code>mother</code>는 부모의 교차항과 나머지 한 부모의 키가 도입되면 정보가 중복된 것뿐이다.</p>
<p>이 모형도 후진법을 사용하여 통게적인 유의성이 적은 변수들을 제거해 보자.</p>
<div class="sourceCode" id="cb2912"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2912-1"><a href="ch-R-linear-regression.html#cb2912-1" tabindex="-1"></a>best_model <span class="ot">&lt;-</span> <span class="fu">step</span>(lm_galton_inter_all, <span class="at">direction=</span><span class="st">&quot;backward&quot;</span>)</span></code></pre></div>
<pre><code>Start:  AIC=1450.79
childHeight ~ (father + mother + gender)^2

                Df Sum of Sq    RSS    AIC
- mother:gender  1    0.9482 4350.4 1449.0
- father:gender  1    3.1920 4352.6 1449.5
- father:mother  1    4.6497 4354.1 1449.8
&lt;none&gt;                       4349.4 1450.8

Step:  AIC=1448.99
childHeight ~ father + mother + gender + father:mother + father:gender

                Df Sum of Sq    RSS    AIC
- father:gender  1    3.4128 4353.8 1447.7
- father:mother  1    4.4782 4354.8 1448.0
&lt;none&gt;                       4350.4 1449.0

Step:  AIC=1447.72
childHeight ~ father + mother + gender + father:mother

                Df Sum of Sq     RSS    AIC
- father:mother  1       4.1  4357.9 1446.6
&lt;none&gt;                        4353.8 1447.7
- gender         1    6324.5 10678.2 2283.7

Step:  AIC=1446.61
childHeight ~ father + mother + gender

         Df Sum of Sq     RSS    AIC
&lt;none&gt;                 4357.9 1446.6
- mother  1     491.9  4849.7 1544.5
- father  1     879.4  5237.2 1616.3
- gender  1    6337.1 10695.0 2283.1</code></pre>
<p>후진번으로 통계적 유의성이 적은 변수들이 제거된자, 앞의 예들과 마찬가지로 일차항만으로 이루어진 원래의 모형이 최적 모형으로 선택되었다.</p>
<div class="sourceCode" id="cb2914"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2914-1"><a href="ch-R-linear-regression.html#cb2914-1" tabindex="-1"></a>best_model</span></code></pre></div>
<pre><code>
Call:
lm(formula = childHeight ~ father + mother + gender, data = GaltonFamilies)

Coefficients:
(Intercept)       father       mother   gendermale  
    16.5212       0.3928       0.3176       5.2150  </code></pre>
<p>원래의 모형으로 돌아왔으니 우리가 지금까지 한 탐색이 무의미해 보인다.
그러나 그렇지 않다.
우리는 이러한 탐색을 통하여 <code>GaltonFamilies</code> 데이터로 판단해 보건데, 아버지 키, 어머니 키, 자식의 성별은 각각 자식의 키에 유의미한 영향을 미치지만 상호 교차하는 영향은 없었다는 새로운 지식을 얻었기 때문이다.
만약 이러한 결과가 유사한 데이터에서 반복적으로 나타난다면 우리는 자식의 키와 부모의 키에 대한 좀 더 확고한 이론을 정립할 수 있을 것이다.</p>
</div>
</div>
<div id="sec-variable-selections" class="section level3 hasAnchor" number="17.2.5">
<h3><span class="header-section-number">17.2.5</span> 변수 선택<a href="ch-R-linear-regression.html#sec-variable-selections" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>변수 선택(variable selection)이란 데이터에 있는 정보의 손실을 최소화하면서 불필요한 변수를 제외하고 모형에 필요한 변수만 선택하는 과정이다.
데이터를 좌표공간에서 표현할 때 한 변수의 값이 좌표공간의 한 차원으로 표현되므로, 변수 선택을 차원 축소(dimension reduciton)이라고도 한다.</p>
<p>데이터에 변수가 많은 경우에 종속변수에 유의미한 영향을 미치는 독립변수를 선택하는 과정은 쉽지 않다.
앞서 우리는 <a href="ch-R-linear-regression.html#sec-interaction-terms">17.2.4</a> 절에서 중요성이 작은 교차항을 제거하기 위해 <code>step()</code> 함수로 후진법으로 변수를 선택해 보았다.
그런데 변수 선택은 다중 선형 회귀에서 독립적인 절로 논의해 볼 필요가 있는 주제이므로 이 절에서 좀 더 체계적으로 다루어 보고자 한다.</p>
<div id="변수-선택의-필요성" class="section level4 unnumbered hasAnchor">
<h4>변수 선택의 필요성<a href="#%EB%B3%80%EC%88%98-%EC%84%A0%ED%83%9D%EC%9D%98-%ED%95%84%EC%9A%94%EC%84%B1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>데이터에 변수가 많으면 어떤 변수를 독립변수로 사용할지 결정하는 것은 어려운 일이다.
가장 단순한 해결책은 종속변수를 제외한 모든 변수를 모형에 도입하는 것이다.
그러나 독립변수의 수가 많아지면 그 중 일부만 종속변수에 유의미한 영향을 미친다.
그리고 유의성이 작은 독립변수들이 모형에 많아지면 다음과 같은 문제가 발생한다.</p>
<ul>
<li>독립변수 수 <span class="math inline">\(p\)</span>가 관측값 수 <span class="math inline">\(n\)</span> 보다 많으면(<span class="math inline">\(p &gt; n\)</span>), 모든 독립변수를 포함시켜 선형 회귀 모형을 적합하는 것은 불가능하다.</li>
<li><span class="math inline">\(p&lt;n\)</span>이어도 <span class="math inline">\(p\)</span>가 <span class="math inline">\(n\)</span>을 기준으로 상당한 크기를 가지면 모형의 안정성을 저해된다. 정보의 중복성이 높은 독립변수가 포함되면 독립변수 사이의 선형 상관성이 높아져서 모형 계수의 추정의 안정성이 저하되는 공선성(multicoliearlity) 문제가 발생한다.</li>
<li>종속변수에 관련없는 독립변수가 모형에 많아지면 모형이 우연적 패턴에 과적합되어 모형의 예측력이 저하되는 과대적합(overfitting) 문제가 발생한다.</li>
<li>독립변수가 많아지면 모형에 대한 이해도가 저하된다.</li>
<li>독립변수가 많아지면 나중에 모형을 새로운 데이터에 적용하려면 모든 독립변수의 데이터를 수집해야 하므로 데이터 수집 비용을 높인다.</li>
<li>’오컴의 면도날’로 대표되는 모형의 단순성에 대한 선호 이론에 따르면 비슷한 설명을 가진 모형이라면 가장 단순한 모형이 과학적 진실일 가능성이 더 높다.</li>
</ul>
<p>반대로 모형에 종속변수의 변동을 충분히 설명할 만큼의 독립변수가 포함되지 않으면 모형의 설명력이 감소하는 과소적합(underfitting) 문제가 발생한다.
그러므로 불필요한 정보의 잉여로 발생하는 과대적합을 방지하면서도 필요한 정보의 부족으로 발생하는 과소적합의 가능성도 줄일 수 있는 최적의 독립변수의 조합을 선택하여 모형에 도입하여야 한다.</p>
</div>
<div id="최적-변수-선택의-척도" class="section level4 unnumbered hasAnchor">
<h4>최적 변수 선택의 척도<a href="#%EC%B5%9C%EC%A0%81-%EB%B3%80%EC%88%98-%EC%84%A0%ED%83%9D%EC%9D%98-%EC%B2%99%EB%8F%84" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>그러면 모형에 최적의 변수 조합이 선택되었다는 것을 어떤 기준으로 평가해야 할까?
모형에 최적 변수의 조합이 선택되었다면 다른 변수 조합보다 새로운 데이터에서도 예측력이 좋을 것이다.
그러므로 변수의 선택이 모형의 예측력을 증가시키는지 평가하는 것이 가장 자연스러운 기준일 것이다.</p>
<p>이를 위해서 <a href="ch-R-linear-regression.html#sec-simple-linear-regression">17.1</a> 절의 ‘모형의 예측력에 대한 평가’ 하위 절에서 설명한 바와 같이 데이터를 훈련집합과 (검증)평가집합으로 나누어 모형의 예측력을 평가해 볼 수 있을 것이다.
기계학습이나 데이터 마이닝에서는 이러한 과정을 거쳐서 최적 모형을 선택한다.</p>
<p>그러나 전통적으로 통계학은 소량의 데이터에서 유용한 정보를 추출해 내기 위해서 발전한 학문이다 보니, 별도의 데이터를 사용하여 모형의 예측력을 평가하기 보다는 모형의 예측력을 간접적으로 추정하는 지표를 사용하는 방법이 이용되었다.
모형의 예측력을 평가하는 지표로 다음과 같은 것이 있다.</p>
<ul>
<li>Mallow’s <span class="math inline">\(C_p\)</span>: 모집단에서 모형의 평균 제곱 오차(MSE)의 추정치로 낮을 수록 좋다.
<span class="math display">\[
C_p = (RSS + 2p \hat{\sigma}^2) / n
\]</span>
단, <span class="math inline">\(\sigma\)</span>는 RSE.</li>
<li>Akaike information criterion (AIC)와 Bayesian information criterion (BIC): 모형의 오차에 변수 개수를 벌금으로 부과한 지표로 낮을수록 좋다.
<span class="math display">\[\begin{align*}
AIC &amp;= 2p - 2 \ln(\hat{L}) \\
BIC &amp; = p \ln(n) - 2 \ln(\hat{L})
\end{align*}\]</span></li>
<li>Adjusted <span class="math inline">\(R^2\)</span>: 변수의 수가 늘어나면 모형의 설명력(<span class="math inline">\(R^2\)</span>)이 지속적으로 향상되는 것을 보정한 지표이다. 높을수록 좋다.
<span class="math display">\[
R_{adjusted}^2 = 1 - \frac{(n-1)(1 - R^2)}{n - p -1}
\]</span></li>
</ul>
</div>
<div id="변수-선택-방법" class="section level4 unnumbered hasAnchor">
<h4>변수 선택 방법<a href="#%EB%B3%80%EC%88%98-%EC%84%A0%ED%83%9D-%EB%B0%A9%EB%B2%95" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>선형 회귀 모형에서 변수를 선택하는 방법은 전역 탐색과 단계적 탐색 방법이 있다.</p>
<p>전역 탐색은 데이터에 있는 변수들을 사용하여 모든 조합으로 모형을 만들어 예측력을 평가하여 가장 좋은 예측력의 모형을 선택한다.
그런데 전역 탐색은 변수가 많아지면 거의 불가능하다.
왜냐하면 <span class="math inline">\(p\)</span> 개의 변수가 있으면 가능한 변수 조합은 <span class="math inline">\(2^p\)</span> 개가 있다.
따라서 <span class="math inline">\(p=20\)</span>이면 거의 백만 개의 모형을 평가해야 한다.</p>
<p>그러므로 가능한 변수 조합 중에서 일부만 탐색하여 최적 조합을 찾는 단계적 탐색이 사용된다.
단계적 탐색법은 크게 다음 세가지 방법으로 나뉜다.</p>
<ul>
<li><p>전진 선택법(forward selection): 독립변수가 하나도 없는 모형에서 시작하여 모형의 예측력을 가장 크게 증가시키는 독립변수를 하나씩 추가한다. 모형에 독립변수를 하나 더 추가해서 예측력이 더 이상 증가하지 않으면 탐색을 종료한다.</p></li>
<li><p>후진 선택법(backrward selection): 모든 가능한 변수가 독립변수로 모두 사용된 모형에서 시작하여 모형의 예측력이 증가하도록 독립변수를 하나씩 제거한다. 모형에서 독립변수 하나를 제거해서 예측력이 더 이상 증가하지 않으면 탐색을 종료한다.</p></li>
<li><p>혼합 선택법(mixed selection): 전진법과 후진법을 결합한 방법이다. 현재의 모형에서 독립변수를 하나 제거하는 경우와 독립변수를 하나 추가하는 경우를 모두 고려하여 가장 예측력이 증가하는 모형으로 이동한다. 독립변수 하나의 추가나 제거로 더 이상 예측력의 증가가 없으면 탐색을 종료한다.</p></li>
</ul>
<p>변수 선택은 최적 모형의 선택 기준이나 선택 방법에 따라 다른 결과가 나올 수 있다. 여러 가지 방법을 사용하여 가장 좋은 모형을 선택한다.</p>
</div>
<div id="r에서의-변수-선택" class="section level4 unnumbered hasAnchor">
<h4><strong>R</strong>에서의 변수 선택<a href="#r%EC%97%90%EC%84%9C%EC%9D%98-%EB%B3%80%EC%88%98-%EC%84%A0%ED%83%9D" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><strong>R</strong>은 <code>step()</code> 함수를 이용하여 단계적 탐색법으로 변수 선택을 자동화할 수 있다.
<code>step()</code> 함수는 AIC를 기준으로 <code>add1()</code>과 <code>drop1()</code> 함수를 연속적으로 사용하여 최적 변수 조합을 탐색한다.</p>
<ul>
<li>첫 번째 인수로 <code>lm()</code> 함수나 <code>glm()</code> 함수로 만든 모형이 전달된다.</li>
<li><code>direction</code> 인수로 전진법(<code>"forward"</code>), 후진법(<code>"backward"</code>), 혼합법(<code>"both"</code>) 중 어떤 방법을 사용하여 변수 탐색을 할지 지정한다.</li>
<li><code>scope</code> 인수로 탐색할 변수의 범위를 지정할 수 있다. 하나의 <code>formula</code> 객체가 지정되거나, <code>lower</code>와 <code>upper</code>로 지정되는 두 개의 수식의 리스트가 지정될 수 있다. <code>lower</code> 수식은 탐색을 할 때 항상 포함되어야 하는 독립변수가, <code>upper</code>는 탐색할 변수의 최대 범위가 지정된다. 그러므로 하나의 수식만 정의되면 <code>upper</code>가 지정된 것이고 모형에 꼭 포함되어야 할 변수인 <code>lower</code>는 없는 것으로 간주한다.</li>
</ul>
<p><a href="ch-R-linear-regression.html#sec-interaction-terms">17.2.4</a> 절에서 <code>step()</code> 함수로 후진법으로 변수를 선택하는 방법은 살펴보았다.
여기서는 전진법과 혼합법으로 변수 선택을 해 보자.</p>
<p>다음은 <code>GaltonFamilies</code> 데이터에서 아버지와 어머니의 키, 가수의 자식의 수, 자식의 성별 열만 사용하여 전집법으로 최적 모형을 선택해 보자.
전진법을 하려면 독립변수가 하나도 없이 절편만 있는 모형을 만들자.
이 모형은 결과적으로 종속변수의 평균값으로 종속변수를 예측힌다.
수식에서 절편을 나타낼 때는 <code>1</code>을 사용한다.</p>
<div class="sourceCode" id="cb2916"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2916-1"><a href="ch-R-linear-regression.html#cb2916-1" tabindex="-1"></a>minimal_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(childHeight <span class="sc">~</span> <span class="dv">1</span>, <span class="at">data=</span>GaltonFamilies)</span>
<span id="cb2916-2"><a href="ch-R-linear-regression.html#cb2916-2" tabindex="-1"></a>minimal_model</span></code></pre></div>
<pre><code>
Call:
lm(formula = childHeight ~ 1, data = GaltonFamilies)

Coefficients:
(Intercept)  
      66.75  </code></pre>
<p><code>scope</code>의 수식에는 종속변수를 기술하는 좌변은 사용하지 않는다.</p>
<div class="sourceCode" id="cb2918"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2918-1"><a href="ch-R-linear-regression.html#cb2918-1" tabindex="-1"></a>best_model <span class="ot">&lt;-</span> <span class="fu">step</span>(minimal_model, <span class="at">direction=</span><span class="st">&quot;forward&quot;</span>,</span>
<span id="cb2918-2"><a href="ch-R-linear-regression.html#cb2918-2" tabindex="-1"></a>                   <span class="at">scope=</span>(<span class="sc">~</span> father <span class="sc">+</span> mother <span class="sc">+</span> children <span class="sc">+</span> gender))</span></code></pre></div>
<pre><code>Start:  AIC=2382.99
childHeight ~ 1

           Df Sum of Sq     RSS    AIC
+ gender    1    6139.8  5812.9 1711.7
+ father    1     846.0 11106.7 2316.4
+ mother    1     484.4 11468.3 2346.3
+ children  1     191.9 11760.8 2369.9
&lt;none&gt;                  11952.7 2383.0

Step:  AIC=1711.69
childHeight ~ gender

           Df Sum of Sq    RSS    AIC
+ father    1    963.19 4849.7 1544.5
+ mother    1    575.69 5237.2 1616.3
+ children  1     81.84 5731.1 1700.5
&lt;none&gt;                  5812.9 1711.7

Step:  AIC=1544.49
childHeight ~ gender + father

           Df Sum of Sq    RSS    AIC
+ mother    1    491.87 4357.9 1446.6
+ children  1     18.86 4830.9 1542.8
&lt;none&gt;                  4849.7 1544.5

Step:  AIC=1446.61
childHeight ~ gender + father + mother

           Df Sum of Sq    RSS    AIC
+ children  1    14.127 4343.7 1445.6
&lt;none&gt;                  4357.9 1446.6

Step:  AIC=1445.57
childHeight ~ gender + father + mother + children</code></pre>
<p><code>step()</code> 함수의 결과를 보면, <code>gender</code>, <code>father</code>, <code>mother</code>, <code>children</code> 순으로 변수가 단계적으로 모형에 추가되었다.
결론적으로 범위로 선택한 모든 변수가 선택되었다.</p>
<p>이번에는 교차항을 포함하여 전진법으로 변수 선택을 수행해 보자.</p>
<div class="sourceCode" id="cb2920"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2920-1"><a href="ch-R-linear-regression.html#cb2920-1" tabindex="-1"></a>best_model <span class="ot">&lt;-</span> <span class="fu">step</span>(minimal_model, <span class="at">direction=</span><span class="st">&quot;forward&quot;</span>,</span>
<span id="cb2920-2"><a href="ch-R-linear-regression.html#cb2920-2" tabindex="-1"></a>                   <span class="at">scope=</span>(<span class="sc">~</span> (father <span class="sc">+</span> mother <span class="sc">+</span> children <span class="sc">+</span> gender)<span class="sc">^</span><span class="dv">2</span>))</span></code></pre></div>
<pre><code>Start:  AIC=2382.99
childHeight ~ 1

           Df Sum of Sq     RSS    AIC
+ gender    1    6139.8  5812.9 1711.7
+ father    1     846.0 11106.7 2316.4
+ mother    1     484.4 11468.3 2346.3
+ children  1     191.9 11760.8 2369.9
&lt;none&gt;                  11952.7 2383.0

Step:  AIC=1711.69
childHeight ~ gender

           Df Sum of Sq    RSS    AIC
+ father    1    963.19 4849.7 1544.5
+ mother    1    575.69 5237.2 1616.3
+ children  1     81.84 5731.1 1700.5
&lt;none&gt;                  5812.9 1711.7

Step:  AIC=1544.49
childHeight ~ gender + father

                Df Sum of Sq    RSS    AIC
+ mother         1    491.87 4357.9 1446.6
+ children       1     18.86 4830.9 1542.8
&lt;none&gt;                       4849.7 1544.5
+ father:gender  1      6.01 4843.7 1545.3

Step:  AIC=1446.61
childHeight ~ gender + father + mother

                Df Sum of Sq    RSS    AIC
+ children       1   14.1275 4343.7 1445.6
&lt;none&gt;                       4357.9 1446.6
+ father:mother  1    4.1116 4353.8 1447.7
+ father:gender  1    3.0462 4354.8 1448.0
+ mother:gender  1    0.9731 4356.9 1448.4

Step:  AIC=1445.57
childHeight ~ gender + father + mother + children

                  Df Sum of Sq    RSS    AIC
&lt;none&gt;                         4343.7 1445.6
+ father:children  1    6.3224 4337.4 1446.2
+ children:gender  1    6.0886 4337.7 1446.3
+ father:mother    1    5.3525 4338.4 1446.4
+ mother:children  1    4.6560 4339.1 1446.6
+ father:gender    1    3.6761 4340.1 1446.8
+ mother:gender    1    1.2350 4342.5 1447.3</code></pre>
<p>마지막 단계의 출력을 보면 어떠한 교차항의 추가도 일차항만 있는 모형보다 AIC가 더 작지 않으므로 일차항만의 모형이 최종 모형으로 선택되는 것을 확인할 수 있다.</p>
<div class="sourceCode" id="cb2922"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2922-1"><a href="ch-R-linear-regression.html#cb2922-1" tabindex="-1"></a><span class="fu">summary</span>(best_model)</span></code></pre></div>
<pre><code>
Call:
lm(formula = childHeight ~ gender + father + mother + children, 
    data = GaltonFamilies)

Residuals:
    Min      1Q  Median      3Q     Max 
-9.4759 -1.4743  0.0906  1.4789  9.1734 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 17.43103    2.77407   6.284 5.08e-10 ***
gendermale   5.19852    0.14197  36.617  &lt; 2e-16 ***
father       0.38521    0.02898  13.292  &lt; 2e-16 ***
mother       0.31619    0.03098  10.207  &lt; 2e-16 ***
children    -0.04573    0.02631  -1.738   0.0825 .  
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 2.162 on 929 degrees of freedom
Multiple R-squared:  0.6366,    Adjusted R-squared:  0.635 
F-statistic: 406.8 on 4 and 929 DF,  p-value: &lt; 2.2e-16</code></pre>
<p><code>summary()</code>의 T-검정 결과를 보면 마지막에 추가된 <code>children</code>은 유의수준 10%에서는 종속변수에 영향력이 있다는 대립가설이 채택되지만, 유의수준 5%에서는 종속변수에 영향력이 없다는 귀무가설이 받아들여진다.
그러므로 이 변수를 모형에 포함시킬지 말지는 분석자가 도메인 지식과 분석의 목적을 고려하여 선택해야 할 것이다.</p>
<p>다음은 혼합법으로 변수 선택을 한 결과이다.
혼합법은 어떠한 모형에서도 시작할 수 있으므로 아버지의 키, 어머니의 키, 성별이 들어간 모형에서 시작해 보자.</p>
<div class="sourceCode" id="cb2924"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2924-1"><a href="ch-R-linear-regression.html#cb2924-1" tabindex="-1"></a>best_model <span class="ot">&lt;-</span> <span class="fu">step</span>(lm_galton_fm, <span class="at">direction=</span><span class="st">&quot;both&quot;</span>,</span>
<span id="cb2924-2"><a href="ch-R-linear-regression.html#cb2924-2" tabindex="-1"></a>                   <span class="at">scope=</span>(<span class="sc">~</span> (father <span class="sc">+</span> mother <span class="sc">+</span> children <span class="sc">+</span> gender)<span class="sc">^</span><span class="dv">2</span>))</span></code></pre></div>
<pre><code>Start:  AIC=1446.61
childHeight ~ father + mother + gender

                Df Sum of Sq     RSS    AIC
+ children       1      14.1  4343.7 1445.6
&lt;none&gt;                        4357.9 1446.6
+ father:mother  1       4.1  4353.8 1447.7
+ father:gender  1       3.0  4354.8 1448.0
+ mother:gender  1       1.0  4356.9 1448.4
- mother         1     491.9  4849.7 1544.5
- father         1     879.4  5237.2 1616.3
- gender         1    6337.1 10695.0 2283.1

Step:  AIC=1445.57
childHeight ~ father + mother + gender + children

                  Df Sum of Sq     RSS    AIC
&lt;none&gt;                          4343.7 1445.6
+ father:children  1       6.3  4337.4 1446.2
+ children:gender  1       6.1  4337.7 1446.3
+ father:mother    1       5.4  4338.4 1446.4
+ mother:children  1       4.7  4339.1 1446.6
- children         1      14.1  4357.9 1446.6
+ father:gender    1       3.7  4340.1 1446.8
+ mother:gender    1       1.2  4342.5 1447.3
- mother           1     487.1  4830.9 1542.8
- father           1     826.1  5169.9 1606.2
- gender           1    6269.1 10612.9 2277.9</code></pre>
<p>첫 단계를 보면 <code>children</code>과 교차항의 추가(<code>+</code>로 표시)와 <code>mother</code>, <code>father</code>, <code>gender</code>의 제거(<code>-</code>로 표시)를 모두 고려한 것을 확인할 수 있다.
이 중 <code>children</code>의 추가만이 현재의 모형보다 AIC가 더 감소한다.
이 문제의 결국 전진법과 혼합법이 모두 동일한 변수 조합을 최적 모형으로 선택하였다.
더 복잡한 문제의 경우에는 전진, 후진, 혼합법의 결과가 서로 다를 수 있다.
그러한 경우에는 각 모형의 설명력, 예측력에 대한 추정치, 분석하고자 하는 문제와의 관련성 등을 고려하여 분석자가 선택을 하여야 한다.</p>
</div>
<div id="중복되는-독립변수의-정보를-제거하는-다른-방법들" class="section level4 unnumbered hasAnchor">
<h4>중복되는 독립변수의 정보를 제거하는 다른 방법들<a href="#%EC%A4%91%EB%B3%B5%EB%90%98%EB%8A%94-%EB%8F%85%EB%A6%BD%EB%B3%80%EC%88%98%EC%9D%98-%EC%A0%95%EB%B3%B4%EB%A5%BC-%EC%A0%9C%EA%B1%B0%ED%95%98%EB%8A%94-%EB%8B%A4%EB%A5%B8-%EB%B0%A9%EB%B2%95%EB%93%A4" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>변수가 많은 경우 변수 선택으로 모형에 포함시킬 독립변수를 직접 선택할 수 있지만, 여기에서 소개하지 않은 다른 방법을 사용할 수도 있다.</p>
<ul>
<li>기존 변수를 선형 결합한 소수의 유도 변수로 선형 모형 적합
<ul>
<li>주성분 분석(PCA)을 이용한 회귀: 독립변수의 변동을 가장 잘 설명하며 서로 선형 독립인 소수의 유도 변수를 생성하여 회귀 분석하는 방법이다. 주성분 분석에 대해서는 <a href="#ch-dimenstion-reduction"><strong>??</strong></a> 장을 참조한다.</li>
<li>부분 최소 제곱법(parital least square)을 이용한 회귀: 종속변수의 변동을 가장 잘 설명하면서 서로 선형 독립인 소수의 유도 변수를 생성하여 회귀 분석</li>
</ul></li>
<li>정칙화 회귀(regularized regression) 모형으로 적합
<ul>
<li>능형 회귀(ridge regression): 회귀 계수의 제곱에 벌금을 부과하여 예측력이 크지 않은 변수의 계수를 0으로 축소시키는 회귀 분석</li>
<li>라쏘(lasso): 회귀 계수의 절대값이 벌금을 부과하여 예측력이 크지 않은 변수의 계수는 0이 되도록 하는 회귀 분석</li>
</ul></li>
</ul>
<!--

## 선형 회귀 모형의 검토 및 확장* {#sec-residual-anlaysis} 

\@ref(sec-multiple-linear-regression) 절에서 모형이 기본 가정을 만족하고 특이점이나 영향점이 없는지를 살펴보기 위하여 잔차 분석을 하는 방법을 설명하였다.
잔차 분석은 주로 잔차 그래프를 그려 모형의 적절성을 시각적으로 검토하는 것이다 보니 경험이 적은 회귀 분석의 초보자에게는 어려운 작업이다.
이 절에서는 `stat` 패키지가 제공하는 기본 잔차 그래프 이외에 잔차 분석을 좀 더 자세히  할 수 있는 다른 도구를 소개하고자 한다.

이 절에서 소개할 잔자 분석 도구들은 주로 `car` 패키지에서 제공한다.
다음 명령어를 사용하여 `car` 패키지를 먼서 설치하고 적재하도록 하자.


``` r
install.packages("car")
```


``` r
library(car)
```

```
필요한 패키지를 로딩중입니다: carData
```

```

다음의 패키지를 부착합니다: 'car'
```

```
The following object is masked from 'package:dplyr':

    recode
```

```
The following object is masked from 'package:purrr':

    some
```


#### 모형 비선형성 검토 {-}

독립변수와 종속변수 사이에 선형 관계만으로 설명되지 않는 비선형적 경향이 있는지를 확인한다.
만약 비선형 관계가 감지되면 교차항 등의 이차항의 도입이나, 종속변수와 독립변수의 변환을 고려한다.

모형의 비선형을 검토하는 대표적인 방법은 잔차 vs. 종속변수 적합치의 그래프를 그려서 뚜렷한 비선형이 있는지룰 확인하는 것이다.
\@ref(sec-multiple-linear-regression) 절에서 설명한 바와 같이 다음처럼 잔차 vs. 종속변수 적합치의 그래프를 그릴 수 있다.
`GaltonFamilies`의 변수선택으로 선택된 최적 모형의 잔차 그래프를 그려보자.
별 다른 비선형적 패턴은 발견되지 않는다.


``` r
plot(best_model, which=1)
```

<img src="R-linear-regression_files/figure-html/unnamed-chunk-89-1.png" width="70%" style="display: block; margin: auto;" />

독립변수 별로 비선형성을 확인하려면 다른 독립변수의 효과를 제외한 종속변수(요소 + 잔차) vs. 독립변수를 나타내는 부분 잔차 그래프(partial residual plot)을 그려본다.
이 그래프를 그리는 방법은 두 가지가 있다.

- 기본 `stat` 패키지의 `termplot()`을 이용하여 부분 잔차 그래프 그리기
- `car` 패키지의 `crPlots()` 함수로 부분 잔차 그래프 그리기

여기서는 `car` 패키지를 이용하도록 한다.
다음 그래프에서 보듯이 모든 독립변수에서 비선형적 경향을 나타나지 않았다.


``` r
crPlots(best_model)
```

<img src="R-linear-regression_files/figure-html/unnamed-chunk-90-1.png" width="90%" style="display: block; margin: auto;" />



#### 모형 정규성 검토 {-}

모형의 오차항이 정규 분포를 따르는지를 확인하는 방법은 표준화 잔차에 대한 Q-Q 도표를 그리거나, 표준화 잔차의 정규성을 가설검정하는 `shapiro.test()`를 수행하는 것이다.
그런데 데이터 크기가 커지면 Shapiro 검정은 대립가설에 우호적이라는 점에 주의해야 한다.
만약 모형의 정규성이 부정되었을 경우에는 변수의 변환(log, sqrt, Box-Cox 변환 등)하거나,  한두 개의 특이점 때문이라면 특이점 영역을 모형의 설명 범위에서 제거하는 방안을 검토해 본다.

\@ref(sec-multiple-linear-regression) 절에서 설명한 바와 같이 다음처럼 표준화 잔차의 Q-Q 도표를 그릴 수 있다. 


``` r
plot(best_model, which = 2)
```

<img src="R-linear-regression_files/figure-html/unnamed-chunk-92-1.png" width="70%" style="display: block; margin: auto;" />


``` r
shapiro.test(rstandard(best_model)) 
```

```

    Shapiro-Wilk normality test

data:  rstandard(best_model)
W = 0.99605, p-value = 0.01775
```

Q-Q 도표에서 꼬리부분에서 정규 분포보다는 꼬리가 약간 긴 형태의 분포를 보이고, Shapiro 검정에서 5% 유의수준에서 정규성이 기각되었다.
그러나 Shapiro 검정은 관측 수가 많아지면 대립가설에 우호적이므로 Shapiro 검정의 결과만으로 정규성을 부정하는데는 신중해야 한다.

좀 더 정확한 정규성 검토를 위해 `car` 패키지의 `qqPlot()` 함수를 사용해 보자. 
이 함수는 부트스트랩 방법을 사용하여 Studentized 잔차의 95% 신뢰구간을 보여 주므로 어떤 데이터가 정규성에 크게 위배되는지 확인할 수 있다.


``` r
qqPlot(best_model)
```

<img src="R-linear-regression_files/figure-html/unnamed-chunk-94-1.png" width="70%" style="display: block; margin: auto;" />

```
[1] 293 487
```

293과 487 번 관측치가 정규성의 95% 신뢰구간에서 조금 벗어난 것을 볼 수 있다.
이 데이터들을 확인해 보면 부모의 키에 비해 예외적으로 큰 아들과, 예외적으로 작은 아들의 데이터라는 것을 확인할 수 있다. 


``` r
slice(GaltonFamilies, c(293, 487))
```

```
  family father mother midparentHeight children childNum gender childHeight
1    072   70.0   65.0           70.10        7        1   male          79
2    109   69.5   64.5           69.58        7        3   male          60
```


#### 모형 등분산성 검토 {-}

모형으 오차항의 분산이 일정한지를 검토한다.
표준화 잔차의 절대값의 제곱근 vs. 종속변수 적합치 그래프를 그려 종속변수 값에 무관하게 표준화 잔차가 1 근처에 있는지 확인한다.
등분산성이 만족되지 않으면 주로 종속변수를 변환하거나 한두 개의 특이점 때문에 발생하는 문제이면 특이점 영역을 모형의 설명 영역에서 제거하는 것을 고려해 본다.

\@ref(sec-multiple-linear-regression) 절에서 설명한 바와 같이 다음처럼 표준화 잔차의 제곱근 vs 그릴 수 있다. 


``` r
plot(best_model, which = 3)
```

<img src="R-linear-regression_files/figure-html/unnamed-chunk-96-1.png" width="70%" style="display: block; margin: auto;" />

`car` 패키지의 `ncvTest()`는 종속변수의 적합치에 무관하게 표준화 잔차의 등분산성이 만족되는지를 가설검정한다.  
아울러 `car` 패키지의 `spreadLevelPlot()`는 종속변수의 적합치 vs. 절대 표준화 잔차 그래프를 그려서 등분산성을 시각적으로 검토할 수 있게 해준다. 표준화  등분산성이 만족되기 위해서 종속변수를 power 변환하는 방법도 제시해 준다.


``` r
ncvTest(best_model)
```

```
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 6.080139, Df = 1, p = 0.013671
```


``` r
spreadLevelPlot(best_model)
```

<img src="R-linear-regression_files/figure-html/unnamed-chunk-98-1.png" width="70%" style="display: block; margin: auto;" />

```

Suggested power transformation:  -0.2130593 
```

#### 모형 독립성 검토 {-}

선형 회귀 모형은 관측 대상의 오차항이 독립이라고 가정한다.
오차항의 독립성은 관측대상 간에 연관성이 있는지에 대한 논리적 검토가 필요하다.
`GaltonFamilies`처럼 가족이 모두 표본에 들어가 있으면 오차항이 서로 연관되어 있을 수 있다.
시계열 데이터에서도 특정 시점의 오차항이 이전 기간의 오차항과 자기상관성이 있는 경우가 많다.
시계열 데이터의 오차항의 자기상관성은 산점도를 이용하여 살펴본다. 
`car` 패키지의 `durbinWatsonTest()`는 오차항의 자기상관성에 대해 가설검정해 준다.
오차항의 독립성 검토는 이 책의 범위를 벗어나므로 상세한 방법에 대한 설명은 생략한다.


#### 특이점과 영향점 확인 {-}

특이점(outliers)은 모형의 예상치와 크게 벗어난 특이한 관측치이다.
레버리지(leverage)는 관측 대상이 독립변수 측면에서 주류적 경향에서 벗어난 정도를 나타낸다. 
영향점(influential points)는 선형 회귀 모형의 추정치에 크게 영향을 주는 관측치이다. 그러므로 이 점을 제외하면 선형 회귀 모형의 계수가 크게 바뀐다.    
특이점과 영향점이 올바른 데이터인지 탐색이 필요하다.

다음 네 그래프를 살펴보자.

<img src="R-linear-regression_files/figure-html/unnamed-chunk-99-1.png" width="45%" style="display: block; margin: auto;" /><img src="R-linear-regression_files/figure-html/unnamed-chunk-99-2.png" width="45%" style="display: block; margin: auto;" /><img src="R-linear-regression_files/figure-html/unnamed-chunk-99-3.png" width="45%" style="display: block; margin: auto;" /><img src="R-linear-regression_files/figure-html/unnamed-chunk-99-4.png" width="45%" style="display: block; margin: auto;" />

- 첫 번째 그래프는 특이점이나 영향점이 없는 데이터이다.
- 두 번째 그래프는 첫 번째 그래프에서 독립변수 X 측면에서 레버리지가 높은 점이 추하되었다. 그러나 추가된 점이 모형의 예측에서 크게 벗어나지 않으므로 특이점은 아니다. 그러므로 이 추가된 점은 회귀 모형에 큰 영향력을 발휘하지 않는다. 
- 세 번째 그래프에는 레버리지는 높지 않지만 모형의 예측치에 벗어난 특이점이 추가되었다. 특이점 때문에 모형의 계수가 조금 변경되었지만 큰 영향력을 발휘하지는 않는다.
- 네 번째 그래프에서는 레버리지도 크고 모형에서도 크게 벗어난 영향점이 추가되었다. 이 점의 추가로 모형의 계수가 매우 크게 변경되는 것을 살펴볼 수 잇다.

일반적으로 표준화 잔차(standardized residulas)의 절대값이 크면 모형의 예측에서 벗어난 특이점이라 판단한다.
이 값이 2 이상이면 주의깊게 살펴보아야 한다.

`car` 패키지의 `outlierTest()`는 특이점인지에 대한 가설검정을 하여 특이점을 출력해 준다.


``` r
outlierTest(best_model)
```

```
     rstudent unadjusted p-value Bonferroni p
487 -4.431101         1.0494e-05    0.0098011
293  4.287384         1.9970e-05    0.0186520
```

`car` 패키지의 `influencePlot()`는 표준화 잔차 vs. 레버리지 그래프 그려준다.
특이점과 레버리지 기준선 출력해 준다. 그리고 점의 크기를 Cook 거리로 표현한다. 
`influencePlot()`에서는 Cook 거리가 $4/(n-p+1)$보다 크면 영향점으로 간주한다.


``` r
influencePlot(best_model)
```

<img src="R-linear-regression_files/figure-html/unnamed-chunk-101-1.png" width="70%" style="display: block; margin: auto;" />

```
       StudRes         Hat        CookD
62  -3.9097236 0.004763492 0.0144109814
293  4.2873840 0.002583411 0.0093471894
487 -4.4311006 0.002311317 0.0089185123
845  0.9230690 0.018871217 0.0032782446
846  0.4560601 0.018871217 0.0008007896
928  3.1881818 0.013410665 0.0273631922
```


#### 독립변수 사이의 공선성 검토 {-}

공선성이란 독립변수 사이의 강한 선형 상관성을 의미한다.
두 변수 사이의 상관성 뿐 아니라 여러 독립변수 사이에도 선형 상관성이 발생할 수 있다.
독립변수에 공선성이 있으면 회귀 계수 예측이 불안정해져서 모형의 설명력에 문제가 발생한다.
공선성은 독립변수의 VIF(Variable Inflation Factor)를 이용하여 확인하는데, $\sqrt{VIF} > 2$ 이상이면 이 변수와 다른 독립변수 사이에 강한 공선성이 있다고 판단한다.

`car` 패키지의 `vif()` 함수는 독립변수의 VIF(Variable Inflation Factor)를 계산해 준다.
공선성이 강하면 변수 선택을 통해 중복 변수를 제거한다.


``` r
vif(best_model)
```

```
  father   mother   gender children 
1.027778 1.004926 1.005658 1.028648 
```

#### 선형 회귀 모형의 확장 - 비선형 항의 도입 {-}

앞서 \@ref(sec-interaction-terms)와 \@ref(sec-variable-selection) 절에서 살펴본 바와 같이 `lm()`의 수식에서 \verb|:, *, ^|는 특수한 의미를 가지고 있다.

- `X:Y`: `X`와 `Y`의 교차항
- `X * Y`: `X`와 `Y`의 일차항과 교차항. 즉, `X + Y + X:Y`를 의미
- `(X + Y) * Z`: `X + Y + Z + X:Z + Y:Z`를 의미
- `(X + Y + z)^2`: 각 항(1차)과 두 항의 교차항(2차) 
- `(X + Y + z)^3`: 각 항(1차)과 두 항의 교차항(2차)과 세 항의 교차항(3차)

다음은 아버지 키, 어머니 키, 성별의 일차항, 두 일차항의 교차항, 세 일차항의 교차항이 모두 포함된 모형이다.


``` r
lm(childHeight ~ (father + mother + gender)^3, data=GaltonFamilies)
```

```

Call:
lm(formula = childHeight ~ (father + mother + gender)^3, data = GaltonFamilies)

Coefficients:
             (Intercept)                    father                    mother  
               83.201988                 -0.553718                 -0.695930  
              gendermale             father:mother         father:gendermale  
              -23.588700                  0.014381                  0.389416  
       mother:gendermale  father:mother:gendermale  
                0.396731                 -0.005315  
```

그러면 변수 `X`의 이차항이나 삼차항을 모형에 도입하려면 어떻게 해야 할까?
`X^2`이나 `X^3`을 사용하면 되지 않을까라 생각할 수 있지만, 앞에서 보았듯이 수식에 `^`는 일차항과 교차항을 표현하기 위해 사용된다.
변수 `X`의 고차항을 도입하려면 `I(X^2), I(X^3), ...`을 사용하여 수식에 표현한다.
`I()` 함수는 사용된 연산자들이 특별한 의미가 없이 원래의 의미로 사용되어야 한다는 것을 나타낸다.

다음은 부모의 중간키의 일차항과 이차항, 그리고 성별로 자식의 키를 설명한느 모형의 적합 결과이다.
모형의 예측치를 시각화해 보면 곡선 형태로 모형을 적합한 것을 볼 수 있다.


``` r
lm_quad <- lm(childHeight ~ midparentHeight + I(midparentHeight^2) + gender, 
   data=GaltonFamilies)
lm_quad
```

```

Call:
lm(formula = childHeight ~ midparentHeight + I(midparentHeight^2) + 
    gender, data = GaltonFamilies)

Coefficients:
         (Intercept)       midparentHeight  I(midparentHeight^2)  
           115.48130              -2.17079               0.02062  
          gendermale  
             5.21859  
```

``` r
ggplot(GaltonFamilies, aes(midparentHeight, childHeight, color=gender)) +
  geom_point() +
  geom_line(aes(y=lm_quad$fitted.values))
```

<img src="R-linear-regression_files/figure-html/unnamed-chunk-105-1.png" width="70%" style="display: block; margin: auto;" />

그러나 부모의 중간키의 일, 이차항의 T-검정의 p-값이 큰 것으로 보아 이차항이 통계적으로 유의미한 설명을 하지 못하는 것으로 판단된다. 


``` r
summary(lm_quad)
```

```

Call:
lm(formula = childHeight ~ midparentHeight + I(midparentHeight^2) + 
    gender, data = GaltonFamilies)

Residuals:
   Min     1Q Median     3Q    Max 
-9.468 -1.454  0.087  1.443  9.164 

Coefficients:
                      Estimate Std. Error t value Pr(>|t|)    
(Intercept)          115.48130   65.71882   1.757   0.0792 .  
midparentHeight       -2.17079    1.89649  -1.145   0.2527    
I(midparentHeight^2)   0.02062    0.01368   1.507   0.1321    
gendermale             5.21859    0.14208  36.730   <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 2.169 on 930 degrees of freedom
Multiple R-squared:  0.6341,    Adjusted R-squared:  0.6329 
F-statistic: 537.2 on 3 and 930 DF,  p-value: < 2.2e-16
```

변수 `X`의 함수 변환한 항을 도입하려면 `log(X), sqrt(X), sin(X), ...`을 사용하여 수식에 표현한다.
로그 변환은 양수이고 왼쪽으로 치우친, 즉 오른쪽으로 꼬리가 긴 분포를 가진 변수에 주로 사용된다.
다음은 다이아몬드 가격(`price`)을 로그 변환한 후, 로그 변환된 다이아몬드 중량(`carat`)과 투명도(`clairty`)을 이용하여 적합한 결과이다.
이 두 변수는 모두 왼쪽으로 크게 치우친 분포를 가지고 있다.


``` r
ggplot(diamonds, aes(price)) + geom_histogram()
```

```
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
```

<img src="R-linear-regression_files/figure-html/unnamed-chunk-107-1.png" width="70%" style="display: block; margin: auto;" />

``` r
ggplot(diamonds, aes(carat)) + geom_histogram()
```

```
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
```

<img src="R-linear-regression_files/figure-html/unnamed-chunk-107-2.png" width="70%" style="display: block; margin: auto;" />


``` r
lm_log <- lm(log(price) ~ log(carat) * clarity, data=diamonds)
lm_log
```

```

Call:
lm(formula = log(price) ~ log(carat) * clarity, data = diamonds)

Coefficients:
         (Intercept)            log(carat)             clarity.L  
             8.51300               1.78539               0.91915  
           clarity.Q             clarity.C             clarity^4  
            -0.22628               0.13204              -0.07998  
           clarity^5             clarity^6             clarity^7  
             0.04857               0.01995               0.04717  
log(carat):clarity.L  log(carat):clarity.Q  log(carat):clarity.C  
             0.21032              -0.12819               0.10829  
log(carat):clarity^4  log(carat):clarity^5  log(carat):clarity^6  
            -0.07273               0.05751               0.01661  
log(carat):clarity^7  
            -0.01736  
```


``` r
ggplot(diamonds, aes(carat, price, color=clarity)) + 
  geom_point(alpha=0.25) +
  geom_line(aes(y=exp(lm_log$fitted.values)), linewidth=1) +
  scale_y_continuous(limits=c(0, 20000))
```

<img src="R-linear-regression_files/figure-html/unnamed-chunk-109-1.png" width="70%" style="display: block; margin: auto;" />

-->

</div>
</div>
</div>
</div>



</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-galton1886regression" class="csl-entry">
Galton, Francis. 1886. <span>“Regression Towards Mediocrity in Hereditary Stature.”</span> <em>The Journal of the Anthropological Institute of Great Britain and Ireland</em> 15: 246–63.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="19">
<li id="fn19"><p>정확히 말하자면 독립변수와 종속변수는 다양한 형태로 변환될 수 있으므로 선형 회귀 모형을 사용하여도 독립변수와 종속변수 사이의 비선형 관계를 모형화할 수 있다. 그러나 궁극적으로 변환된 독립변수와 종속변수들은 선형식으로 관계가 표현된다.<a href="ch-R-linear-regression.html#fnref19" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="ch-R-hypothesis-tests.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="ch-RandPython.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["R-programming-3rd.pdf", "R-programming-3rd.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
